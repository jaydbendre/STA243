{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and scaling the dataset\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets \n",
    "train_df = pd.read_csv('train.data.csv')\n",
    "test_df = pd.read_csv('test.data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()), ('reg', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>7237550310</td>\n",
       "      <td>20140512T000000</td>\n",
       "      <td>1225000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5420</td>\n",
       "      <td>101930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3890</td>\n",
       "      <td>1530</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.6561</td>\n",
       "      <td>-122.005</td>\n",
       "      <td>4760</td>\n",
       "      <td>101930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1321400060</td>\n",
       "      <td>20140627T000000</td>\n",
       "      <td>257500</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          id             date    price  bedrooms  bathrooms  \\\n",
       "0           2  6414100192  20141209T000000   538000         3       2.25   \n",
       "1           4  2487200875  20141209T000000   604000         4       3.00   \n",
       "2           5  1954400510  20150218T000000   510000         3       2.00   \n",
       "3           6  7237550310  20140512T000000  1225000         4       4.50   \n",
       "4           7  1321400060  20140627T000000   257500         3       2.25   \n",
       "\n",
       "   sqft_living  sqft_lot  floors  waterfront  ...  grade  sqft_above  \\\n",
       "0         2570      7242     2.0           0  ...      7        2170   \n",
       "1         1960      5000     1.0           0  ...      7        1050   \n",
       "2         1680      8080     1.0           0  ...      8        1680   \n",
       "3         5420    101930     1.0           0  ...     11        3890   \n",
       "4         1715      6819     2.0           0  ...      7        1715   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0            400      1951          1991    98125  47.7210 -122.319   \n",
       "1            910      1965             0    98136  47.5208 -122.393   \n",
       "2              0      1987             0    98074  47.6168 -122.045   \n",
       "3           1530      2001             0    98053  47.6561 -122.005   \n",
       "4              0      1995             0    98003  47.3097 -122.327   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1690        7639  \n",
       "1           1360        5000  \n",
       "2           1800        7503  \n",
       "3           4760      101930  \n",
       "4           2238        6819  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the predictors and the target\n",
    "X_train = train_df[[\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\"]]\n",
    "y_train = train_df[\"price\"]\n",
    "\n",
    "X_test = test_df[[\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\"]]\n",
    "y_test = test_df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('reg', LinearRegression())])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5101138530794578"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5049944614037101"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = pipe.named_steps['reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-55655.71729094,   2842.59687198, 290948.51916872, -16587.41536884])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538146.886509353"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the gradient descent algorithm\n",
    "def gradient(X,y,betas):\n",
    "    \"\"\"\n",
    "    Calculates the gradient of the loss function\n",
    "\n",
    "    Args:\n",
    "        X (np.matrix): Data Matrix (n x d)\n",
    "        y (np.array): Response vector (n x 1)\n",
    "        betas (np.array): Regression coefficients (d x 1)\n",
    "\n",
    "    Returns:\n",
    "        np.array: Vector containing gradient of the loss function\n",
    "    \"\"\"\n",
    "    return (2/(X.shape[0]))*X.T @ (X @ betas - y)\n",
    "\n",
    "\n",
    "def gradient_descent(X,y,betas,learning_rate,tau = 10e-6):\n",
    "    \"\"\"\n",
    "    Performs Gradient descent on the scaled dataset\n",
    "\n",
    "    Args:\n",
    "        X (np.matrix): Data Matrix (n x d)\n",
    "        y (np.array): Response vector (n x 1)\n",
    "        betas (np.array): Initial coefficient vector (d x 1)\n",
    "        learning_rate (np.float64): Learning rate for gradient descent at which the algorithm converges\n",
    "        tau (np.float64, optional): Threshold value used to determine the stopping point for the algorithm. \n",
    "        Defaults to 10e-6.\n",
    "\n",
    "    Returns:\n",
    "        np.array: True estimate of the regression coefficients\n",
    "    \"\"\"\n",
    "    \n",
    "    # Counter variable to keep track of the number of iterations\n",
    "    i = 0\n",
    "    \n",
    "    # Starting the gradient descent algorithm\n",
    "    while True:\n",
    "        # Getting the gradient at the 't'th iteration\n",
    "        gradients = gradient(X,y,betas)\n",
    "        \n",
    "        # Calculating the norm of the gradient\n",
    "        gradient_norm = np.linalg.norm(gradients)\n",
    "        print(\"Norm of gradient at iteration {}: {}\".format(i, gradient_norm))\n",
    "        \n",
    "        # Checking if the norm of the gradient is less than the threshold value\n",
    "        if gradient_norm < tau:\n",
    "            break\n",
    "        \n",
    "        # Updating the coefficients\n",
    "        betas = betas - learning_rate*gradient(X,y,betas)\n",
    "        \n",
    "        # Incrementing the counter\n",
    "        i+=1\n",
    "        \n",
    "    # Returning the true coefficients\n",
    "    return betas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "X_train_scaled = scalar.fit_transform(X_train)\n",
    "X_test_scaled = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = np.hstack((np.ones((X_train_scaled.shape[0],1)),X_train_scaled))\n",
    "X_test_scaled = np.hstack((np.ones((X_test_scaled.shape[0],1)),X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15129, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6484, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of gradient at iteration 0: 1276097.5840578405\n",
      "Norm of gradient at iteration 1: 1242209.5304384353\n",
      "Norm of gradient at iteration 2: 1209549.9526426902\n",
      "Norm of gradient at iteration 3: 1178061.5246820697\n",
      "Norm of gradient at iteration 4: 1147689.839856283\n",
      "Norm of gradient at iteration 5: 1118383.2716054874\n",
      "Norm of gradient at iteration 6: 1090092.8397720542\n",
      "Norm of gradient at iteration 7: 1062772.0821232477\n",
      "Norm of gradient at iteration 8: 1036376.9309928807\n",
      "Norm of gradient at iteration 9: 1010865.5949053472\n",
      "Norm of gradient at iteration 10: 986198.4450496013\n",
      "Norm of gradient at iteration 11: 962337.9064737505\n",
      "Norm of gradient at iteration 12: 939248.3538732276\n",
      "Norm of gradient at iteration 13: 916896.0118470504\n",
      "Norm of gradient at iteration 14: 895248.8594977164\n",
      "Norm of gradient at iteration 15: 874276.5392508638\n",
      "Norm of gradient at iteration 16: 853950.2697711639\n",
      "Norm of gradient at iteration 17: 834242.7628510223\n",
      "Norm of gradient at iteration 18: 815128.1441487273\n",
      "Norm of gradient at iteration 19: 796581.877652732\n",
      "Norm of gradient at iteration 20: 778580.6937488654\n",
      "Norm of gradient at iteration 21: 761102.5207675135\n",
      "Norm of gradient at iteration 22: 744126.4198882184\n",
      "Norm of gradient at iteration 23: 727632.5232797503\n",
      "Norm of gradient at iteration 24: 711601.9753545499\n",
      "Norm of gradient at iteration 25: 696016.8770175013\n",
      "Norm of gradient at iteration 26: 680860.232790319\n",
      "Norm of gradient at iteration 27: 666115.9006943955\n",
      "Norm of gradient at iteration 28: 651768.5447767475\n",
      "Norm of gradient at iteration 29: 637803.5901657338\n",
      "Norm of gradient at iteration 30: 624207.1805454519\n",
      "Norm of gradient at iteration 31: 610966.1379401515\n",
      "Norm of gradient at iteration 32: 598067.924702618\n",
      "Norm of gradient at iteration 33: 585500.607603236\n",
      "Norm of gradient at iteration 34: 573252.8239193496\n",
      "Norm of gradient at iteration 35: 561313.749427533\n",
      "Norm of gradient at iteration 36: 549673.0682044979\n",
      "Norm of gradient at iteration 37: 538320.9441455207\n",
      "Norm of gradient at iteration 38: 527247.9941125013\n",
      "Norm of gradient at iteration 39: 516445.2626270074\n",
      "Norm of gradient at iteration 40: 505904.1980269234\n",
      "Norm of gradient at iteration 41: 495616.63000857964\n",
      "Norm of gradient at iteration 42: 485574.7484794767\n",
      "Norm of gradient at iteration 43: 475771.08364993177\n",
      "Norm of gradient at iteration 44: 466198.48729513085\n",
      "Norm of gradient at iteration 45: 456850.11512218567\n",
      "Norm of gradient at iteration 46: 447719.4101798363\n",
      "Norm of gradient at iteration 47: 438800.08725141344\n",
      "Norm of gradient at iteration 48: 430086.118174575\n",
      "Norm of gradient at iteration 49: 421571.7180341345\n",
      "Norm of gradient at iteration 50: 413251.3321770289\n",
      "Norm of gradient at iteration 51: 405119.6240011047\n",
      "Norm of gradient at iteration 52: 397171.4634719334\n",
      "Norm of gradient at iteration 53: 389401.91632431943\n",
      "Norm of gradient at iteration 54: 381806.2339074985\n",
      "Norm of gradient at iteration 55: 374379.8436352838\n",
      "Norm of gradient at iteration 56: 367118.34000456467\n",
      "Norm of gradient at iteration 57: 360017.47614762135\n",
      "Norm of gradient at iteration 58: 353073.1558856855\n",
      "Norm of gradient at iteration 59: 346281.42625304573\n",
      "Norm of gradient at iteration 60: 339638.47046277765\n",
      "Norm of gradient at iteration 61: 333140.6012868785\n",
      "Norm of gradient at iteration 62: 326784.25482518086\n",
      "Norm of gradient at iteration 63: 320565.98463896284\n",
      "Norm of gradient at iteration 64: 314482.4562266015\n",
      "Norm of gradient at iteration 65: 308530.44181999273\n",
      "Norm of gradient at iteration 66: 302706.81548175524\n",
      "Norm of gradient at iteration 67: 297008.5484844537\n",
      "Norm of gradient at iteration 68: 291432.70495423547\n",
      "Norm of gradient at iteration 69: 285976.43776236445\n",
      "Norm of gradient at iteration 70: 280636.9846491595\n",
      "Norm of gradient at iteration 71: 275411.66456581466\n",
      "Norm of gradient at iteration 72: 270297.8742204932\n",
      "Norm of gradient at iteration 73: 265293.08481593715\n",
      "Norm of gradient at iteration 74: 260394.83896664882\n",
      "Norm of gradient at iteration 75: 255600.74778445423\n",
      "Norm of gradient at iteration 76: 250908.48812197288\n",
      "Norm of gradient at iteration 77: 246315.79996418676\n",
      "Norm of gradient at iteration 78: 241820.48395892972\n",
      "Norm of gradient at iteration 79: 237420.399077708\n",
      "Norm of gradient at iteration 80: 233113.46039881685\n",
      "Norm of gradient at iteration 81: 228897.63700523388\n",
      "Norm of gradient at iteration 82: 224770.94999025718\n",
      "Norm of gradient at iteration 83: 220731.47056431495\n",
      "Norm of gradient at iteration 84: 216777.3182567918\n",
      "Norm of gradient at iteration 85: 212906.65920712636\n",
      "Norm of gradient at iteration 86: 209117.70453980035\n",
      "Norm of gradient at iteration 87: 205408.70881819498\n",
      "Norm of gradient at iteration 88: 201777.96857261495\n",
      "Norm of gradient at iteration 89: 198223.82089808848\n",
      "Norm of gradient at iteration 90: 194744.64211783762\n",
      "Norm of gradient at iteration 91: 191338.8465085811\n",
      "Norm of gradient at iteration 92: 188004.8850840837\n",
      "Norm of gradient at iteration 93: 184741.24443359833\n",
      "Norm of gradient at iteration 94: 181546.4456120679\n",
      "Norm of gradient at iteration 95: 178419.04307915855\n",
      "Norm of gradient at iteration 96: 175357.62368438434\n",
      "Norm of gradient at iteration 97: 172360.80569576524\n",
      "Norm of gradient at iteration 98: 169427.2378696253\n",
      "Norm of gradient at iteration 99: 166555.59855929384\n",
      "Norm of gradient at iteration 100: 163744.59486061631\n",
      "Norm of gradient at iteration 101: 160992.96179232042\n",
      "Norm of gradient at iteration 102: 158299.4615094055\n",
      "Norm of gradient at iteration 103: 155662.882547844\n",
      "Norm of gradient at iteration 104: 153082.039098993\n",
      "Norm of gradient at iteration 105: 150555.77031221474\n",
      "Norm of gradient at iteration 106: 148082.93962430416\n",
      "Norm of gradient at iteration 107: 145662.43411440597\n",
      "Norm of gradient at iteration 108: 143293.1638831904\n",
      "Norm of gradient at iteration 109: 140974.06145513273\n",
      "Norm of gradient at iteration 110: 138704.08120281086\n",
      "Norm of gradient at iteration 111: 136482.19879220735\n",
      "Norm of gradient at iteration 112: 134307.410648059\n",
      "Norm of gradient at iteration 113: 132178.7334383581\n",
      "Norm of gradient at iteration 114: 130095.2035771605\n",
      "Norm of gradient at iteration 115: 128055.87674490859\n",
      "Norm of gradient at iteration 116: 126059.82742551963\n",
      "Norm of gradient at iteration 117: 124106.14845953499\n",
      "Norm of gradient at iteration 118: 122193.9506126642\n",
      "Norm of gradient at iteration 119: 120322.36215909582\n",
      "Norm of gradient at iteration 120: 118490.52847897814\n",
      "Norm of gradient at iteration 121: 116697.61166950678\n",
      "Norm of gradient at iteration 122: 114942.79016908427\n",
      "Norm of gradient at iteration 123: 113225.25839404135\n",
      "Norm of gradient at iteration 124: 111544.22638743812\n",
      "Norm of gradient at iteration 125: 109898.91947948169\n",
      "Norm of gradient at iteration 126: 108288.57795912161\n",
      "Norm of gradient at iteration 127: 106712.45675639901\n",
      "Norm of gradient at iteration 128: 105169.82513514861\n",
      "Norm of gradient at iteration 129: 103659.9663956644\n",
      "Norm of gradient at iteration 130: 102182.17758695643\n",
      "Norm of gradient at iteration 131: 100735.76922824029\n",
      "Norm of gradient at iteration 132: 99320.0650393136\n",
      "Norm of gradient at iteration 133: 97934.4016794841\n",
      "Norm of gradient at iteration 134: 96578.12849472715\n",
      "Norm of gradient at iteration 135: 95250.60727275757\n",
      "Norm of gradient at iteration 136: 93951.21200571324\n",
      "Norm of gradient at iteration 137: 92679.32866015406\n",
      "Norm of gradient at iteration 138: 91434.35495408947\n",
      "Norm of gradient at iteration 139: 90215.70014075459\n",
      "Norm of gradient at iteration 140: 89022.7847988627\n",
      "Norm of gradient at iteration 141: 87855.04062906929\n",
      "Norm of gradient at iteration 142: 86711.91025638778\n",
      "Norm of gradient at iteration 143: 85592.84703830486\n",
      "Norm of gradient at iteration 144: 84497.31487835031\n",
      "Norm of gradient at iteration 145: 83424.78804487891\n",
      "Norm of gradient at iteration 146: 82374.75099483269\n",
      "Norm of gradient at iteration 147: 81346.69820225234\n",
      "Norm of gradient at iteration 148: 80340.13399131851\n",
      "Norm of gradient at iteration 149: 79354.57237370334\n",
      "Norm of gradient at iteration 150: 78389.53689002308\n",
      "Norm of gradient at iteration 151: 77444.56045518699\n",
      "Norm of gradient at iteration 152: 76519.1852074426\n",
      "Norm of gradient at iteration 153: 75612.96236092536\n",
      "Norm of gradient at iteration 154: 74725.45206152585\n",
      "Norm of gradient at iteration 155: 73856.22324589366\n",
      "Norm of gradient at iteration 156: 73004.85350340465\n",
      "Norm of gradient at iteration 157: 72170.92894092304\n",
      "Norm of gradient at iteration 158: 71354.04405019744\n",
      "Norm of gradient at iteration 159: 70553.80157773674\n",
      "Norm of gradient at iteration 160: 69769.81239701723\n",
      "Norm of gradient at iteration 161: 69001.69538288038\n",
      "Norm of gradient at iteration 162: 68249.07728798606\n",
      "Norm of gradient at iteration 163: 67511.5926211953\n",
      "Norm of gradient at iteration 164: 66788.88352776035\n",
      "Norm of gradient at iteration 165: 66080.59967120845\n",
      "Norm of gradient at iteration 166: 65386.3981168139\n",
      "Norm of gradient at iteration 167: 64705.94321655628\n",
      "Norm of gradient at iteration 168: 64038.90649547294\n",
      "Norm of gradient at iteration 169: 63384.966539318586\n",
      "Norm of gradient at iteration 170: 62743.80888345183\n",
      "Norm of gradient at iteration 171: 62115.125902875756\n",
      "Norm of gradient at iteration 172: 61498.61670336534\n",
      "Norm of gradient at iteration 173: 60893.987013620055\n",
      "Norm of gradient at iteration 174: 60300.94907838794\n",
      "Norm of gradient at iteration 175: 59719.221552512085\n",
      "Norm of gradient at iteration 176: 59148.529395855505\n",
      "Norm of gradient at iteration 177: 58588.60376906828\n",
      "Norm of gradient at iteration 178: 58039.18193016315\n",
      "Norm of gradient at iteration 179: 57500.00713187322\n",
      "Norm of gradient at iteration 180: 56970.82851976884\n",
      "Norm of gradient at iteration 181: 56451.40103111601\n",
      "Norm of gradient at iteration 182: 55941.48529446261\n",
      "Norm of gradient at iteration 183: 55440.847529942745\n",
      "Norm of gradient at iteration 184: 54949.2594502934\n",
      "Norm of gradient at iteration 185: 54466.498162581636\n",
      "Norm of gradient at iteration 186: 53992.34607064306\n",
      "Norm of gradient at iteration 187: 53526.59077823468\n",
      "Norm of gradient at iteration 188: 53069.024992910345\n",
      "Norm of gradient at iteration 189: 52619.446430627\n",
      "Norm of gradient at iteration 190: 52177.657721092524\n",
      "Norm of gradient at iteration 191: 51743.46631387003\n",
      "Norm of gradient at iteration 192: 51316.68438525167\n",
      "Norm of gradient at iteration 193: 50897.12874592004\n",
      "Norm of gradient at iteration 194: 50484.620749413254\n",
      "Norm of gradient at iteration 195: 50078.98620141363\n",
      "Norm of gradient at iteration 196: 49680.055269878605\n",
      "Norm of gradient at iteration 197: 49287.66239603391\n",
      "Norm of gradient at iteration 198: 48901.6462062498\n",
      "Norm of gradient at iteration 199: 48521.84942482046\n",
      "Norm of gradient at iteration 200: 48148.11878766742\n",
      "Norm of gradient at iteration 201: 47780.30495698782\n",
      "Norm of gradient at iteration 202: 47418.26243686678\n",
      "Norm of gradient at iteration 203: 47061.84948987527\n",
      "Norm of gradient at iteration 204: 46710.92805467137\n",
      "Norm of gradient at iteration 205: 46365.36366462421\n",
      "Norm of gradient at iteration 206: 46025.025367479124\n",
      "Norm of gradient at iteration 207: 45689.7856460801\n",
      "Norm of gradient at iteration 208: 45359.52034016633\n",
      "Norm of gradient at iteration 209: 45034.108569258555\n",
      "Norm of gradient at iteration 210: 44713.43265664853\n",
      "Norm of gradient at iteration 211: 44397.37805450557\n",
      "Norm of gradient at iteration 212: 44085.83327011145\n",
      "Norm of gradient at iteration 213: 43778.68979323549\n",
      "Norm of gradient at iteration 214: 43475.84202465845\n",
      "Norm of gradient at iteration 215: 43177.1872058545\n",
      "Norm of gradient at iteration 216: 42882.62534983836\n",
      "Norm of gradient at iteration 217: 42592.05917318322\n",
      "Norm of gradient at iteration 218: 42305.39402921483\n",
      "Norm of gradient at iteration 219: 42022.53784238516\n",
      "Norm of gradient at iteration 220: 41743.401043828155\n",
      "Norm of gradient at iteration 221: 41467.896508098536\n",
      "Norm of gradient at iteration 222: 41195.939491094425\n",
      "Norm of gradient at iteration 223: 40927.44756916187\n",
      "Norm of gradient at iteration 224: 40662.34057937983\n",
      "Norm of gradient at iteration 225: 40400.540561022506\n",
      "Norm of gradient at iteration 226: 40141.971698194066\n",
      "Norm of gradient at iteration 227: 39886.56026363157\n",
      "Norm of gradient at iteration 228: 39634.23456366902\n",
      "Norm of gradient at iteration 229: 39384.9248843561\n",
      "Norm of gradient at iteration 230: 39138.563438723184\n",
      "Norm of gradient at iteration 231: 38895.08431518444\n",
      "Norm of gradient at iteration 232: 38654.42342706905\n",
      "Norm of gradient at iteration 233: 38416.51846326999\n",
      "Norm of gradient at iteration 234: 38181.30884000005\n",
      "Norm of gradient at iteration 235: 37948.73565364325\n",
      "Norm of gradient at iteration 236: 37718.741634688886\n",
      "Norm of gradient at iteration 237: 37491.271102735984\n",
      "Norm of gradient at iteration 238: 37266.26992255477\n",
      "Norm of gradient at iteration 239: 37043.68546119079\n",
      "Norm of gradient at iteration 240: 36823.4665460981\n",
      "Norm of gradient at iteration 241: 36605.563424286476\n",
      "Norm of gradient at iteration 242: 36389.92772246786\n",
      "Norm of gradient at iteration 243: 36176.51240818604\n",
      "Norm of gradient at iteration 244: 35965.271751915134\n",
      "Norm of gradient at iteration 245: 35756.16129010987\n",
      "Norm of gradient at iteration 246: 35549.137789191955\n",
      "Norm of gradient at iteration 247: 35344.15921045676\n",
      "Norm of gradient at iteration 248: 35141.184675882774\n",
      "Norm of gradient at iteration 249: 34940.17443482871\n",
      "Norm of gradient at iteration 250: 34741.089831600155\n",
      "Norm of gradient at iteration 251: 34543.89327387027\n",
      "Norm of gradient at iteration 252: 34348.54820193717\n",
      "Norm of gradient at iteration 253: 34155.01905880145\n",
      "Norm of gradient at iteration 254: 33963.27126104684\n",
      "Norm of gradient at iteration 255: 33773.27117050789\n",
      "Norm of gradient at iteration 256: 33584.986066707366\n",
      "Norm of gradient at iteration 257: 33398.384120047194\n",
      "Norm of gradient at iteration 258: 33213.43436573648\n",
      "Norm of gradient at iteration 259: 33030.10667844007\n",
      "Norm of gradient at iteration 260: 32848.37174763124\n",
      "Norm of gradient at iteration 261: 32668.201053633173\n",
      "Norm of gradient at iteration 262: 32489.566844332374\n",
      "Norm of gradient at iteration 263: 32312.442112548724\n",
      "Norm of gradient at iteration 264: 32136.8005740466\n",
      "Norm of gradient at iteration 265: 31962.61664617134\n",
      "Norm of gradient at iteration 266: 31789.865427096276\n",
      "Norm of gradient at iteration 267: 31618.52267566507\n",
      "Norm of gradient at iteration 268: 31448.564791814264\n",
      "Norm of gradient at iteration 269: 31279.968797562335\n",
      "Norm of gradient at iteration 270: 31112.712318550035\n",
      "Norm of gradient at iteration 271: 30946.77356611831\n",
      "Norm of gradient at iteration 272: 30782.131319909942\n",
      "Norm of gradient at iteration 273: 30618.76491098109\n",
      "Norm of gradient at iteration 274: 30456.654205409806\n",
      "Norm of gradient at iteration 275: 30295.77958838749\n",
      "Norm of gradient at iteration 276: 30136.121948781743\n",
      "Norm of gradient at iteration 277: 29977.662664156273\n",
      "Norm of gradient at iteration 278: 29820.38358623723\n",
      "Norm of gradient at iteration 279: 29664.267026812584\n",
      "Norm of gradient at iteration 280: 29509.29574405301\n",
      "Norm of gradient at iteration 281: 29355.452929243012\n",
      "Norm of gradient at iteration 282: 29202.72219391041\n",
      "Norm of gradient at iteration 283: 29051.087557343428\n",
      "Norm of gradient at iteration 284: 28900.53343448411\n",
      "Norm of gradient at iteration 285: 28751.044624187947\n",
      "Norm of gradient at iteration 286: 28602.606297838865\n",
      "Norm of gradient at iteration 287: 28455.203988309844\n",
      "Norm of gradient at iteration 288: 28308.823579258737\n",
      "Norm of gradient at iteration 289: 28163.451294750033\n",
      "Norm of gradient at iteration 290: 28019.073689193447\n",
      "Norm of gradient at iteration 291: 27875.677637589095\n",
      "Norm of gradient at iteration 292: 27733.25032607134\n",
      "Norm of gradient at iteration 293: 27591.77924274213\n",
      "Norm of gradient at iteration 294: 27451.252168785053\n",
      "Norm of gradient at iteration 295: 27311.65716985275\n",
      "Norm of gradient at iteration 296: 27172.982587718005\n",
      "Norm of gradient at iteration 297: 27035.21703218256\n",
      "Norm of gradient at iteration 298: 26898.349373234312\n",
      "Norm of gradient at iteration 299: 26762.36873344668\n",
      "Norm of gradient at iteration 300: 26627.26448061186\n",
      "Norm of gradient at iteration 301: 26493.02622060182\n",
      "Norm of gradient at iteration 302: 26359.643790449576\n",
      "Norm of gradient at iteration 303: 26227.107251644145\n",
      "Norm of gradient at iteration 304: 26095.406883633135\n",
      "Norm of gradient at iteration 305: 25964.533177525773\n",
      "Norm of gradient at iteration 306: 25834.476829991345\n",
      "Norm of gradient at iteration 307: 25705.228737346126\n",
      "Norm of gradient at iteration 308: 25576.779989823444\n",
      "Norm of gradient at iteration 309: 25449.121866021436\n",
      "Norm of gradient at iteration 310: 25322.245827522493\n",
      "Norm of gradient at iteration 311: 25196.14351367951\n",
      "Norm of gradient at iteration 312: 25070.80673656376\n",
      "Norm of gradient at iteration 313: 24946.22747606913\n",
      "Norm of gradient at iteration 314: 24822.397875167997\n",
      "Norm of gradient at iteration 315: 24699.31023531436\n",
      "Norm of gradient at iteration 316: 24576.95701198891\n",
      "Norm of gradient at iteration 317: 24455.33081038234\n",
      "Norm of gradient at iteration 318: 24334.424381212044\n",
      "Norm of gradient at iteration 319: 24214.23061666856\n",
      "Norm of gradient at iteration 320: 24094.74254648706\n",
      "Norm of gradient at iteration 321: 23975.953334140606\n",
      "Norm of gradient at iteration 322: 23857.856273150686\n",
      "Norm of gradient at iteration 323: 23740.444783512077\n",
      "Norm of gradient at iteration 324: 23623.712408227722\n",
      "Norm of gradient at iteration 325: 23507.652809950814\n",
      "Norm of gradient at iteration 326: 23392.25976773003\n",
      "Norm of gradient at iteration 327: 23277.527173855295\n",
      "Norm of gradient at iteration 328: 23163.4490308004\n",
      "Norm of gradient at iteration 329: 23050.01944825991\n",
      "Norm of gradient at iteration 330: 22937.232640276725\n",
      "Norm of gradient at iteration 331: 22825.08292245815\n",
      "Norm of gradient at iteration 332: 22713.564709276994\n",
      "Norm of gradient at iteration 333: 22602.672511455567\n",
      "Norm of gradient at iteration 334: 22492.400933429602\n",
      "Norm of gradient at iteration 335: 22382.744670889668\n",
      "Norm of gradient at iteration 336: 22273.698508397596\n",
      "Norm of gradient at iteration 337: 22165.257317075604\n",
      "Norm of gradient at iteration 338: 22057.41605236572\n",
      "Norm of gradient at iteration 339: 21950.169751857225\n",
      "Norm of gradient at iteration 340: 21843.513533180285\n",
      "Norm of gradient at iteration 341: 21737.44259196314\n",
      "Norm of gradient at iteration 342: 21631.95219985119\n",
      "Norm of gradient at iteration 343: 21527.03770258615\n",
      "Norm of gradient at iteration 344: 21422.694518142664\n",
      "Norm of gradient at iteration 345: 21318.91813492158\n",
      "Norm of gradient at iteration 346: 21215.70410999719\n",
      "Norm of gradient at iteration 347: 21113.048067417007\n",
      "Norm of gradient at iteration 348: 21010.945696552793\n",
      "Norm of gradient at iteration 349: 20909.39275050059\n",
      "Norm of gradient at iteration 350: 20808.38504452856\n",
      "Norm of gradient at iteration 351: 20707.918454571056\n",
      "Norm of gradient at iteration 352: 20607.988915767553\n",
      "Norm of gradient at iteration 353: 20508.59242104464\n",
      "Norm of gradient at iteration 354: 20409.725019740188\n",
      "Norm of gradient at iteration 355: 20311.3828162681\n",
      "Norm of gradient at iteration 356: 20213.561968822247\n",
      "Norm of gradient at iteration 357: 20116.25868811876\n",
      "Norm of gradient at iteration 358: 20019.469236174813\n",
      "Norm of gradient at iteration 359: 19923.18992512363\n",
      "Norm of gradient at iteration 360: 19827.417116063465\n",
      "Norm of gradient at iteration 361: 19732.1472179406\n",
      "Norm of gradient at iteration 362: 19637.37668646451\n",
      "Norm of gradient at iteration 363: 19543.102023054453\n",
      "Norm of gradient at iteration 364: 19449.319773816427\n",
      "Norm of gradient at iteration 365: 19356.026528549784\n",
      "Norm of gradient at iteration 366: 19263.21891978213\n",
      "Norm of gradient at iteration 367: 19170.893621831958\n",
      "Norm of gradient at iteration 368: 19079.04734989811\n",
      "Norm of gradient at iteration 369: 18987.676859174942\n",
      "Norm of gradient at iteration 370: 18896.77894399293\n",
      "Norm of gradient at iteration 371: 18806.350436983146\n",
      "Norm of gradient at iteration 372: 18716.388208265773\n",
      "Norm of gradient at iteration 373: 18626.889164660995\n",
      "Norm of gradient at iteration 374: 18537.850248922365\n",
      "Norm of gradient at iteration 375: 18449.26843899128\n",
      "Norm of gradient at iteration 376: 18361.140747272453\n",
      "Norm of gradient at iteration 377: 18273.464219929265\n",
      "Norm of gradient at iteration 378: 18186.23593619875\n",
      "Norm of gradient at iteration 379: 18099.453007725457\n",
      "Norm of gradient at iteration 380: 18013.112577913384\n",
      "Norm of gradient at iteration 381: 17927.211821295987\n",
      "Norm of gradient at iteration 382: 17841.74794292292\n",
      "Norm of gradient at iteration 383: 17756.71817776387\n",
      "Norm of gradient at iteration 384: 17672.119790128152\n",
      "Norm of gradient at iteration 385: 17587.950073100164\n",
      "Norm of gradient at iteration 386: 17504.206347989846\n",
      "Norm of gradient at iteration 387: 17420.88596379794\n",
      "Norm of gradient at iteration 388: 17337.98629669543\n",
      "Norm of gradient at iteration 389: 17255.504749516716\n",
      "Norm of gradient at iteration 390: 17173.43875126628\n",
      "Norm of gradient at iteration 391: 17091.785756638325\n",
      "Norm of gradient at iteration 392: 17010.543245548834\n",
      "Norm of gradient at iteration 393: 16929.708722679985\n",
      "Norm of gradient at iteration 394: 16849.2797170364\n",
      "Norm of gradient at iteration 395: 16769.253781512612\n",
      "Norm of gradient at iteration 396: 16689.628492472068\n",
      "Norm of gradient at iteration 397: 16610.401449336434\n",
      "Norm of gradient at iteration 398: 16531.570274185837\n",
      "Norm of gradient at iteration 399: 16453.132611368914\n",
      "Norm of gradient at iteration 400: 16375.08612712279\n",
      "Norm of gradient at iteration 401: 16297.428509202726\n",
      "Norm of gradient at iteration 402: 16220.157466520877\n",
      "Norm of gradient at iteration 403: 16143.270728794052\n",
      "Norm of gradient at iteration 404: 16066.766046200428\n",
      "Norm of gradient at iteration 405: 15990.641189044367\n",
      "Norm of gradient at iteration 406: 15914.893947429679\n",
      "Norm of gradient at iteration 407: 15839.522130940855\n",
      "Norm of gradient at iteration 408: 15764.523568331942\n",
      "Norm of gradient at iteration 409: 15689.896107222961\n",
      "Norm of gradient at iteration 410: 15615.63761380377\n",
      "Norm of gradient at iteration 411: 15541.745972544602\n",
      "Norm of gradient at iteration 412: 15468.219085914057\n",
      "Norm of gradient at iteration 413: 15395.054874103254\n",
      "Norm of gradient at iteration 414: 15322.251274756654\n",
      "Norm of gradient at iteration 415: 15249.806242709383\n",
      "Norm of gradient at iteration 416: 15177.717749730222\n",
      "Norm of gradient at iteration 417: 15105.983784271044\n",
      "Norm of gradient at iteration 418: 15034.602351221574\n",
      "Norm of gradient at iteration 419: 14963.571471669975\n",
      "Norm of gradient at iteration 420: 14892.889182668961\n",
      "Norm of gradient at iteration 421: 14822.553537006936\n",
      "Norm of gradient at iteration 422: 14752.562602984503\n",
      "Norm of gradient at iteration 423: 14682.914464195948\n",
      "Norm of gradient at iteration 424: 14613.60721931539\n",
      "Norm of gradient at iteration 425: 14544.638981887876\n",
      "Norm of gradient at iteration 426: 14476.00788012498\n",
      "Norm of gradient at iteration 427: 14407.712056704744\n",
      "Norm of gradient at iteration 428: 14339.749668576245\n",
      "Norm of gradient at iteration 429: 14272.118886768021\n",
      "Norm of gradient at iteration 430: 14204.817896200932\n",
      "Norm of gradient at iteration 431: 14137.844895504779\n",
      "Norm of gradient at iteration 432: 14071.198096838927\n",
      "Norm of gradient at iteration 433: 14004.875725716556\n",
      "Norm of gradient at iteration 434: 13938.876020832795\n",
      "Norm of gradient at iteration 435: 13873.1972338963\n",
      "Norm of gradient at iteration 436: 13807.837629464339\n",
      "Norm of gradient at iteration 437: 13742.795484781167\n",
      "Norm of gradient at iteration 438: 13678.069089619883\n",
      "Norm of gradient at iteration 439: 13613.656746127339\n",
      "Norm of gradient at iteration 440: 13549.55676867219\n",
      "Norm of gradient at iteration 441: 13485.767483696078\n",
      "Norm of gradient at iteration 442: 13422.287229567652\n",
      "Norm of gradient at iteration 443: 13359.114356439502\n",
      "Norm of gradient at iteration 444: 13296.247226108007\n",
      "Norm of gradient at iteration 445: 13233.684211875772\n",
      "Norm of gradient at iteration 446: 13171.423698416711\n",
      "Norm of gradient at iteration 447: 13109.46408164396\n",
      "Norm of gradient at iteration 448: 13047.803768579943\n",
      "Norm of gradient at iteration 449: 12986.441177229315\n",
      "Norm of gradient at iteration 450: 12925.374736453838\n",
      "Norm of gradient at iteration 451: 12864.602885850169\n",
      "Norm of gradient at iteration 452: 12804.124075629372\n",
      "Norm of gradient at iteration 453: 12743.936766498977\n",
      "Norm of gradient at iteration 454: 12684.039429547018\n",
      "Norm of gradient at iteration 455: 12624.430546128453\n",
      "Norm of gradient at iteration 456: 12565.108607753342\n",
      "Norm of gradient at iteration 457: 12506.0721159773\n",
      "Norm of gradient at iteration 458: 12447.31958229348\n",
      "Norm of gradient at iteration 459: 12388.849528027129\n",
      "Norm of gradient at iteration 460: 12330.660484231441\n",
      "Norm of gradient at iteration 461: 12272.750991585395\n",
      "Norm of gradient at iteration 462: 12215.119600293532\n",
      "Norm of gradient at iteration 463: 12157.764869987355\n",
      "Norm of gradient at iteration 464: 12100.685369628161\n",
      "Norm of gradient at iteration 465: 12043.87967741202\n",
      "Norm of gradient at iteration 466: 11987.346380676048\n",
      "Norm of gradient at iteration 467: 11931.084075806251\n",
      "Norm of gradient at iteration 468: 11875.091368147096\n",
      "Norm of gradient at iteration 469: 11819.36687191225\n",
      "Norm of gradient at iteration 470: 11763.909210097268\n",
      "Norm of gradient at iteration 471: 11708.717014393276\n",
      "Norm of gradient at iteration 472: 11653.788925102263\n",
      "Norm of gradient at iteration 473: 11599.12359105369\n",
      "Norm of gradient at iteration 474: 11544.719669522425\n",
      "Norm of gradient at iteration 475: 11490.575826148062\n",
      "Norm of gradient at iteration 476: 11436.690734855469\n",
      "Norm of gradient at iteration 477: 11383.063077776433\n",
      "Norm of gradient at iteration 478: 11329.69154517289\n",
      "Norm of gradient at iteration 479: 11276.574835360936\n",
      "Norm of gradient at iteration 480: 11223.711654636272\n",
      "Norm of gradient at iteration 481: 11171.100717200756\n",
      "Norm of gradient at iteration 482: 11118.740745089894\n",
      "Norm of gradient at iteration 483: 11066.630468101735\n",
      "Norm of gradient at iteration 484: 11014.768623726506\n",
      "Norm of gradient at iteration 485: 10963.153957077544\n",
      "Norm of gradient at iteration 486: 10911.785220823083\n",
      "Norm of gradient at iteration 487: 10860.661175119167\n",
      "Norm of gradient at iteration 488: 10809.780587543457\n",
      "Norm of gradient at iteration 489: 10759.142233029968\n",
      "Norm of gradient at iteration 490: 10708.74489380502\n",
      "Norm of gradient at iteration 491: 10658.58735932354\n",
      "Norm of gradient at iteration 492: 10608.668426206943\n",
      "Norm of gradient at iteration 493: 10558.986898181485\n",
      "Norm of gradient at iteration 494: 10509.541586017358\n",
      "Norm of gradient at iteration 495: 10460.331307469152\n",
      "Norm of gradient at iteration 496: 10411.354887216621\n",
      "Norm of gradient at iteration 497: 10362.611156806608\n",
      "Norm of gradient at iteration 498: 10314.098954595413\n",
      "Norm of gradient at iteration 499: 10265.817125692476\n",
      "Norm of gradient at iteration 500: 10217.764521904242\n",
      "Norm of gradient at iteration 501: 10169.94000167918\n",
      "Norm of gradient at iteration 502: 10122.34243005333\n",
      "Norm of gradient at iteration 503: 10074.97067859665\n",
      "Norm of gradient at iteration 504: 10027.823625360143\n",
      "Norm of gradient at iteration 505: 9980.900154823446\n",
      "Norm of gradient at iteration 506: 9934.199157843437\n",
      "Norm of gradient at iteration 507: 9887.719531603087\n",
      "Norm of gradient at iteration 508: 9841.460179561342\n",
      "Norm of gradient at iteration 509: 9795.420011403576\n",
      "Norm of gradient at iteration 510: 9749.59794299233\n",
      "Norm of gradient at iteration 511: 9703.992896319207\n",
      "Norm of gradient at iteration 512: 9658.603799456929\n",
      "Norm of gradient at iteration 513: 9613.429586512322\n",
      "Norm of gradient at iteration 514: 9568.469197579516\n",
      "Norm of gradient at iteration 515: 9523.72157869413\n",
      "Norm of gradient at iteration 516: 9479.185681787683\n",
      "Norm of gradient at iteration 517: 9434.860464642723\n",
      "Norm of gradient at iteration 518: 9390.744890848528\n",
      "Norm of gradient at iteration 519: 9346.837929757163\n",
      "Norm of gradient at iteration 520: 9303.138556440339\n",
      "Norm of gradient at iteration 521: 9259.64575164645\n",
      "Norm of gradient at iteration 522: 9216.358501758366\n",
      "Norm of gradient at iteration 523: 9173.275798751694\n",
      "Norm of gradient at iteration 524: 9130.396640153402\n",
      "Norm of gradient at iteration 525: 9087.72002900104\n",
      "Norm of gradient at iteration 526: 9045.244973802308\n",
      "Norm of gradient at iteration 527: 9002.970488495324\n",
      "Norm of gradient at iteration 528: 8960.895592409068\n",
      "Norm of gradient at iteration 529: 8919.01931022434\n",
      "Norm of gradient at iteration 530: 8877.340671935443\n",
      "Norm of gradient at iteration 531: 8835.858712811774\n",
      "Norm of gradient at iteration 532: 8794.572473360382\n",
      "Norm of gradient at iteration 533: 8753.480999288551\n",
      "Norm of gradient at iteration 534: 8712.58334146701\n",
      "Norm of gradient at iteration 535: 8671.878555893443\n",
      "Norm of gradient at iteration 536: 8631.365703656364\n",
      "Norm of gradient at iteration 537: 8591.043850899581\n",
      "Norm of gradient at iteration 538: 8550.912068786882\n",
      "Norm of gradient at iteration 539: 8510.969433466953\n",
      "Norm of gradient at iteration 540: 8471.215026039139\n",
      "Norm of gradient at iteration 541: 8431.64793251901\n",
      "Norm of gradient at iteration 542: 8392.267243804714\n",
      "Norm of gradient at iteration 543: 8353.072055643432\n",
      "Norm of gradient at iteration 544: 8314.061468598375\n",
      "Norm of gradient at iteration 545: 8275.234588015903\n",
      "Norm of gradient at iteration 546: 8236.590523993205\n",
      "Norm of gradient at iteration 547: 8198.12839134614\n",
      "Norm of gradient at iteration 548: 8159.847309577534\n",
      "Norm of gradient at iteration 549: 8121.74640284575\n",
      "Norm of gradient at iteration 550: 8083.824799933454\n",
      "Norm of gradient at iteration 551: 8046.081634216957\n",
      "Norm of gradient at iteration 552: 8008.516043635626\n",
      "Norm of gradient at iteration 553: 7971.127170661749\n",
      "Norm of gradient at iteration 554: 7933.914162270569\n",
      "Norm of gradient at iteration 555: 7896.876169910751\n",
      "Norm of gradient at iteration 556: 7860.012349475054\n",
      "Norm of gradient at iteration 557: 7823.321861271327\n",
      "Norm of gradient at iteration 558: 7786.803869993638\n",
      "Norm of gradient at iteration 559: 7750.457544694065\n",
      "Norm of gradient at iteration 560: 7714.282058754269\n",
      "Norm of gradient at iteration 561: 7678.276589857759\n",
      "Norm of gradient at iteration 562: 7642.440319962016\n",
      "Norm of gradient at iteration 563: 7606.772435271349\n",
      "Norm of gradient at iteration 564: 7571.272126209634\n",
      "Norm of gradient at iteration 565: 7535.93858739337\n",
      "Norm of gradient at iteration 566: 7500.771017605257\n",
      "Norm of gradient at iteration 567: 7465.768619767616\n",
      "Norm of gradient at iteration 568: 7430.930600916393\n",
      "Norm of gradient at iteration 569: 7396.256172175146\n",
      "Norm of gradient at iteration 570: 7361.744548729533\n",
      "Norm of gradient at iteration 571: 7327.394949801777\n",
      "Norm of gradient at iteration 572: 7293.20659862544\n",
      "Norm of gradient at iteration 573: 7259.178722420671\n",
      "Norm of gradient at iteration 574: 7225.310552369179\n",
      "Norm of gradient at iteration 575: 7191.601323589986\n",
      "Norm of gradient at iteration 576: 7158.050275114942\n",
      "Norm of gradient at iteration 577: 7124.656649864738\n",
      "Norm of gradient at iteration 578: 7091.419694625004\n",
      "Norm of gradient at iteration 579: 7058.338660022614\n",
      "Norm of gradient at iteration 580: 7025.412800502331\n",
      "Norm of gradient at iteration 581: 6992.641374303478\n",
      "Norm of gradient at iteration 582: 6960.023643436959\n",
      "Norm of gradient at iteration 583: 6927.5588736623395\n",
      "Norm of gradient at iteration 584: 6895.246334465192\n",
      "Norm of gradient at iteration 585: 6863.085299034766\n",
      "Norm of gradient at iteration 586: 6831.075044241583\n",
      "Norm of gradient at iteration 587: 6799.214850615429\n",
      "Norm of gradient at iteration 588: 6767.504002323437\n",
      "Norm of gradient at iteration 589: 6735.941787148441\n",
      "Norm of gradient at iteration 590: 6704.527496467376\n",
      "Norm of gradient at iteration 591: 6673.260425229999\n",
      "Norm of gradient at iteration 592: 6642.13987193771\n",
      "Norm of gradient at iteration 593: 6611.165138622516\n",
      "Norm of gradient at iteration 594: 6580.33553082632\n",
      "Norm of gradient at iteration 595: 6549.650357580098\n",
      "Norm of gradient at iteration 596: 6519.10893138363\n",
      "Norm of gradient at iteration 597: 6488.710568185081\n",
      "Norm of gradient at iteration 598: 6458.454587360863\n",
      "Norm of gradient at iteration 599: 6428.340311695605\n",
      "Norm of gradient at iteration 600: 6398.367067362489\n",
      "Norm of gradient at iteration 601: 6368.534183903366\n",
      "Norm of gradient at iteration 602: 6338.84099420949\n",
      "Norm of gradient at iteration 603: 6309.286834501981\n",
      "Norm of gradient at iteration 604: 6279.871044312652\n",
      "Norm of gradient at iteration 605: 6250.5929664651185\n",
      "Norm of gradient at iteration 606: 6221.451947055664\n",
      "Norm of gradient at iteration 607: 6192.447335434716\n",
      "Norm of gradient at iteration 608: 6163.57848418808\n",
      "Norm of gradient at iteration 609: 6134.844749118551\n",
      "Norm of gradient at iteration 610: 6106.245489227661\n",
      "Norm of gradient at iteration 611: 6077.780066697332\n",
      "Norm of gradient at iteration 612: 6049.447846872035\n",
      "Norm of gradient at iteration 613: 6021.2481982407335\n",
      "Norm of gradient at iteration 614: 5993.180492419205\n",
      "Norm of gradient at iteration 615: 5965.244104132443\n",
      "Norm of gradient at iteration 616: 5937.438411197076\n",
      "Norm of gradient at iteration 617: 5909.762794504081\n",
      "Norm of gradient at iteration 618: 5882.216638001505\n",
      "Norm of gradient at iteration 619: 5854.799328677411\n",
      "Norm of gradient at iteration 620: 5827.510256542833\n",
      "Norm of gradient at iteration 621: 5800.348814615018\n",
      "Norm of gradient at iteration 622: 5773.314398900613\n",
      "Norm of gradient at iteration 623: 5746.406408379069\n",
      "Norm of gradient at iteration 624: 5719.624244986315\n",
      "Norm of gradient at iteration 625: 5692.967313598175\n",
      "Norm of gradient at iteration 626: 5666.435022014258\n",
      "Norm of gradient at iteration 627: 5640.026780941852\n",
      "Norm of gradient at iteration 628: 5613.7420039797835\n",
      "Norm of gradient at iteration 629: 5587.5801076027465\n",
      "Norm of gradient at iteration 630: 5561.540511145305\n",
      "Norm of gradient at iteration 631: 5535.622636786404\n",
      "Norm of gradient at iteration 632: 5509.825909533667\n",
      "Norm of gradient at iteration 633: 5484.149757208089\n",
      "Norm of gradient at iteration 634: 5458.59361042861\n",
      "Norm of gradient at iteration 635: 5433.156902596944\n",
      "Norm of gradient at iteration 636: 5407.83906988249\n",
      "Norm of gradient at iteration 637: 5382.639551207204\n",
      "Norm of gradient at iteration 638: 5357.5577882308435\n",
      "Norm of gradient at iteration 639: 5332.5932253360625\n",
      "Norm of gradient at iteration 640: 5307.745309613761\n",
      "Norm of gradient at iteration 641: 5283.0134908484415\n",
      "Norm of gradient at iteration 642: 5258.397221503816\n",
      "Norm of gradient at iteration 643: 5233.895956708262\n",
      "Norm of gradient at iteration 644: 5209.509154240661\n",
      "Norm of gradient at iteration 645: 5185.236274516124\n",
      "Norm of gradient at iteration 646: 5161.076780571915\n",
      "Norm of gradient at iteration 647: 5137.030138053418\n",
      "Norm of gradient at iteration 648: 5113.095815200232\n",
      "Norm of gradient at iteration 649: 5089.273282832414\n",
      "Norm of gradient at iteration 650: 5065.56201433668\n",
      "Norm of gradient at iteration 651: 5041.961485652791\n",
      "Norm of gradient at iteration 652: 5018.471175260009\n",
      "Norm of gradient at iteration 653: 4995.090564163623\n",
      "Norm of gradient at iteration 654: 4971.819135881727\n",
      "Norm of gradient at iteration 655: 4948.656376431677\n",
      "Norm of gradient at iteration 656: 4925.6017743172\n",
      "Norm of gradient at iteration 657: 4902.654820515036\n",
      "Norm of gradient at iteration 658: 4879.815008462169\n",
      "Norm of gradient at iteration 659: 4857.081834042639\n",
      "Norm of gradient at iteration 660: 4834.454795574979\n",
      "Norm of gradient at iteration 661: 4811.9333937991505\n",
      "Norm of gradient at iteration 662: 4789.517131864167\n",
      "Norm of gradient at iteration 663: 4767.205515315214\n",
      "Norm of gradient at iteration 664: 4744.998052081455\n",
      "Norm of gradient at iteration 665: 4722.89425246322\n",
      "Norm of gradient at iteration 666: 4700.8936291200025\n",
      "Norm of gradient at iteration 667: 4678.995697057951\n",
      "Norm of gradient at iteration 668: 4657.199973617749\n",
      "Norm of gradient at iteration 669: 4635.505978462552\n",
      "Norm of gradient at iteration 670: 4613.9132335658405\n",
      "Norm of gradient at iteration 671: 4592.421263199546\n",
      "Norm of gradient at iteration 672: 4571.029593922091\n",
      "Norm of gradient at iteration 673: 4549.737754566584\n",
      "Norm of gradient at iteration 674: 4528.545276229142\n",
      "Norm of gradient at iteration 675: 4507.451692257197\n",
      "Norm of gradient at iteration 676: 4486.456538237731\n",
      "Norm of gradient at iteration 677: 4465.5593519861\n",
      "Norm of gradient at iteration 678: 4444.759673534277\n",
      "Norm of gradient at iteration 679: 4424.05704511955\n",
      "Norm of gradient at iteration 680: 4403.451011173332\n",
      "Norm of gradient at iteration 681: 4382.941118309693\n",
      "Norm of gradient at iteration 682: 4362.526915314495\n",
      "Norm of gradient at iteration 683: 4342.207953133987\n",
      "Norm of gradient at iteration 684: 4321.98378486394\n",
      "Norm of gradient at iteration 685: 4301.85396573861\n",
      "Norm of gradient at iteration 686: 4281.818053119923\n",
      "Norm of gradient at iteration 687: 4261.875606486512\n",
      "Norm of gradient at iteration 688: 4242.026187423118\n",
      "Norm of gradient at iteration 689: 4222.269359609665\n",
      "Norm of gradient at iteration 690: 4202.604688810857\n",
      "Norm of gradient at iteration 691: 4183.031742865387\n",
      "Norm of gradient at iteration 692: 4163.550091675557\n",
      "Norm of gradient at iteration 693: 4144.159307196823\n",
      "Norm of gradient at iteration 694: 4124.858963427372\n",
      "Norm of gradient at iteration 695: 4105.64863639775\n",
      "Norm of gradient at iteration 696: 4086.5279041607114\n",
      "Norm of gradient at iteration 697: 4067.4963467809375\n",
      "Norm of gradient at iteration 698: 4048.5535463248893\n",
      "Norm of gradient at iteration 699: 4029.6990868508174\n",
      "Norm of gradient at iteration 700: 4010.932554398602\n",
      "Norm of gradient at iteration 701: 3992.253536979882\n",
      "Norm of gradient at iteration 702: 3973.6616245680657\n",
      "Norm of gradient at iteration 703: 3955.156409088682\n",
      "Norm of gradient at iteration 704: 3936.7374844092956\n",
      "Norm of gradient at iteration 705: 3918.4044463299815\n",
      "Norm of gradient at iteration 706: 3900.156892573607\n",
      "Norm of gradient at iteration 707: 3881.9944227762044\n",
      "Norm of gradient at iteration 708: 3863.916638477367\n",
      "Norm of gradient at iteration 709: 3845.9231431107573\n",
      "Norm of gradient at iteration 710: 3828.013541994685\n",
      "Norm of gradient at iteration 711: 3810.187442322679\n",
      "Norm of gradient at iteration 712: 3792.444453154164\n",
      "Norm of gradient at iteration 713: 3774.784185405113\n",
      "Norm of gradient at iteration 714: 3757.2062518388407\n",
      "Norm of gradient at iteration 715: 3739.710267056891\n",
      "Norm of gradient at iteration 716: 3722.2958474897546\n",
      "Norm of gradient at iteration 717: 3704.962611387879\n",
      "Norm of gradient at iteration 718: 3687.7101788125938\n",
      "Norm of gradient at iteration 719: 3670.538171627223\n",
      "Norm of gradient at iteration 720: 3653.446213488014\n",
      "Norm of gradient at iteration 721: 3636.433929835383\n",
      "Norm of gradient at iteration 722: 3619.5009478850375\n",
      "Norm of gradient at iteration 723: 3602.6468966190823\n",
      "Norm of gradient at iteration 724: 3585.871406777609\n",
      "Norm of gradient at iteration 725: 3569.174110849592\n",
      "Norm of gradient at iteration 726: 3552.554643064586\n",
      "Norm of gradient at iteration 727: 3536.012639383991\n",
      "Norm of gradient at iteration 728: 3519.547737492532\n",
      "Norm of gradient at iteration 729: 3503.159576789806\n",
      "Norm of gradient at iteration 730: 3486.8477983818325\n",
      "Norm of gradient at iteration 731: 3470.612045072635\n",
      "Norm of gradient at iteration 732: 3454.4519613558828\n",
      "Norm of gradient at iteration 733: 3438.3671934066097\n",
      "Norm of gradient at iteration 734: 3422.357389072909\n",
      "Norm of gradient at iteration 735: 3406.422197867892\n",
      "Norm of gradient at iteration 736: 3390.561270961244\n",
      "Norm of gradient at iteration 737: 3374.7742611713625\n",
      "Norm of gradient at iteration 738: 3359.0608229571003\n",
      "Norm of gradient at iteration 739: 3343.4206124098064\n",
      "Norm of gradient at iteration 740: 3327.8532872453966\n",
      "Norm of gradient at iteration 741: 3312.3585067962604\n",
      "Norm of gradient at iteration 742: 3296.9359320034628\n",
      "Norm of gradient at iteration 743: 3281.5852254088836\n",
      "Norm of gradient at iteration 744: 3266.3060511473263\n",
      "Norm of gradient at iteration 745: 3251.0980749388327\n",
      "Norm of gradient at iteration 746: 3235.9609640809326\n",
      "Norm of gradient at iteration 747: 3220.894387440884\n",
      "Norm of gradient at iteration 748: 3205.898015448067\n",
      "Norm of gradient at iteration 749: 3190.9715200864\n",
      "Norm of gradient at iteration 750: 3176.1145748867225\n",
      "Norm of gradient at iteration 751: 3161.3268549193413\n",
      "Norm of gradient at iteration 752: 3146.6080367864756\n",
      "Norm of gradient at iteration 753: 3131.9577986147765\n",
      "Norm of gradient at iteration 754: 3117.375820048061\n",
      "Norm of gradient at iteration 755: 3102.861782239802\n",
      "Norm of gradient at iteration 756: 3088.415367845907\n",
      "Norm of gradient at iteration 757: 3074.0362610173215\n",
      "Norm of gradient at iteration 758: 3059.724147392861\n",
      "Norm of gradient at iteration 759: 3045.478714091971\n",
      "Norm of gradient at iteration 760: 3031.2996497075455\n",
      "Norm of gradient at iteration 761: 3017.186644298816\n",
      "Norm of gradient at iteration 762: 3003.139389384255\n",
      "Norm of gradient at iteration 763: 2989.157577934442\n",
      "Norm of gradient at iteration 764: 2975.2409043651546\n",
      "Norm of gradient at iteration 765: 2961.3890645303136\n",
      "Norm of gradient at iteration 766: 2947.601755715015\n",
      "Norm of gradient at iteration 767: 2933.878676628677\n",
      "Norm of gradient at iteration 768: 2920.2195273980687\n",
      "Norm of gradient at iteration 769: 2906.6240095606304\n",
      "Norm of gradient at iteration 770: 2893.0918260575017\n",
      "Norm of gradient at iteration 771: 2879.622681226835\n",
      "Norm of gradient at iteration 772: 2866.2162807970635\n",
      "Norm of gradient at iteration 773: 2852.8723318801385\n",
      "Norm of gradient at iteration 774: 2839.590542964965\n",
      "Norm of gradient at iteration 775: 2826.3706239106923\n",
      "Norm of gradient at iteration 776: 2813.2122859401475\n",
      "Norm of gradient at iteration 777: 2800.1152416332557\n",
      "Norm of gradient at iteration 778: 2787.07920492058\n",
      "Norm of gradient at iteration 779: 2774.1038910767206\n",
      "Norm of gradient at iteration 780: 2761.1890167138695\n",
      "Norm of gradient at iteration 781: 2748.33429977564\n",
      "Norm of gradient at iteration 782: 2735.539459530161\n",
      "Norm of gradient at iteration 783: 2722.8042165642164\n",
      "Norm of gradient at iteration 784: 2710.1282927766824\n",
      "Norm of gradient at iteration 785: 2697.511411372251\n",
      "Norm of gradient at iteration 786: 2684.9532968551384\n",
      "Norm of gradient at iteration 787: 2672.453675022968\n",
      "Norm of gradient at iteration 788: 2660.0122729604745\n",
      "Norm of gradient at iteration 789: 2647.62881903339\n",
      "Norm of gradient at iteration 790: 2635.3030428822294\n",
      "Norm of gradient at iteration 791: 2623.034675416304\n",
      "Norm of gradient at iteration 792: 2610.823448807527\n",
      "Norm of gradient at iteration 793: 2598.6690964844756\n",
      "Norm of gradient at iteration 794: 2586.5713531263164\n",
      "Norm of gradient at iteration 795: 2574.5299546568926\n",
      "Norm of gradient at iteration 796: 2562.544638238587\n",
      "Norm of gradient at iteration 797: 2550.6151422667526\n",
      "Norm of gradient at iteration 798: 2538.741206363427\n",
      "Norm of gradient at iteration 799: 2526.9225713717515\n",
      "Norm of gradient at iteration 800: 2515.1589793500293\n",
      "Norm of gradient at iteration 801: 2503.450173565917\n",
      "Norm of gradient at iteration 802: 2491.795898490687\n",
      "Norm of gradient at iteration 803: 2480.1958997935426\n",
      "Norm of gradient at iteration 804: 2468.649924335698\n",
      "Norm of gradient at iteration 805: 2457.157720165037\n",
      "Norm of gradient at iteration 806: 2445.7190365100387\n",
      "Norm of gradient at iteration 807: 2434.3336237745098\n",
      "Norm of gradient at iteration 808: 2423.0012335317847\n",
      "Norm of gradient at iteration 809: 2411.721618519291\n",
      "Norm of gradient at iteration 810: 2400.4945326328125\n",
      "Norm of gradient at iteration 811: 2389.319730921184\n",
      "Norm of gradient at iteration 812: 2378.196969580617\n",
      "Norm of gradient at iteration 813: 2367.126005949495\n",
      "Norm of gradient at iteration 814: 2356.106598502581\n",
      "Norm of gradient at iteration 815: 2345.138506845953\n",
      "Norm of gradient at iteration 816: 2334.221491711436\n",
      "Norm of gradient at iteration 817: 2323.355314951335\n",
      "Norm of gradient at iteration 818: 2312.539739533021\n",
      "Norm of gradient at iteration 819: 2301.774529533678\n",
      "Norm of gradient at iteration 820: 2291.059450135145\n",
      "Norm of gradient at iteration 821: 2280.39426761842\n",
      "Norm of gradient at iteration 822: 2269.7787493587384\n",
      "Norm of gradient at iteration 823: 2259.212663820043\n",
      "Norm of gradient at iteration 824: 2248.695780550206\n",
      "Norm of gradient at iteration 825: 2238.22787017554\n",
      "Norm of gradient at iteration 826: 2227.80870439584\n",
      "Norm of gradient at iteration 827: 2217.4380559793285\n",
      "Norm of gradient at iteration 828: 2207.115698757486\n",
      "Norm of gradient at iteration 829: 2196.8414076201343\n",
      "Norm of gradient at iteration 830: 2186.614958510242\n",
      "Norm of gradient at iteration 831: 2176.4361284191195\n",
      "Norm of gradient at iteration 832: 2166.304695381365\n",
      "Norm of gradient at iteration 833: 2156.2204384699103\n",
      "Norm of gradient at iteration 834: 2146.1831377910994\n",
      "Norm of gradient at iteration 835: 2136.1925744798637\n",
      "Norm of gradient at iteration 836: 2126.2485306947915\n",
      "Norm of gradient at iteration 837: 2116.350789613298\n",
      "Norm of gradient at iteration 838: 2106.4991354268277\n",
      "Norm of gradient at iteration 839: 2096.693353336001\n",
      "Norm of gradient at iteration 840: 2086.933229545882\n",
      "Norm of gradient at iteration 841: 2077.218551261253\n",
      "Norm of gradient at iteration 842: 2067.549106681816\n",
      "Norm of gradient at iteration 843: 2057.924684997558\n",
      "Norm of gradient at iteration 844: 2048.345076384056\n",
      "Norm of gradient at iteration 845: 2038.810071997707\n",
      "Norm of gradient at iteration 846: 2029.319463971296\n",
      "Norm of gradient at iteration 847: 2019.8730454092222\n",
      "Norm of gradient at iteration 848: 2010.4706103830235\n",
      "Norm of gradient at iteration 849: 2001.1119539266617\n",
      "Norm of gradient at iteration 850: 1991.7968720321492\n",
      "Norm of gradient at iteration 851: 1982.5251616448543\n",
      "Norm of gradient at iteration 852: 1973.2966206591714\n",
      "Norm of gradient at iteration 853: 1964.1110479139468\n",
      "Norm of gradient at iteration 854: 1954.9682431879985\n",
      "Norm of gradient at iteration 855: 1945.8680071957313\n",
      "Norm of gradient at iteration 856: 1936.810141582712\n",
      "Norm of gradient at iteration 857: 1927.794448921303\n",
      "Norm of gradient at iteration 858: 1918.8207327061878\n",
      "Norm of gradient at iteration 859: 1909.8887973501553\n",
      "Norm of gradient at iteration 860: 1900.998448179741\n",
      "Norm of gradient at iteration 861: 1892.1494914308416\n",
      "Norm of gradient at iteration 862: 1883.3417342444877\n",
      "Norm of gradient at iteration 863: 1874.574984662581\n",
      "Norm of gradient at iteration 864: 1865.8490516236127\n",
      "Norm of gradient at iteration 865: 1857.1637449584948\n",
      "Norm of gradient at iteration 866: 1848.5188753863154\n",
      "Norm of gradient at iteration 867: 1839.9142545101654\n",
      "Norm of gradient at iteration 868: 1831.3496948129816\n",
      "Norm of gradient at iteration 869: 1822.8250096534157\n",
      "Norm of gradient at iteration 870: 1814.3400132616437\n",
      "Norm of gradient at iteration 871: 1805.8945207353743\n",
      "Norm of gradient at iteration 872: 1797.4883480356607\n",
      "Norm of gradient at iteration 873: 1789.1213119828917\n",
      "Norm of gradient at iteration 874: 1780.7932302527265\n",
      "Norm of gradient at iteration 875: 1772.5039213721573\n",
      "Norm of gradient at iteration 876: 1764.253204715328\n",
      "Norm of gradient at iteration 877: 1756.0409004997007\n",
      "Norm of gradient at iteration 878: 1747.8668297820716\n",
      "Norm of gradient at iteration 879: 1739.7308144545257\n",
      "Norm of gradient at iteration 880: 1731.6326772405896\n",
      "Norm of gradient at iteration 881: 1723.5722416913582\n",
      "Norm of gradient at iteration 882: 1715.549332181511\n",
      "Norm of gradient at iteration 883: 1707.5637739054173\n",
      "Norm of gradient at iteration 884: 1699.6153928735596\n",
      "Norm of gradient at iteration 885: 1691.7040159082392\n",
      "Norm of gradient at iteration 886: 1683.8294706401998\n",
      "Norm of gradient at iteration 887: 1675.9915855045358\n",
      "Norm of gradient at iteration 888: 1668.1901897370137\n",
      "Norm of gradient at iteration 889: 1660.4251133703967\n",
      "Norm of gradient at iteration 890: 1652.6961872305585\n",
      "Norm of gradient at iteration 891: 1645.0032429328264\n",
      "Norm of gradient at iteration 892: 1637.3461128782726\n",
      "Norm of gradient at iteration 893: 1629.7246302500482\n",
      "Norm of gradient at iteration 894: 1622.1386290096398\n",
      "Norm of gradient at iteration 895: 1614.5879438932336\n",
      "Norm of gradient at iteration 896: 1607.072410408191\n",
      "Norm of gradient at iteration 897: 1599.5918648292836\n",
      "Norm of gradient at iteration 898: 1592.1461441951496\n",
      "Norm of gradient at iteration 899: 1584.7350863047525\n",
      "Norm of gradient at iteration 900: 1577.358529713696\n",
      "Norm of gradient at iteration 901: 1570.0163137308218\n",
      "Norm of gradient at iteration 902: 1562.7082784145641\n",
      "Norm of gradient at iteration 903: 1555.4342645694614\n",
      "Norm of gradient at iteration 904: 1548.1941137426988\n",
      "Norm of gradient at iteration 905: 1540.9876682205231\n",
      "Norm of gradient at iteration 906: 1533.8147710249602\n",
      "Norm of gradient at iteration 907: 1526.6752659102135\n",
      "Norm of gradient at iteration 908: 1519.568997359167\n",
      "Norm of gradient at iteration 909: 1512.495810580201\n",
      "Norm of gradient at iteration 910: 1505.4555515035438\n",
      "Norm of gradient at iteration 911: 1498.4480667781559\n",
      "Norm of gradient at iteration 912: 1491.4732037680437\n",
      "Norm of gradient at iteration 913: 1484.5308105491927\n",
      "Norm of gradient at iteration 914: 1477.6207359060377\n",
      "Norm of gradient at iteration 915: 1470.7428293282737\n",
      "Norm of gradient at iteration 916: 1463.896941007453\n",
      "Norm of gradient at iteration 917: 1457.0829218337112\n",
      "Norm of gradient at iteration 918: 1450.300623392627\n",
      "Norm of gradient at iteration 919: 1443.5498979617278\n",
      "Norm of gradient at iteration 920: 1436.8305985074892\n",
      "Norm of gradient at iteration 921: 1430.1425786819193\n",
      "Norm of gradient at iteration 922: 1423.4856928194718\n",
      "Norm of gradient at iteration 923: 1416.8597959337792\n",
      "Norm of gradient at iteration 924: 1410.2647437144815\n",
      "Norm of gradient at iteration 925: 1403.700392524117\n",
      "Norm of gradient at iteration 926: 1397.1665993949266\n",
      "Norm of gradient at iteration 927: 1390.6632220256458\n",
      "Norm of gradient at iteration 928: 1384.1901187786054\n",
      "Norm of gradient at iteration 929: 1377.7471486762897\n",
      "Norm of gradient at iteration 930: 1371.334171398623\n",
      "Norm of gradient at iteration 931: 1364.9510472795675\n",
      "Norm of gradient at iteration 932: 1358.5976373042763\n",
      "Norm of gradient at iteration 933: 1352.2738031059152\n",
      "Norm of gradient at iteration 934: 1345.9794069627512\n",
      "Norm of gradient at iteration 935: 1339.7143117949763\n",
      "Norm of gradient at iteration 936: 1333.4783811619077\n",
      "Norm of gradient at iteration 937: 1327.2714792587456\n",
      "Norm of gradient at iteration 938: 1321.0934709138926\n",
      "Norm of gradient at iteration 939: 1314.9442215857105\n",
      "Norm of gradient at iteration 940: 1308.8235973596861\n",
      "Norm of gradient at iteration 941: 1302.731464945645\n",
      "Norm of gradient at iteration 942: 1296.6676916745575\n",
      "Norm of gradient at iteration 943: 1290.6321454958247\n",
      "Norm of gradient at iteration 944: 1284.6246949743593\n",
      "Norm of gradient at iteration 945: 1278.6452092876405\n",
      "Norm of gradient at iteration 946: 1272.6935582228587\n",
      "Norm of gradient at iteration 947: 1266.7696121741687\n",
      "Norm of gradient at iteration 948: 1260.8732421396744\n",
      "Norm of gradient at iteration 949: 1255.0043197188486\n",
      "Norm of gradient at iteration 950: 1249.1627171094408\n",
      "Norm of gradient at iteration 951: 1243.3483071048702\n",
      "Norm of gradient at iteration 952: 1237.5609630914737\n",
      "Norm of gradient at iteration 953: 1231.8005590454713\n",
      "Norm of gradient at iteration 954: 1226.0669695305317\n",
      "Norm of gradient at iteration 955: 1220.3600696948195\n",
      "Norm of gradient at iteration 956: 1214.6797352683718\n",
      "Norm of gradient at iteration 957: 1209.0258425602465\n",
      "Norm of gradient at iteration 958: 1203.3982684559817\n",
      "Norm of gradient at iteration 959: 1197.796890414787\n",
      "Norm of gradient at iteration 960: 1192.2215864668995\n",
      "Norm of gradient at iteration 961: 1186.6722352109061\n",
      "Norm of gradient at iteration 962: 1181.1487158111377\n",
      "Norm of gradient at iteration 963: 1175.650907994893\n",
      "Norm of gradient at iteration 964: 1170.178692049969\n",
      "Norm of gradient at iteration 965: 1164.7319488219398\n",
      "Norm of gradient at iteration 966: 1159.310559711618\n",
      "Norm of gradient at iteration 967: 1153.9144066723907\n",
      "Norm of gradient at iteration 968: 1148.543372207647\n",
      "Norm of gradient at iteration 969: 1143.1973393682479\n",
      "Norm of gradient at iteration 970: 1137.876191749986\n",
      "Norm of gradient at iteration 971: 1132.579813491039\n",
      "Norm of gradient at iteration 972: 1127.3080892692565\n",
      "Norm of gradient at iteration 973: 1122.0609042999517\n",
      "Norm of gradient at iteration 974: 1116.83814433315\n",
      "Norm of gradient at iteration 975: 1111.639695651158\n",
      "Norm of gradient at iteration 976: 1106.4654450661023\n",
      "Norm of gradient at iteration 977: 1101.3152799174754\n",
      "Norm of gradient at iteration 978: 1096.1890880695946\n",
      "Norm of gradient at iteration 979: 1091.0867579091982\n",
      "Norm of gradient at iteration 980: 1086.0081783430437\n",
      "Norm of gradient at iteration 981: 1080.9532387953986\n",
      "Norm of gradient at iteration 982: 1075.9218292057053\n",
      "Norm of gradient at iteration 983: 1070.9138400260274\n",
      "Norm of gradient at iteration 984: 1065.9291622189714\n",
      "Norm of gradient at iteration 985: 1060.9676872548725\n",
      "Norm of gradient at iteration 986: 1056.0293071097872\n",
      "Norm of gradient at iteration 987: 1051.1139142629268\n",
      "Norm of gradient at iteration 988: 1046.221401694435\n",
      "Norm of gradient at iteration 989: 1041.351662882956\n",
      "Norm of gradient at iteration 990: 1036.504591803325\n",
      "Norm of gradient at iteration 991: 1031.6800829242661\n",
      "Norm of gradient at iteration 992: 1026.8780312061535\n",
      "Norm of gradient at iteration 993: 1022.0983320985792\n",
      "Norm of gradient at iteration 994: 1017.3408815381541\n",
      "Norm of gradient at iteration 995: 1012.6055759463078\n",
      "Norm of gradient at iteration 996: 1007.8923122268228\n",
      "Norm of gradient at iteration 997: 1003.2009877637857\n",
      "Norm of gradient at iteration 998: 998.5315004191957\n",
      "Norm of gradient at iteration 999: 993.8837485308946\n",
      "Norm of gradient at iteration 1000: 989.2576309101341\n",
      "Norm of gradient at iteration 1001: 984.6530468396251\n",
      "Norm of gradient at iteration 1002: 980.0698960711044\n",
      "Norm of gradient at iteration 1003: 975.508078823231\n",
      "Norm of gradient at iteration 1004: 970.9674957794872\n",
      "Norm of gradient at iteration 1005: 966.4480480858833\n",
      "Norm of gradient at iteration 1006: 961.9496373488948\n",
      "Norm of gradient at iteration 1007: 957.4721656332343\n",
      "Norm of gradient at iteration 1008: 953.0155354598226\n",
      "Norm of gradient at iteration 1009: 948.5796498034787\n",
      "Norm of gradient at iteration 1010: 944.1644120910388\n",
      "Norm of gradient at iteration 1011: 939.7697261990621\n",
      "Norm of gradient at iteration 1012: 935.3954964518275\n",
      "Norm of gradient at iteration 1013: 931.0416276191733\n",
      "Norm of gradient at iteration 1014: 926.7080249144926\n",
      "Norm of gradient at iteration 1015: 922.3945939925961\n",
      "Norm of gradient at iteration 1016: 918.1012409477552\n",
      "Norm of gradient at iteration 1017: 913.8278723115245\n",
      "Norm of gradient at iteration 1018: 909.5743950507856\n",
      "Norm of gradient at iteration 1019: 905.3407165656806\n",
      "Norm of gradient at iteration 1020: 901.1267446876328\n",
      "Norm of gradient at iteration 1021: 896.9323876772498\n",
      "Norm of gradient at iteration 1022: 892.7575542224884\n",
      "Norm of gradient at iteration 1023: 888.6021534364389\n",
      "Norm of gradient at iteration 1024: 884.4660948555508\n",
      "Norm of gradient at iteration 1025: 880.3492884374505\n",
      "Norm of gradient at iteration 1026: 876.2516445592387\n",
      "Norm of gradient at iteration 1027: 872.1730740152562\n",
      "Norm of gradient at iteration 1028: 868.1134880153295\n",
      "Norm of gradient at iteration 1029: 864.0727981827486\n",
      "Norm of gradient at iteration 1030: 860.0509165524246\n",
      "Norm of gradient at iteration 1031: 856.0477555688278\n",
      "Norm of gradient at iteration 1032: 852.0632280841986\n",
      "Norm of gradient at iteration 1033: 848.0972473566286\n",
      "Norm of gradient at iteration 1034: 844.1497270480768\n",
      "Norm of gradient at iteration 1035: 840.2205812226312\n",
      "Norm of gradient at iteration 1036: 836.3097243445015\n",
      "Norm of gradient at iteration 1037: 832.4170712763145\n",
      "Norm of gradient at iteration 1038: 828.5425372770314\n",
      "Norm of gradient at iteration 1039: 824.6860380002261\n",
      "Norm of gradient at iteration 1040: 820.8474894923744\n",
      "Norm of gradient at iteration 1041: 817.0268081907666\n",
      "Norm of gradient at iteration 1042: 813.2239109218341\n",
      "Norm of gradient at iteration 1043: 809.4387148992913\n",
      "Norm of gradient at iteration 1044: 805.6711377224246\n",
      "Norm of gradient at iteration 1045: 801.9210973741674\n",
      "Norm of gradient at iteration 1046: 798.1885122193637\n",
      "Norm of gradient at iteration 1047: 794.4733010029845\n",
      "Norm of gradient at iteration 1048: 790.7753828483757\n",
      "Norm of gradient at iteration 1049: 787.0946772554685\n",
      "Norm of gradient at iteration 1050: 783.4311040990552\n",
      "Norm of gradient at iteration 1051: 779.7845836269425\n",
      "Norm of gradient at iteration 1052: 776.1550364584327\n",
      "Norm of gradient at iteration 1053: 772.5423835823375\n",
      "Norm of gradient at iteration 1054: 768.9465463553412\n",
      "Norm of gradient at iteration 1055: 765.367446500445\n",
      "Norm of gradient at iteration 1056: 761.80500610505\n",
      "Norm of gradient at iteration 1057: 758.2591476193285\n",
      "Norm of gradient at iteration 1058: 754.7297938545106\n",
      "Norm of gradient at iteration 1059: 751.2168679813707\n",
      "Norm of gradient at iteration 1060: 747.7202935282259\n",
      "Norm of gradient at iteration 1061: 744.2399943795833\n",
      "Norm of gradient at iteration 1062: 740.7758947743665\n",
      "Norm of gradient at iteration 1063: 737.3279193042072\n",
      "Norm of gradient at iteration 1064: 733.8959929118035\n",
      "Norm of gradient at iteration 1065: 730.4800408893886\n",
      "Norm of gradient at iteration 1066: 727.0799888770257\n",
      "Norm of gradient at iteration 1067: 723.6957628610177\n",
      "Norm of gradient at iteration 1068: 720.3272891722523\n",
      "Norm of gradient at iteration 1069: 716.9744944845955\n",
      "Norm of gradient at iteration 1070: 713.6373058134484\n",
      "Norm of gradient at iteration 1071: 710.3156505138104\n",
      "Norm of gradient at iteration 1072: 707.0094562791136\n",
      "Norm of gradient at iteration 1073: 703.7186511393572\n",
      "Norm of gradient at iteration 1074: 700.4431634596652\n",
      "Norm of gradient at iteration 1075: 697.1829219386036\n",
      "Norm of gradient at iteration 1076: 693.9378556067686\n",
      "Norm of gradient at iteration 1077: 690.7078938252234\n",
      "Norm of gradient at iteration 1078: 687.4929662838574\n",
      "Norm of gradient at iteration 1079: 684.2930029999487\n",
      "Norm of gradient at iteration 1080: 681.1079343165321\n",
      "Norm of gradient at iteration 1081: 677.9376909010662\n",
      "Norm of gradient at iteration 1082: 674.782203743702\n",
      "Norm of gradient at iteration 1083: 671.6414041559722\n",
      "Norm of gradient at iteration 1084: 668.515223769138\n",
      "Norm of gradient at iteration 1085: 665.4035945328286\n",
      "Norm of gradient at iteration 1086: 662.306448713413\n",
      "Norm of gradient at iteration 1087: 659.2237188927049\n",
      "Norm of gradient at iteration 1088: 656.1553379663397\n",
      "Norm of gradient at iteration 1089: 653.1012391424333\n",
      "Norm of gradient at iteration 1090: 650.061355939972\n",
      "Norm of gradient at iteration 1091: 647.0356221874953\n",
      "Norm of gradient at iteration 1092: 644.0239720216949\n",
      "Norm of gradient at iteration 1093: 641.0263398857443\n",
      "Norm of gradient at iteration 1094: 638.0426605281348\n",
      "Norm of gradient at iteration 1095: 635.0728690011395\n",
      "Norm of gradient at iteration 1096: 632.1169006593543\n",
      "Norm of gradient at iteration 1097: 629.174691158381\n",
      "Norm of gradient at iteration 1098: 626.2461764533512\n",
      "Norm of gradient at iteration 1099: 623.3312927975954\n",
      "Norm of gradient at iteration 1100: 620.4299767412007\n",
      "Norm of gradient at iteration 1101: 617.5421651296199\n",
      "Norm of gradient at iteration 1102: 614.6677951023802\n",
      "Norm of gradient at iteration 1103: 611.8068040916155\n",
      "Norm of gradient at iteration 1104: 608.9591298207934\n",
      "Norm of gradient at iteration 1105: 606.1247103032148\n",
      "Norm of gradient at iteration 1106: 603.3034838408781\n",
      "Norm of gradient at iteration 1107: 600.495389022934\n",
      "Norm of gradient at iteration 1108: 597.7003647244409\n",
      "Norm of gradient at iteration 1109: 594.9183501050485\n",
      "Norm of gradient at iteration 1110: 592.149284607655\n",
      "Norm of gradient at iteration 1111: 589.3931079570227\n",
      "Norm of gradient at iteration 1112: 586.6497601585521\n",
      "Norm of gradient at iteration 1113: 583.9191814969497\n",
      "Norm of gradient at iteration 1114: 581.2013125349081\n",
      "Norm of gradient at iteration 1115: 578.4960941118279\n",
      "Norm of gradient at iteration 1116: 575.8034673425402\n",
      "Norm of gradient at iteration 1117: 573.1233736159744\n",
      "Norm of gradient at iteration 1118: 570.4557545939715\n",
      "Norm of gradient at iteration 1119: 567.8005522098964\n",
      "Norm of gradient at iteration 1120: 565.1577086674413\n",
      "Norm of gradient at iteration 1121: 562.5271664394096\n",
      "Norm of gradient at iteration 1122: 559.9088682663806\n",
      "Norm of gradient at iteration 1123: 557.3027571554752\n",
      "Norm of gradient at iteration 1124: 554.7087763791544\n",
      "Norm of gradient at iteration 1125: 552.1268694739751\n",
      "Norm of gradient at iteration 1126: 549.5569802393265\n",
      "Norm of gradient at iteration 1127: 546.9990527362211\n",
      "Norm of gradient at iteration 1128: 544.4530312860667\n",
      "Norm of gradient at iteration 1129: 541.918860469551\n",
      "Norm of gradient at iteration 1130: 539.396485125309\n",
      "Norm of gradient at iteration 1131: 536.8858503486817\n",
      "Norm of gradient at iteration 1132: 534.3869014907207\n",
      "Norm of gradient at iteration 1133: 531.899584156847\n",
      "Norm of gradient at iteration 1134: 529.423844205686\n",
      "Norm of gradient at iteration 1135: 526.9596277478818\n",
      "Norm of gradient at iteration 1136: 524.506881144993\n",
      "Norm of gradient at iteration 1137: 522.0655510082104\n",
      "Norm of gradient at iteration 1138: 519.6355841973865\n",
      "Norm of gradient at iteration 1139: 517.2169278195972\n",
      "Norm of gradient at iteration 1140: 514.8095292281797\n",
      "Norm of gradient at iteration 1141: 512.4133360216565\n",
      "Norm of gradient at iteration 1142: 510.02829604237\n",
      "Norm of gradient at iteration 1143: 507.6543573755338\n",
      "Norm of gradient at iteration 1144: 505.2914683479837\n",
      "Norm of gradient at iteration 1145: 502.9395775271125\n",
      "Norm of gradient at iteration 1146: 500.59863371974797\n",
      "Norm of gradient at iteration 1147: 498.2685859710704\n",
      "Norm of gradient at iteration 1148: 495.94938356338247\n",
      "Norm of gradient at iteration 1149: 493.64097601509843\n",
      "Norm of gradient at iteration 1150: 491.34331307967983\n",
      "Norm of gradient at iteration 1151: 489.0563447444236\n",
      "Norm of gradient at iteration 1152: 486.78002122952904\n",
      "Norm of gradient at iteration 1153: 484.5142929868294\n",
      "Norm of gradient at iteration 1154: 482.25911069885365\n",
      "Norm of gradient at iteration 1155: 480.0144252777292\n",
      "Norm of gradient at iteration 1156: 477.7801878640194\n",
      "Norm of gradient at iteration 1157: 475.55634982579284\n",
      "Norm of gradient at iteration 1158: 473.34286275751344\n",
      "Norm of gradient at iteration 1159: 471.1396784789231\n",
      "Norm of gradient at iteration 1160: 468.94674903399545\n",
      "Norm of gradient at iteration 1161: 466.7640266901381\n",
      "Norm of gradient at iteration 1162: 464.591463936743\n",
      "Norm of gradient at iteration 1163: 462.42901348446884\n",
      "Norm of gradient at iteration 1164: 460.2766282640796\n",
      "Norm of gradient at iteration 1165: 458.13426142547587\n",
      "Norm of gradient at iteration 1166: 456.00186633659746\n",
      "Norm of gradient at iteration 1167: 453.879396582482\n",
      "Norm of gradient at iteration 1168: 451.7668059642747\n",
      "Norm of gradient at iteration 1169: 449.6640484980672\n",
      "Norm of gradient at iteration 1170: 447.5710784141332\n",
      "Norm of gradient at iteration 1171: 445.487850155665\n",
      "Norm of gradient at iteration 1172: 443.4143183780329\n",
      "Norm of gradient at iteration 1173: 441.35043794760674\n",
      "Norm of gradient at iteration 1174: 439.296163940953\n",
      "Norm of gradient at iteration 1175: 437.25145164364324\n",
      "Norm of gradient at iteration 1176: 435.21625654942625\n",
      "Norm of gradient at iteration 1177: 433.19053435925815\n",
      "Norm of gradient at iteration 1178: 431.1742409802676\n",
      "Norm of gradient at iteration 1179: 429.1673325248631\n",
      "Norm of gradient at iteration 1180: 427.1697653097598\n",
      "Norm of gradient at iteration 1181: 425.1814958549253\n",
      "Norm of gradient at iteration 1182: 423.2024808827964\n",
      "Norm of gradient at iteration 1183: 421.2326773172795\n",
      "Norm of gradient at iteration 1184: 419.2720422827248\n",
      "Norm of gradient at iteration 1185: 417.32053310315484\n",
      "Norm of gradient at iteration 1186: 415.3781073011761\n",
      "Norm of gradient at iteration 1187: 413.44472259712995\n",
      "Norm of gradient at iteration 1188: 411.5203369081691\n",
      "Norm of gradient at iteration 1189: 409.604908347379\n",
      "Norm of gradient at iteration 1190: 407.698395222761\n",
      "Norm of gradient at iteration 1191: 405.8007560364511\n",
      "Norm of gradient at iteration 1192: 403.91194948363176\n",
      "Norm of gradient at iteration 1193: 402.0319344519419\n",
      "Norm of gradient at iteration 1194: 400.1606700202142\n",
      "Norm of gradient at iteration 1195: 398.2981154579005\n",
      "Norm of gradient at iteration 1196: 396.44423022395495\n",
      "Norm of gradient at iteration 1197: 394.598973966083\n",
      "Norm of gradient at iteration 1198: 392.76230651977784\n",
      "Norm of gradient at iteration 1199: 390.9341879075878\n",
      "Norm of gradient at iteration 1200: 389.1145783380324\n",
      "Norm of gradient at iteration 1201: 387.3034382049818\n",
      "Norm of gradient at iteration 1202: 385.5007280865482\n",
      "Norm of gradient at iteration 1203: 383.70640874439385\n",
      "Norm of gradient at iteration 1204: 381.92044112287283\n",
      "Norm of gradient at iteration 1205: 380.1427863480369\n",
      "Norm of gradient at iteration 1206: 378.37340572697724\n",
      "Norm of gradient at iteration 1207: 376.6122607468691\n",
      "Norm of gradient at iteration 1208: 374.85931307414467\n",
      "Norm of gradient at iteration 1209: 373.1145245536573\n",
      "Norm of gradient at iteration 1210: 371.3778572078726\n",
      "Norm of gradient at iteration 1211: 369.649273236096\n",
      "Norm of gradient at iteration 1212: 367.92873501351903\n",
      "Norm of gradient at iteration 1213: 366.21620509044413\n",
      "Norm of gradient at iteration 1214: 364.51164619156896\n",
      "Norm of gradient at iteration 1215: 362.8150212150427\n",
      "Norm of gradient at iteration 1216: 361.12629323179414\n",
      "Norm of gradient at iteration 1217: 359.4454254845663\n",
      "Norm of gradient at iteration 1218: 357.7723813871953\n",
      "Norm of gradient at iteration 1219: 356.1071245238998\n",
      "Norm of gradient at iteration 1220: 354.4496186483287\n",
      "Norm of gradient at iteration 1221: 352.79982768288517\n",
      "Norm of gradient at iteration 1222: 351.1577157178916\n",
      "Norm of gradient at iteration 1223: 349.5232470108211\n",
      "Norm of gradient at iteration 1224: 347.8963859855131\n",
      "Norm of gradient at iteration 1225: 346.2770972314067\n",
      "Norm of gradient at iteration 1226: 344.66534550280824\n",
      "Norm of gradient at iteration 1227: 343.0610957180601\n",
      "Norm of gradient at iteration 1228: 341.46431295872264\n",
      "Norm of gradient at iteration 1229: 339.8749624690699\n",
      "Norm of gradient at iteration 1230: 338.29300965495736\n",
      "Norm of gradient at iteration 1231: 336.7184200834301\n",
      "Norm of gradient at iteration 1232: 335.15115948169375\n",
      "Norm of gradient at iteration 1233: 333.59119373652015\n",
      "Norm of gradient at iteration 1234: 332.0384888935203\n",
      "Norm of gradient at iteration 1235: 330.4930111562462\n",
      "Norm of gradient at iteration 1236: 328.95472688569697\n",
      "Norm of gradient at iteration 1237: 327.4236025993554\n",
      "Norm of gradient at iteration 1238: 325.8996049705562\n",
      "Norm of gradient at iteration 1239: 324.38270082781276\n",
      "Norm of gradient at iteration 1240: 322.87285715402356\n",
      "Norm of gradient at iteration 1241: 321.370041085766\n",
      "Norm of gradient at iteration 1242: 319.8742199125578\n",
      "Norm of gradient at iteration 1243: 318.38536107623355\n",
      "Norm of gradient at iteration 1244: 316.90343217010616\n",
      "Norm of gradient at iteration 1245: 315.4284009384286\n",
      "Norm of gradient at iteration 1246: 313.96023527546083\n",
      "Norm of gradient at iteration 1247: 312.4989032250682\n",
      "Norm of gradient at iteration 1248: 311.0443729797387\n",
      "Norm of gradient at iteration 1249: 309.5966128800605\n",
      "Norm of gradient at iteration 1250: 308.15559141393567\n",
      "Norm of gradient at iteration 1251: 306.72127721603687\n",
      "Norm of gradient at iteration 1252: 305.2936390669766\n",
      "Norm of gradient at iteration 1253: 303.8726458926886\n",
      "Norm of gradient at iteration 1254: 302.458266763688\n",
      "Norm of gradient at iteration 1255: 301.05047089462767\n",
      "Norm of gradient at iteration 1256: 299.64922764327935\n",
      "Norm of gradient at iteration 1257: 298.2545065101243\n",
      "Norm of gradient at iteration 1258: 296.8662771375651\n",
      "Norm of gradient at iteration 1259: 295.4845093094073\n",
      "Norm of gradient at iteration 1260: 294.1091729499899\n",
      "Norm of gradient at iteration 1261: 292.7402381236802\n",
      "Norm of gradient at iteration 1262: 291.37767503421696\n",
      "Norm of gradient at iteration 1263: 290.0214540240326\n",
      "Norm of gradient at iteration 1264: 288.6715455735521\n",
      "Norm of gradient at iteration 1265: 287.3279203006225\n",
      "Norm of gradient at iteration 1266: 285.9905489598875\n",
      "Norm of gradient at iteration 1267: 284.6594024421098\n",
      "Norm of gradient at iteration 1268: 283.3344517735123\n",
      "Norm of gradient at iteration 1269: 282.0156681151856\n",
      "Norm of gradient at iteration 1270: 280.70302276252585\n",
      "Norm of gradient at iteration 1271: 279.3964871444469\n",
      "Norm of gradient at iteration 1272: 278.09603282287173\n",
      "Norm of gradient at iteration 1273: 276.80163149212734\n",
      "Norm of gradient at iteration 1274: 275.5132549783053\n",
      "Norm of gradient at iteration 1275: 274.2308752385694\n",
      "Norm of gradient at iteration 1276: 272.954464360668\n",
      "Norm of gradient at iteration 1277: 271.6839945622267\n",
      "Norm of gradient at iteration 1278: 270.41943819025556\n",
      "Norm of gradient at iteration 1279: 269.1607677204476\n",
      "Norm of gradient at iteration 1280: 267.90795575655113\n",
      "Norm of gradient at iteration 1281: 266.66097502992864\n",
      "Norm of gradient at iteration 1282: 265.4197983987712\n",
      "Norm of gradient at iteration 1283: 264.1843988477369\n",
      "Norm of gradient at iteration 1284: 262.95474948709204\n",
      "Norm of gradient at iteration 1285: 261.73082355235323\n",
      "Norm of gradient at iteration 1286: 260.5125944035955\n",
      "Norm of gradient at iteration 1287: 259.3000355248713\n",
      "Norm of gradient at iteration 1288: 258.0931205236508\n",
      "Norm of gradient at iteration 1289: 256.8918231302952\n",
      "Norm of gradient at iteration 1290: 255.69611719742562\n",
      "Norm of gradient at iteration 1291: 254.50597669931057\n",
      "Norm of gradient at iteration 1292: 253.32137573147216\n",
      "Norm of gradient at iteration 1293: 252.1422885099141\n",
      "Norm of gradient at iteration 1294: 250.96868937065523\n",
      "Norm of gradient at iteration 1295: 249.80055276924253\n",
      "Norm of gradient at iteration 1296: 248.63785328005926\n",
      "Norm of gradient at iteration 1297: 247.4805655958483\n",
      "Norm of gradient at iteration 1298: 246.32866452715552\n",
      "Norm of gradient at iteration 1299: 245.18212500180832\n",
      "Norm of gradient at iteration 1300: 244.04092206424755\n",
      "Norm of gradient at iteration 1301: 242.90503087515043\n",
      "Norm of gradient at iteration 1302: 241.77442671078694\n",
      "Norm of gradient at iteration 1303: 240.6490849624778\n",
      "Norm of gradient at iteration 1304: 239.52898113617113\n",
      "Norm of gradient at iteration 1305: 238.41409085172302\n",
      "Norm of gradient at iteration 1306: 237.30438984254016\n",
      "Norm of gradient at iteration 1307: 236.19985395493114\n",
      "Norm of gradient at iteration 1308: 235.10045914766906\n",
      "Norm of gradient at iteration 1309: 234.00618149143975\n",
      "Norm of gradient at iteration 1310: 232.91699716823067\n",
      "Norm of gradient at iteration 1311: 231.83288247095862\n",
      "Norm of gradient at iteration 1312: 230.7538138029647\n",
      "Norm of gradient at iteration 1313: 229.6797676772329\n",
      "Norm of gradient at iteration 1314: 228.61072071622826\n",
      "Norm of gradient at iteration 1315: 227.5466496511155\n",
      "Norm of gradient at iteration 1316: 226.48753132147098\n",
      "Norm of gradient at iteration 1317: 225.43334267459093\n",
      "Norm of gradient at iteration 1318: 224.3840607651615\n",
      "Norm of gradient at iteration 1319: 223.33966275457146\n",
      "Norm of gradient at iteration 1320: 222.30012591057383\n",
      "Norm of gradient at iteration 1321: 221.2654276066963\n",
      "Norm of gradient at iteration 1322: 220.23554532185778\n",
      "Norm of gradient at iteration 1323: 219.2104566396591\n",
      "Norm of gradient at iteration 1324: 218.19013924821286\n",
      "Norm of gradient at iteration 1325: 217.17457093934206\n",
      "Norm of gradient at iteration 1326: 216.1637296083218\n",
      "Norm of gradient at iteration 1327: 215.15759325328406\n",
      "Norm of gradient at iteration 1328: 214.15613997479556\n",
      "Norm of gradient at iteration 1329: 213.15934797532992\n",
      "Norm of gradient at iteration 1330: 212.1671955588318\n",
      "Norm of gradient at iteration 1331: 211.17966113020137\n",
      "Norm of gradient at iteration 1332: 210.1967231949298\n",
      "Norm of gradient at iteration 1333: 209.21836035843555\n",
      "Norm of gradient at iteration 1334: 208.2445513258728\n",
      "Norm of gradient at iteration 1335: 207.2752749013605\n",
      "Norm of gradient at iteration 1336: 206.31050998776763\n",
      "Norm of gradient at iteration 1337: 205.3502355861678\n",
      "Norm of gradient at iteration 1338: 204.39443079533598\n",
      "Norm of gradient at iteration 1339: 203.44307481136784\n",
      "Norm of gradient at iteration 1340: 202.49614692713664\n",
      "Norm of gradient at iteration 1341: 201.55362653193833\n",
      "Norm of gradient at iteration 1342: 200.6154931109727\n",
      "Norm of gradient at iteration 1343: 199.68172624502824\n",
      "Norm of gradient at iteration 1344: 198.75230560980134\n",
      "Norm of gradient at iteration 1345: 197.8272109756692\n",
      "Norm of gradient at iteration 1346: 196.90642220716234\n",
      "Norm of gradient at iteration 1347: 195.98991926247479\n",
      "Norm of gradient at iteration 1348: 195.07768219315054\n",
      "Norm of gradient at iteration 1349: 194.16969114355138\n",
      "Norm of gradient at iteration 1350: 193.26592635052285\n",
      "Norm of gradient at iteration 1351: 192.36636814279987\n",
      "Norm of gradient at iteration 1352: 191.47099694075476\n",
      "Norm of gradient at iteration 1353: 190.57979325584986\n",
      "Norm of gradient at iteration 1354: 189.692737690269\n",
      "Norm of gradient at iteration 1355: 188.80981093651496\n",
      "Norm of gradient at iteration 1356: 187.93099377689884\n",
      "Norm of gradient at iteration 1357: 187.056267083264\n",
      "Norm of gradient at iteration 1358: 186.18561181639927\n",
      "Norm of gradient at iteration 1359: 185.31900902576209\n",
      "Norm of gradient at iteration 1360: 184.456439849012\n",
      "Norm of gradient at iteration 1361: 183.59788551161031\n",
      "Norm of gradient at iteration 1362: 182.74332732639178\n",
      "Norm of gradient at iteration 1363: 181.89274669314597\n",
      "Norm of gradient at iteration 1364: 181.04612509831932\n",
      "Norm of gradient at iteration 1365: 180.20344411444444\n",
      "Norm of gradient at iteration 1366: 179.36468539987285\n",
      "Norm of gradient at iteration 1367: 178.5298306982728\n",
      "Norm of gradient at iteration 1368: 177.69886183839972\n",
      "Norm of gradient at iteration 1369: 176.8717607334866\n",
      "Norm of gradient at iteration 1370: 176.0485093809662\n",
      "Norm of gradient at iteration 1371: 175.22908986211917\n",
      "Norm of gradient at iteration 1372: 174.41348434155813\n",
      "Norm of gradient at iteration 1373: 173.60167506695953\n",
      "Norm of gradient at iteration 1374: 172.7936443686172\n",
      "Norm of gradient at iteration 1375: 171.98937465907514\n",
      "Norm of gradient at iteration 1376: 171.18884843273617\n",
      "Norm of gradient at iteration 1377: 170.39204826545418\n",
      "Norm of gradient at iteration 1378: 169.5989568142497\n",
      "Norm of gradient at iteration 1379: 168.80955681676286\n",
      "Norm of gradient at iteration 1380: 168.02383109114078\n",
      "Norm of gradient at iteration 1381: 167.24176253531937\n",
      "Norm of gradient at iteration 1382: 166.46333412697032\n",
      "Norm of gradient at iteration 1383: 165.68852892298895\n",
      "Norm of gradient at iteration 1384: 164.91733005905104\n",
      "Norm of gradient at iteration 1385: 164.14972074942008\n",
      "Norm of gradient at iteration 1386: 163.38568428638965\n",
      "Norm of gradient at iteration 1387: 162.625204040105\n",
      "Norm of gradient at iteration 1388: 161.8682634580621\n",
      "Norm of gradient at iteration 1389: 161.11484606485809\n",
      "Norm of gradient at iteration 1390: 160.36493546177186\n",
      "Norm of gradient at iteration 1391: 159.61851532630942\n",
      "Norm of gradient at iteration 1392: 158.87556941203587\n",
      "Norm of gradient at iteration 1393: 158.13608154818587\n",
      "Norm of gradient at iteration 1394: 157.40003563914868\n",
      "Norm of gradient at iteration 1395: 156.66741566429113\n",
      "Norm of gradient at iteration 1396: 155.93820567756234\n",
      "Norm of gradient at iteration 1397: 155.21238980704678\n",
      "Norm of gradient at iteration 1398: 154.48995225486914\n",
      "Norm of gradient at iteration 1399: 153.7708772964924\n",
      "Norm of gradient at iteration 1400: 153.0551492807134\n",
      "Norm of gradient at iteration 1401: 152.34275262911916\n",
      "Norm of gradient at iteration 1402: 151.6336718358043\n",
      "Norm of gradient at iteration 1403: 150.92789146705042\n",
      "Norm of gradient at iteration 1404: 150.22539616098095\n",
      "Norm of gradient at iteration 1405: 149.52617062722535\n",
      "Norm of gradient at iteration 1406: 148.8301996465531\n",
      "Norm of gradient at iteration 1407: 148.13746807059115\n",
      "Norm of gradient at iteration 1408: 147.44796082150268\n",
      "Norm of gradient at iteration 1409: 146.7616628915823\n",
      "Norm of gradient at iteration 1410: 146.0785593429544\n",
      "Norm of gradient at iteration 1411: 145.3986353074176\n",
      "Norm of gradient at iteration 1412: 144.72187598579256\n",
      "Norm of gradient at iteration 1413: 144.04826664788123\n",
      "Norm of gradient at iteration 1414: 143.3777926320549\n",
      "Norm of gradient at iteration 1415: 142.7104393449353\n",
      "Norm of gradient at iteration 1416: 142.04619226094695\n",
      "Norm of gradient at iteration 1417: 141.38503692230574\n",
      "Norm of gradient at iteration 1418: 140.7269589383769\n",
      "Norm of gradient at iteration 1419: 140.07194398557405\n",
      "Norm of gradient at iteration 1420: 139.4199778069879\n",
      "Norm of gradient at iteration 1421: 138.77104621204944\n",
      "Norm of gradient at iteration 1422: 138.1251350762254\n",
      "Norm of gradient at iteration 1423: 137.4822303407538\n",
      "Norm of gradient at iteration 1424: 136.8423180122624\n",
      "Norm of gradient at iteration 1425: 136.20538416261417\n",
      "Norm of gradient at iteration 1426: 135.57141492838622\n",
      "Norm of gradient at iteration 1427: 134.94039651071975\n",
      "Norm of gradient at iteration 1428: 134.31231517503093\n",
      "Norm of gradient at iteration 1429: 133.68715725061642\n",
      "Norm of gradient at iteration 1430: 133.06490913040767\n",
      "Norm of gradient at iteration 1431: 132.44555727064684\n",
      "Norm of gradient at iteration 1432: 131.82908819071298\n",
      "Norm of gradient at iteration 1433: 131.21548847259945\n",
      "Norm of gradient at iteration 1434: 130.60474476084582\n",
      "Norm of gradient at iteration 1435: 129.99684376215257\n",
      "Norm of gradient at iteration 1436: 129.39177224503158\n",
      "Norm of gradient at iteration 1437: 128.7895170396242\n",
      "Norm of gradient at iteration 1438: 128.19006503738748\n",
      "Norm of gradient at iteration 1439: 127.59340319077121\n",
      "Norm of gradient at iteration 1440: 126.99951851291178\n",
      "Norm of gradient at iteration 1441: 126.40839807748597\n",
      "Norm of gradient at iteration 1442: 125.82002901826368\n",
      "Norm of gradient at iteration 1443: 125.23439852893081\n",
      "Norm of gradient at iteration 1444: 124.6514938627669\n",
      "Norm of gradient at iteration 1445: 124.07130233243893\n",
      "Norm of gradient at iteration 1446: 123.49381130950843\n",
      "Norm of gradient at iteration 1447: 122.91900822455194\n",
      "Norm of gradient at iteration 1448: 122.34688056643402\n",
      "Norm of gradient at iteration 1449: 121.77741588238267\n",
      "Norm of gradient at iteration 1450: 121.21060177755413\n",
      "Norm of gradient at iteration 1451: 120.64642591478616\n",
      "Norm of gradient at iteration 1452: 120.08487601430889\n",
      "Norm of gradient at iteration 1453: 119.5259398535937\n",
      "Norm of gradient at iteration 1454: 118.96960526690353\n",
      "Norm of gradient at iteration 1455: 118.41586014520384\n",
      "Norm of gradient at iteration 1456: 117.86469243581875\n",
      "Norm of gradient at iteration 1457: 117.3160901421129\n",
      "Norm of gradient at iteration 1458: 116.7700413233543\n",
      "Norm of gradient at iteration 1459: 116.22653409430156\n",
      "Norm of gradient at iteration 1460: 115.68555662517194\n",
      "Norm of gradient at iteration 1461: 115.1470971411014\n",
      "Norm of gradient at iteration 1462: 114.61114392213534\n",
      "Norm of gradient at iteration 1463: 114.07768530281669\n",
      "Norm of gradient at iteration 1464: 113.54670967197507\n",
      "Norm of gradient at iteration 1465: 113.01820547252623\n",
      "Norm of gradient at iteration 1466: 112.49216120119358\n",
      "Norm of gradient at iteration 1467: 111.96856540814613\n",
      "Norm of gradient at iteration 1468: 111.44740669694909\n",
      "Norm of gradient at iteration 1469: 110.92867372415792\n",
      "Norm of gradient at iteration 1470: 110.41235519917451\n",
      "Norm of gradient at iteration 1471: 109.8984398838889\n",
      "Norm of gradient at iteration 1472: 109.38691659251742\n",
      "Norm of gradient at iteration 1473: 108.87777419138314\n",
      "Norm of gradient at iteration 1474: 108.37100159860924\n",
      "Norm of gradient at iteration 1475: 107.86658778389054\n",
      "Norm of gradient at iteration 1476: 107.36452176825215\n",
      "Norm of gradient at iteration 1477: 106.86479262380642\n",
      "Norm of gradient at iteration 1478: 106.36738947361226\n",
      "Norm of gradient at iteration 1479: 105.87230149125456\n",
      "Norm of gradient at iteration 1480: 105.379517900768\n",
      "Norm of gradient at iteration 1481: 104.88902797636658\n",
      "Norm of gradient at iteration 1482: 104.40082104210092\n",
      "Norm of gradient at iteration 1483: 103.91488647180122\n",
      "Norm of gradient at iteration 1484: 103.43121368872929\n",
      "Norm of gradient at iteration 1485: 102.94979216535164\n",
      "Norm of gradient at iteration 1486: 102.47061142313393\n",
      "Norm of gradient at iteration 1487: 101.99366103234088\n",
      "Norm of gradient at iteration 1488: 101.5189306117948\n",
      "Norm of gradient at iteration 1489: 101.04640982860012\n",
      "Norm of gradient at iteration 1490: 100.5760883979915\n",
      "Norm of gradient at iteration 1491: 100.10795608302875\n",
      "Norm of gradient at iteration 1492: 99.6420026944901\n",
      "Norm of gradient at iteration 1493: 99.17821809050183\n",
      "Norm of gradient at iteration 1494: 98.71659217645582\n",
      "Norm of gradient at iteration 1495: 98.25711490465119\n",
      "Norm of gradient at iteration 1496: 97.79977627425242\n",
      "Norm of gradient at iteration 1497: 97.34456633093912\n",
      "Norm of gradient at iteration 1498: 96.89147516667127\n",
      "Norm of gradient at iteration 1499: 96.44049291960032\n",
      "Norm of gradient at iteration 1500: 95.99160977373995\n",
      "Norm of gradient at iteration 1501: 95.54481595878755\n",
      "Norm of gradient at iteration 1502: 95.10010174991947\n",
      "Norm of gradient at iteration 1503: 94.65745746763326\n",
      "Norm of gradient at iteration 1504: 94.21687347736061\n",
      "Norm of gradient at iteration 1505: 93.77834018951094\n",
      "Norm of gradient at iteration 1506: 93.34184805903519\n",
      "Norm of gradient at iteration 1507: 92.90738758532959\n",
      "Norm of gradient at iteration 1508: 92.47494931209361\n",
      "Norm of gradient at iteration 1509: 92.0445238268787\n",
      "Norm of gradient at iteration 1510: 91.61610176122099\n",
      "Norm of gradient at iteration 1511: 91.18967379009784\n",
      "Norm of gradient at iteration 1512: 90.76523063205003\n",
      "Norm of gradient at iteration 1513: 90.34276304871761\n",
      "Norm of gradient at iteration 1514: 89.92226184474121\n",
      "Norm of gradient at iteration 1515: 89.50371786762041\n",
      "Norm of gradient at iteration 1516: 89.08712200742482\n",
      "Norm of gradient at iteration 1517: 88.67246519657171\n",
      "Norm of gradient at iteration 1518: 88.25973840980143\n",
      "Norm of gradient at iteration 1519: 87.84893266373815\n",
      "Norm of gradient at iteration 1520: 87.4400390169261\n",
      "Norm of gradient at iteration 1521: 87.03304856943637\n",
      "Norm of gradient at iteration 1522: 86.62795246282731\n",
      "Norm of gradient at iteration 1523: 86.22474187984605\n",
      "Norm of gradient at iteration 1524: 85.82340804435692\n",
      "Norm of gradient at iteration 1525: 85.42394222093904\n",
      "Norm of gradient at iteration 1526: 85.02633571497196\n",
      "Norm of gradient at iteration 1527: 84.63057987225251\n",
      "Norm of gradient at iteration 1528: 84.23666607876653\n",
      "Norm of gradient at iteration 1529: 83.84458576077512\n",
      "Norm of gradient at iteration 1530: 83.45433038424572\n",
      "Norm of gradient at iteration 1531: 83.06589145508045\n",
      "Norm of gradient at iteration 1532: 82.67926051848453\n",
      "Norm of gradient at iteration 1533: 82.29442915927342\n",
      "Norm of gradient at iteration 1534: 81.91138900119392\n",
      "Norm of gradient at iteration 1535: 81.530131707088\n",
      "Norm of gradient at iteration 1536: 81.15064897865142\n",
      "Norm of gradient at iteration 1537: 80.77293255610807\n",
      "Norm of gradient at iteration 1538: 80.39697421817496\n",
      "Norm of gradient at iteration 1539: 80.02276578181733\n",
      "Norm of gradient at iteration 1540: 79.6502991021152\n",
      "Norm of gradient at iteration 1541: 79.27956607206286\n",
      "Norm of gradient at iteration 1542: 78.91055862232989\n",
      "Norm of gradient at iteration 1543: 78.5432687211831\n",
      "Norm of gradient at iteration 1544: 78.17768837433886\n",
      "Norm of gradient at iteration 1545: 77.81380962459912\n",
      "Norm of gradient at iteration 1546: 77.45162455185101\n",
      "Norm of gradient at iteration 1547: 77.09112527287917\n",
      "Norm of gradient at iteration 1548: 76.73230394117894\n",
      "Norm of gradient at iteration 1549: 76.375152746661\n",
      "Norm of gradient at iteration 1550: 76.01966391568122\n",
      "Norm of gradient at iteration 1551: 75.66582971077175\n",
      "Norm of gradient at iteration 1552: 75.31364243043276\n",
      "Norm of gradient at iteration 1553: 74.96309440905162\n",
      "Norm of gradient at iteration 1554: 74.61417801666018\n",
      "Norm of gradient at iteration 1555: 74.26688565885337\n",
      "Norm of gradient at iteration 1556: 73.9212097765429\n",
      "Norm of gradient at iteration 1557: 73.57714284579717\n",
      "Norm of gradient at iteration 1558: 73.23467737775432\n",
      "Norm of gradient at iteration 1559: 72.8938059183665\n",
      "Norm of gradient at iteration 1560: 72.55452104836185\n",
      "Norm of gradient at iteration 1561: 72.21681538289094\n",
      "Norm of gradient at iteration 1562: 71.88068157157117\n",
      "Norm of gradient at iteration 1563: 71.5461122981357\n",
      "Norm of gradient at iteration 1564: 71.2131002804676\n",
      "Norm of gradient at iteration 1565: 70.88163827028589\n",
      "Norm of gradient at iteration 1566: 70.55171905310026\n",
      "Norm of gradient at iteration 1567: 70.2233354479142\n",
      "Norm of gradient at iteration 1568: 69.89648030724294\n",
      "Norm of gradient at iteration 1569: 69.57114651680503\n",
      "Norm of gradient at iteration 1570: 69.24732699548949\n",
      "Norm of gradient at iteration 1571: 68.92501469511174\n",
      "Norm of gradient at iteration 1572: 68.60420260025312\n",
      "Norm of gradient at iteration 1573: 68.2848837282702\n",
      "Norm of gradient at iteration 1574: 67.96705112887602\n",
      "Norm of gradient at iteration 1575: 67.65069788421475\n",
      "Norm of gradient at iteration 1576: 67.3358171086272\n",
      "Norm of gradient at iteration 1577: 67.02240194851065\n",
      "Norm of gradient at iteration 1578: 66.71044558208439\n",
      "Norm of gradient at iteration 1579: 66.39994121944258\n",
      "Norm of gradient at iteration 1580: 66.09088210214559\n",
      "Norm of gradient at iteration 1581: 65.78326150335084\n",
      "Norm of gradient at iteration 1582: 65.47707272744871\n",
      "Norm of gradient at iteration 1583: 65.17230911000225\n",
      "Norm of gradient at iteration 1584: 64.86896401759546\n",
      "Norm of gradient at iteration 1585: 64.56703084766067\n",
      "Norm of gradient at iteration 1586: 64.26650302844054\n",
      "Norm of gradient at iteration 1587: 63.96737401866907\n",
      "Norm of gradient at iteration 1588: 63.66963730759432\n",
      "Norm of gradient at iteration 1589: 63.373286414767335\n",
      "Norm of gradient at iteration 1590: 63.078314889861915\n",
      "Norm of gradient at iteration 1591: 62.78471631260721\n",
      "Norm of gradient at iteration 1592: 62.49248429255267\n",
      "Norm of gradient at iteration 1593: 62.201612469122324\n",
      "Norm of gradient at iteration 1594: 61.91209451123786\n",
      "Norm of gradient at iteration 1595: 61.623924117323156\n",
      "Norm of gradient at iteration 1596: 61.33709501511337\n",
      "Norm of gradient at iteration 1597: 61.05160096153415\n",
      "Norm of gradient at iteration 1598: 60.76743574262754\n",
      "Norm of gradient at iteration 1599: 60.48459317330555\n",
      "Norm of gradient at iteration 1600: 60.20306709729443\n",
      "Norm of gradient at iteration 1601: 59.922851386973065\n",
      "Norm of gradient at iteration 1602: 59.64393994319462\n",
      "Norm of gradient at iteration 1603: 59.36632669526539\n",
      "Norm of gradient at iteration 1604: 59.09000560069422\n",
      "Norm of gradient at iteration 1605: 58.81497064514307\n",
      "Norm of gradient at iteration 1606: 58.54121584229736\n",
      "Norm of gradient at iteration 1607: 58.26873523365258\n",
      "Norm of gradient at iteration 1608: 57.99752288847407\n",
      "Norm of gradient at iteration 1609: 57.72757290362124\n",
      "Norm of gradient at iteration 1610: 57.45887940337941\n",
      "Norm of gradient at iteration 1611: 57.19143653948477\n",
      "Norm of gradient at iteration 1612: 56.9252384907725\n",
      "Norm of gradient at iteration 1613: 56.660279463298906\n",
      "Norm of gradient at iteration 1614: 56.396553690041166\n",
      "Norm of gradient at iteration 1615: 56.1340554307229\n",
      "Norm of gradient at iteration 1616: 55.8727789719689\n",
      "Norm of gradient at iteration 1617: 55.61271862682626\n",
      "Norm of gradient at iteration 1618: 55.353868734908396\n",
      "Norm of gradient at iteration 1619: 55.09622366214642\n",
      "Norm of gradient at iteration 1620: 54.83977780067697\n",
      "Norm of gradient at iteration 1621: 54.584525568796415\n",
      "Norm of gradient at iteration 1622: 54.330461410720616\n",
      "Norm of gradient at iteration 1623: 54.07757979653847\n",
      "Norm of gradient at iteration 1624: 53.825875222133455\n",
      "Norm of gradient at iteration 1625: 53.575342208931495\n",
      "Norm of gradient at iteration 1626: 53.32597530389211\n",
      "Norm of gradient at iteration 1627: 53.07776907934592\n",
      "Norm of gradient at iteration 1628: 52.83071813291966\n",
      "Norm of gradient at iteration 1629: 52.58481708732937\n",
      "Norm of gradient at iteration 1630: 52.340060590390365\n",
      "Norm of gradient at iteration 1631: 52.096443314713014\n",
      "Norm of gradient at iteration 1632: 51.85395995786896\n",
      "Norm of gradient at iteration 1633: 51.61260524200294\n",
      "Norm of gradient at iteration 1634: 51.372373913787456\n",
      "Norm of gradient at iteration 1635: 51.13326074445323\n",
      "Norm of gradient at iteration 1636: 50.89526052952925\n",
      "Norm of gradient at iteration 1637: 50.65836808874562\n",
      "Norm of gradient at iteration 1638: 50.42257826591576\n",
      "Norm of gradient at iteration 1639: 50.18788592898004\n",
      "Norm of gradient at iteration 1640: 49.954285969613984\n",
      "Norm of gradient at iteration 1641: 49.72177330333592\n",
      "Norm of gradient at iteration 1642: 49.49034286936937\n",
      "Norm of gradient at iteration 1643: 49.25998963040825\n",
      "Norm of gradient at iteration 1644: 49.0307085726763\n",
      "Norm of gradient at iteration 1645: 48.80249470568301\n",
      "Norm of gradient at iteration 1646: 48.57534306215615\n",
      "Norm of gradient at iteration 1647: 48.34924869800762\n",
      "Norm of gradient at iteration 1648: 48.124206692099214\n",
      "Norm of gradient at iteration 1649: 47.900212146230714\n",
      "Norm of gradient at iteration 1650: 47.67726018493773\n",
      "Norm of gradient at iteration 1651: 47.45534595554725\n",
      "Norm of gradient at iteration 1652: 47.234464627965075\n",
      "Norm of gradient at iteration 1653: 47.01461139449597\n",
      "Norm of gradient at iteration 1654: 46.795781469840094\n",
      "Norm of gradient at iteration 1655: 46.57797009104859\n",
      "Norm of gradient at iteration 1656: 46.36117251726251\n",
      "Norm of gradient at iteration 1657: 46.14538402973028\n",
      "Norm of gradient at iteration 1658: 45.930599931620485\n",
      "Norm of gradient at iteration 1659: 45.71681554801649\n",
      "Norm of gradient at iteration 1660: 45.50402622571953\n",
      "Norm of gradient at iteration 1661: 45.29222733322773\n",
      "Norm of gradient at iteration 1662: 45.08141426061053\n",
      "Norm of gradient at iteration 1663: 44.87158241930792\n",
      "Norm of gradient at iteration 1664: 44.66272724216674\n",
      "Norm of gradient at iteration 1665: 44.45484418332929\n",
      "Norm of gradient at iteration 1666: 44.247928718045614\n",
      "Norm of gradient at iteration 1667: 44.041976342635984\n",
      "Norm of gradient at iteration 1668: 43.83698257438496\n",
      "Norm of gradient at iteration 1669: 43.6329429514417\n",
      "Norm of gradient at iteration 1670: 43.429853032779675\n",
      "Norm of gradient at iteration 1671: 43.22770839794155\n",
      "Norm of gradient at iteration 1672: 43.02650464710699\n",
      "Norm of gradient at iteration 1673: 42.82623740092886\n",
      "Norm of gradient at iteration 1674: 42.62690230041078\n",
      "Norm of gradient at iteration 1675: 42.42849500694202\n",
      "Norm of gradient at iteration 1676: 42.231011201961046\n",
      "Norm of gradient at iteration 1677: 42.034446587090855\n",
      "Norm of gradient at iteration 1678: 41.838796884009994\n",
      "Norm of gradient at iteration 1679: 41.64405783418181\n",
      "Norm of gradient at iteration 1680: 41.45022519901743\n",
      "Norm of gradient at iteration 1681: 41.25729475957544\n",
      "Norm of gradient at iteration 1682: 41.065262316581446\n",
      "Norm of gradient at iteration 1683: 40.87412369029005\n",
      "Norm of gradient at iteration 1684: 40.68387472044983\n",
      "Norm of gradient at iteration 1685: 40.494511266130175\n",
      "Norm of gradient at iteration 1686: 40.30602920567879\n",
      "Norm of gradient at iteration 1687: 40.11842443667579\n",
      "Norm of gradient at iteration 1688: 39.93169287575174\n",
      "Norm of gradient at iteration 1689: 39.74583045850627\n",
      "Norm of gradient at iteration 1690: 39.56083313955824\n",
      "Norm of gradient at iteration 1691: 39.37669689227094\n",
      "Norm of gradient at iteration 1692: 39.193417708798115\n",
      "Norm of gradient at iteration 1693: 39.0109915999046\n",
      "Norm of gradient at iteration 1694: 38.82941459494804\n",
      "Norm of gradient at iteration 1695: 38.64868274181392\n",
      "Norm of gradient at iteration 1696: 38.46879210664152\n",
      "Norm of gradient at iteration 1697: 38.28973877403654\n",
      "Norm of gradient at iteration 1698: 38.11151884679855\n",
      "Norm of gradient at iteration 1699: 37.93412844577275\n",
      "Norm of gradient at iteration 1700: 37.757563709940726\n",
      "Norm of gradient at iteration 1701: 37.58182079621934\n",
      "Norm of gradient at iteration 1702: 37.40689587951366\n",
      "Norm of gradient at iteration 1703: 37.232785152354694\n",
      "Norm of gradient at iteration 1704: 37.05948482510011\n",
      "Norm of gradient at iteration 1705: 36.88699112575548\n",
      "Norm of gradient at iteration 1706: 36.7153002998946\n",
      "Norm of gradient at iteration 1707: 36.54440861048443\n",
      "Norm of gradient at iteration 1708: 36.37431233800354\n",
      "Norm of gradient at iteration 1709: 36.205007780073196\n",
      "Norm of gradient at iteration 1710: 36.03649125173209\n",
      "Norm of gradient at iteration 1711: 35.86875908509079\n",
      "Norm of gradient at iteration 1712: 35.70180762927086\n",
      "Norm of gradient at iteration 1713: 35.53563325049902\n",
      "Norm of gradient at iteration 1714: 35.37023233184938\n",
      "Norm of gradient at iteration 1715: 35.20560127324875\n",
      "Norm of gradient at iteration 1716: 35.04173649137231\n",
      "Norm of gradient at iteration 1717: 34.87863441956959\n",
      "Norm of gradient at iteration 1718: 34.716291507833745\n",
      "Norm of gradient at iteration 1719: 34.554704222559835\n",
      "Norm of gradient at iteration 1720: 34.39386904679504\n",
      "Norm of gradient at iteration 1721: 34.23378247977899\n",
      "Norm of gradient at iteration 1722: 34.074441037100435\n",
      "Norm of gradient at iteration 1723: 33.91584125056936\n",
      "Norm of gradient at iteration 1724: 33.757979668141594\n",
      "Norm of gradient at iteration 1725: 33.600852853871544\n",
      "Norm of gradient at iteration 1726: 33.44445738775588\n",
      "Norm of gradient at iteration 1727: 33.288789865715174\n",
      "Norm of gradient at iteration 1728: 33.13384689950674\n",
      "Norm of gradient at iteration 1729: 32.9796251167593\n",
      "Norm of gradient at iteration 1730: 32.826121160651596\n",
      "Norm of gradient at iteration 1731: 32.67333169004767\n",
      "Norm of gradient at iteration 1732: 32.52125337941629\n",
      "Norm of gradient at iteration 1733: 32.36988291860571\n",
      "Norm of gradient at iteration 1734: 32.219217012954\n",
      "Norm of gradient at iteration 1735: 32.06925238310184\n",
      "Norm of gradient at iteration 1736: 31.91998576494819\n",
      "Norm of gradient at iteration 1737: 31.77141390955842\n",
      "Norm of gradient at iteration 1738: 31.623533583241432\n",
      "Norm of gradient at iteration 1739: 31.476341567152538\n",
      "Norm of gradient at iteration 1740: 31.3298346576428\n",
      "Norm of gradient at iteration 1741: 31.184009665826164\n",
      "Norm of gradient at iteration 1742: 31.038863417740895\n",
      "Norm of gradient at iteration 1743: 30.89439275414331\n",
      "Norm of gradient at iteration 1744: 30.750594530532528\n",
      "Norm of gradient at iteration 1745: 30.607465617044106\n",
      "Norm of gradient at iteration 1746: 30.465002898315383\n",
      "Norm of gradient at iteration 1747: 30.323203273586238\n",
      "Norm of gradient at iteration 1748: 30.182063656480945\n",
      "Norm of gradient at iteration 1749: 30.041580974966646\n",
      "Norm of gradient at iteration 1750: 29.90175217131893\n",
      "Norm of gradient at iteration 1751: 29.762574202099227\n",
      "Norm of gradient at iteration 1752: 29.62404403795364\n",
      "Norm of gradient at iteration 1753: 29.4861586636766\n",
      "Norm of gradient at iteration 1754: 29.348915078104056\n",
      "Norm of gradient at iteration 1755: 29.21231029401428\n",
      "Norm of gradient at iteration 1756: 29.076341338110545\n",
      "Norm of gradient at iteration 1757: 28.94100525090839\n",
      "Norm of gradient at iteration 1758: 28.80629908673345\n",
      "Norm of gradient at iteration 1759: 28.672219913570583\n",
      "Norm of gradient at iteration 1760: 28.53876481312184\n",
      "Norm of gradient at iteration 1761: 28.405930880609525\n",
      "Norm of gradient at iteration 1762: 28.27371522481398\n",
      "Norm of gradient at iteration 1763: 28.14211496795822\n",
      "Norm of gradient at iteration 1764: 28.011127245667886\n",
      "Norm of gradient at iteration 1765: 27.880749206869794\n",
      "Norm of gradient at iteration 1766: 27.75097801383406\n",
      "Norm of gradient at iteration 1767: 27.621810841935694\n",
      "Norm of gradient at iteration 1768: 27.49324487979494\n",
      "Norm of gradient at iteration 1769: 27.36527732909094\n",
      "Norm of gradient at iteration 1770: 27.237905404442124\n",
      "Norm of gradient at iteration 1771: 27.11112633355157\n",
      "Norm of gradient at iteration 1772: 26.984937356972747\n",
      "Norm of gradient at iteration 1773: 26.85933572810327\n",
      "Norm of gradient at iteration 1774: 26.734318713127582\n",
      "Norm of gradient at iteration 1775: 26.609883590935954\n",
      "Norm of gradient at iteration 1776: 26.486027653127444\n",
      "Norm of gradient at iteration 1777: 26.3627482038877\n",
      "Norm of gradient at iteration 1778: 26.240042559912634\n",
      "Norm of gradient at iteration 1779: 26.11790805046482\n",
      "Norm of gradient at iteration 1780: 25.996342017159343\n",
      "Norm of gradient at iteration 1781: 25.875341814022306\n",
      "Norm of gradient at iteration 1782: 25.754904807415077\n",
      "Norm of gradient at iteration 1783: 25.635028375918406\n",
      "Norm of gradient at iteration 1784: 25.51570991033279\n",
      "Norm of gradient at iteration 1785: 25.396946813609247\n",
      "Norm of gradient at iteration 1786: 25.278736500755755\n",
      "Norm of gradient at iteration 1787: 25.161076398847666\n",
      "Norm of gradient at iteration 1788: 25.043963946936532\n",
      "Norm of gradient at iteration 1789: 24.927396595953795\n",
      "Norm of gradient at iteration 1790: 24.81137180871916\n",
      "Norm of gradient at iteration 1791: 24.695887059922946\n",
      "Norm of gradient at iteration 1792: 24.580939835884262\n",
      "Norm of gradient at iteration 1793: 24.4665276347052\n",
      "Norm of gradient at iteration 1794: 24.352647966128302\n",
      "Norm of gradient at iteration 1795: 24.23929835149706\n",
      "Norm of gradient at iteration 1796: 24.12647632363843\n",
      "Norm of gradient at iteration 1797: 24.014179426883317\n",
      "Norm of gradient at iteration 1798: 23.902405217045608\n",
      "Norm of gradient at iteration 1799: 23.791151261280326\n",
      "Norm of gradient at iteration 1800: 23.68041513798302\n",
      "Norm of gradient at iteration 1801: 23.57019443699446\n",
      "Norm of gradient at iteration 1802: 23.4604867592424\n",
      "Norm of gradient at iteration 1803: 23.351289716824773\n",
      "Norm of gradient at iteration 1804: 23.242600932987976\n",
      "Norm of gradient at iteration 1805: 23.134418042080263\n",
      "Norm of gradient at iteration 1806: 23.026738689364873\n",
      "Norm of gradient at iteration 1807: 22.919560531159764\n",
      "Norm of gradient at iteration 1808: 22.812881234630648\n",
      "Norm of gradient at iteration 1809: 22.706698477860005\n",
      "Norm of gradient at iteration 1810: 22.60100994961699\n",
      "Norm of gradient at iteration 1811: 22.49581334963713\n",
      "Norm of gradient at iteration 1812: 22.391106388136237\n",
      "Norm of gradient at iteration 1813: 22.286886786055028\n",
      "Norm of gradient at iteration 1814: 22.183152275085444\n",
      "Norm of gradient at iteration 1815: 22.079900597289594\n",
      "Norm of gradient at iteration 1816: 21.97712950537946\n",
      "Norm of gradient at iteration 1817: 21.87483676238809\n",
      "Norm of gradient at iteration 1818: 21.773020141868468\n",
      "Norm of gradient at iteration 1819: 21.671677427719132\n",
      "Norm of gradient at iteration 1820: 21.57080641409848\n",
      "Norm of gradient at iteration 1821: 21.470404905556745\n",
      "Norm of gradient at iteration 1822: 21.37047071669655\n",
      "Norm of gradient at iteration 1823: 21.271001672385985\n",
      "Norm of gradient at iteration 1824: 21.171995607637054\n",
      "Norm of gradient at iteration 1825: 21.073450367506904\n",
      "Norm of gradient at iteration 1826: 20.975363807033855\n",
      "Norm of gradient at iteration 1827: 20.877733791316277\n",
      "Norm of gradient at iteration 1828: 20.780558195382877\n",
      "Norm of gradient at iteration 1829: 20.68383490412329\n",
      "Norm of gradient at iteration 1830: 20.58756181228002\n",
      "Norm of gradient at iteration 1831: 20.491736824371444\n",
      "Norm of gradient at iteration 1832: 20.396357854731725\n",
      "Norm of gradient at iteration 1833: 20.30142282733873\n",
      "Norm of gradient at iteration 1834: 20.206929675893956\n",
      "Norm of gradient at iteration 1835: 20.112876343628777\n",
      "Norm of gradient at iteration 1836: 20.019260783462407\n",
      "Norm of gradient at iteration 1837: 19.9260809577205\n",
      "Norm of gradient at iteration 1838: 19.83333483830215\n",
      "Norm of gradient at iteration 1839: 19.74102040649125\n",
      "Norm of gradient at iteration 1840: 19.649135653032776\n",
      "Norm of gradient at iteration 1841: 19.55767857798134\n",
      "Norm of gradient at iteration 1842: 19.46664719068056\n",
      "Norm of gradient at iteration 1843: 19.376039509790434\n",
      "Norm of gradient at iteration 1844: 19.28585356315733\n",
      "Norm of gradient at iteration 1845: 19.196087387798205\n",
      "Norm of gradient at iteration 1846: 19.106739029891553\n",
      "Norm of gradient at iteration 1847: 19.01780654470235\n",
      "Norm of gradient at iteration 1848: 18.92928799652578\n",
      "Norm of gradient at iteration 1849: 18.841181458754583\n",
      "Norm of gradient at iteration 1850: 18.753485013626435\n",
      "Norm of gradient at iteration 1851: 18.666196752378774\n",
      "Norm of gradient at iteration 1852: 18.579314775102752\n",
      "Norm of gradient at iteration 1853: 18.492837190778097\n",
      "Norm of gradient at iteration 1854: 18.406762117099685\n",
      "Norm of gradient at iteration 1855: 18.32108768063758\n",
      "Norm of gradient at iteration 1856: 18.235812016576176\n",
      "Norm of gradient at iteration 1857: 18.150933268885662\n",
      "Norm of gradient at iteration 1858: 18.066449590025574\n",
      "Norm of gradient at iteration 1859: 17.98235914123839\n",
      "Norm of gradient at iteration 1860: 17.89866009216832\n",
      "Norm of gradient at iteration 1861: 17.815350621040444\n",
      "Norm of gradient at iteration 1862: 17.732428914585714\n",
      "Norm of gradient at iteration 1863: 17.649893167954623\n",
      "Norm of gradient at iteration 1864: 17.56774158468088\n",
      "Norm of gradient at iteration 1865: 17.485972376654093\n",
      "Norm of gradient at iteration 1866: 17.404583764203277\n",
      "Norm of gradient at iteration 1867: 17.323573975691318\n",
      "Norm of gradient at iteration 1868: 17.24294124796565\n",
      "Norm of gradient at iteration 1869: 17.162683825999242\n",
      "Norm of gradient at iteration 1870: 17.082799962916805\n",
      "Norm of gradient at iteration 1871: 17.00328791996904\n",
      "Norm of gradient at iteration 1872: 16.924145966536972\n",
      "Norm of gradient at iteration 1873: 16.845372380003646\n",
      "Norm of gradient at iteration 1874: 16.766965445820645\n",
      "Norm of gradient at iteration 1875: 16.68892345741034\n",
      "Norm of gradient at iteration 1876: 16.611244716118932\n",
      "Norm of gradient at iteration 1877: 16.533927531223124\n",
      "Norm of gradient at iteration 1878: 16.456970219855297\n",
      "Norm of gradient at iteration 1879: 16.38037110696298\n",
      "Norm of gradient at iteration 1880: 16.304128525335777\n",
      "Norm of gradient at iteration 1881: 16.22824081544804\n",
      "Norm of gradient at iteration 1882: 16.152706325616432\n",
      "Norm of gradient at iteration 1883: 16.077523411707276\n",
      "Norm of gradient at iteration 1884: 16.00269043731929\n",
      "Norm of gradient at iteration 1885: 15.928205773702283\n",
      "Norm of gradient at iteration 1886: 15.854067799577688\n",
      "Norm of gradient at iteration 1887: 15.780274901332227\n",
      "Norm of gradient at iteration 1888: 15.706825472755705\n",
      "Norm of gradient at iteration 1889: 15.633717915227344\n",
      "Norm of gradient at iteration 1890: 15.56095063744253\n",
      "Norm of gradient at iteration 1891: 15.488522055599736\n",
      "Norm of gradient at iteration 1892: 15.416430593224144\n",
      "Norm of gradient at iteration 1893: 15.344674681209485\n",
      "Norm of gradient at iteration 1894: 15.27325275770704\n",
      "Norm of gradient at iteration 1895: 15.202163268177316\n",
      "Norm of gradient at iteration 1896: 15.131404665305926\n",
      "Norm of gradient at iteration 1897: 15.060975408969792\n",
      "Norm of gradient at iteration 1898: 14.990873966242772\n",
      "Norm of gradient at iteration 1899: 14.92109881128385\n",
      "Norm of gradient at iteration 1900: 14.851648425387857\n",
      "Norm of gradient at iteration 1901: 14.78252129696899\n",
      "Norm of gradient at iteration 1902: 14.713715921346163\n",
      "Norm of gradient at iteration 1903: 14.645230800975975\n",
      "Norm of gradient at iteration 1904: 14.577064445172981\n",
      "Norm of gradient at iteration 1905: 14.509215370292347\n",
      "Norm of gradient at iteration 1906: 14.441682099502716\n",
      "Norm of gradient at iteration 1907: 14.374463162945878\n",
      "Norm of gradient at iteration 1908: 14.307557097541704\n",
      "Norm of gradient at iteration 1909: 14.240962446976377\n",
      "Norm of gradient at iteration 1910: 14.174677761806521\n",
      "Norm of gradient at iteration 1911: 14.108701599291125\n",
      "Norm of gradient at iteration 1912: 14.043032523394947\n",
      "Norm of gradient at iteration 1913: 13.977669104777688\n",
      "Norm of gradient at iteration 1914: 13.912609920783352\n",
      "Norm of gradient at iteration 1915: 13.847853555346497\n",
      "Norm of gradient at iteration 1916: 13.783398598961048\n",
      "Norm of gradient at iteration 1917: 13.719243648745715\n",
      "Norm of gradient at iteration 1918: 13.65538730832195\n",
      "Norm of gradient at iteration 1919: 13.591828187788863\n",
      "Norm of gradient at iteration 1920: 13.52856490377954\n",
      "Norm of gradient at iteration 1921: 13.465596079232148\n",
      "Norm of gradient at iteration 1922: 13.402920343655174\n",
      "Norm of gradient at iteration 1923: 13.34053633282084\n",
      "Norm of gradient at iteration 1924: 13.278442688943214\n",
      "Norm of gradient at iteration 1925: 13.216638060454533\n",
      "Norm of gradient at iteration 1926: 13.155121102162042\n",
      "Norm of gradient at iteration 1927: 13.093890475108477\n",
      "Norm of gradient at iteration 1928: 13.032944846534322\n",
      "Norm of gradient at iteration 1929: 12.972282889929438\n",
      "Norm of gradient at iteration 1930: 12.911903284940196\n",
      "Norm of gradient at iteration 1931: 12.851804717359077\n",
      "Norm of gradient at iteration 1932: 12.791985879087656\n",
      "Norm of gradient at iteration 1933: 12.732445468123524\n",
      "Norm of gradient at iteration 1934: 12.673182188536147\n",
      "Norm of gradient at iteration 1935: 12.61419475037596\n",
      "Norm of gradient at iteration 1936: 12.555481869770965\n",
      "Norm of gradient at iteration 1937: 12.497042268824098\n",
      "Norm of gradient at iteration 1938: 12.438874675486128\n",
      "Norm of gradient at iteration 1939: 12.380977823727017\n",
      "Norm of gradient at iteration 1940: 12.323350453379057\n",
      "Norm of gradient at iteration 1941: 12.265991310133984\n",
      "Norm of gradient at iteration 1942: 12.208899145502917\n",
      "Norm of gradient at iteration 1943: 12.152072716880914\n",
      "Norm of gradient at iteration 1944: 12.095510787390683\n",
      "Norm of gradient at iteration 1945: 12.039212125884132\n",
      "Norm of gradient at iteration 1946: 11.983175506989909\n",
      "Norm of gradient at iteration 1947: 11.927399711008881\n",
      "Norm of gradient at iteration 1948: 11.871883523964618\n",
      "Norm of gradient at iteration 1949: 11.816625737517017\n",
      "Norm of gradient at iteration 1950: 11.76162514892548\n",
      "Norm of gradient at iteration 1951: 11.706880561053815\n",
      "Norm of gradient at iteration 1952: 11.652390782370388\n",
      "Norm of gradient at iteration 1953: 11.598154626826446\n",
      "Norm of gradient at iteration 1954: 11.544170913929792\n",
      "Norm of gradient at iteration 1955: 11.490438468695599\n",
      "Norm of gradient at iteration 1956: 11.43695612162872\n",
      "Norm of gradient at iteration 1957: 11.383722708616967\n",
      "Norm of gradient at iteration 1958: 11.330737070977271\n",
      "Norm of gradient at iteration 1959: 11.277998055476044\n",
      "Norm of gradient at iteration 1960: 11.225504514165724\n",
      "Norm of gradient at iteration 1961: 11.173255304499532\n",
      "Norm of gradient at iteration 1962: 11.121249289272985\n",
      "Norm of gradient at iteration 1963: 11.069485336492543\n",
      "Norm of gradient at iteration 1964: 11.01796231949662\n",
      "Norm of gradient at iteration 1965: 10.96667911681049\n",
      "Norm of gradient at iteration 1966: 10.915634612241403\n",
      "Norm of gradient at iteration 1967: 10.864827694754931\n",
      "Norm of gradient at iteration 1968: 10.814257258546148\n",
      "Norm of gradient at iteration 1969: 10.763922202890571\n",
      "Norm of gradient at iteration 1970: 10.713821432182296\n",
      "Norm of gradient at iteration 1971: 10.663953855971497\n",
      "Norm of gradient at iteration 1972: 10.61431838878972\n",
      "Norm of gradient at iteration 1973: 10.56491395035945\n",
      "Norm of gradient at iteration 1974: 10.515739465312597\n",
      "Norm of gradient at iteration 1975: 10.466793863343707\n",
      "Norm of gradient at iteration 1976: 10.418076079108202\n",
      "Norm of gradient at iteration 1977: 10.36958505222329\n",
      "Norm of gradient at iteration 1978: 10.321319727236435\n",
      "Norm of gradient at iteration 1979: 10.273279053671\n",
      "Norm of gradient at iteration 1980: 10.225461985809206\n",
      "Norm of gradient at iteration 1981: 10.177867482927091\n",
      "Norm of gradient at iteration 1982: 10.13049450907274\n",
      "Norm of gradient at iteration 1983: 10.083342033147252\n",
      "Norm of gradient at iteration 1984: 10.036409028819564\n",
      "Norm of gradient at iteration 1985: 9.98969447459458\n",
      "Norm of gradient at iteration 1986: 9.943197353665678\n",
      "Norm of gradient at iteration 1987: 9.896916654000616\n",
      "Norm of gradient at iteration 1988: 9.850851368253466\n",
      "Norm of gradient at iteration 1989: 9.805000493774193\n",
      "Norm of gradient at iteration 1990: 9.759363032613107\n",
      "Norm of gradient at iteration 1991: 9.713937991401481\n",
      "Norm of gradient at iteration 1992: 9.668724381463553\n",
      "Norm of gradient at iteration 1993: 9.623721218666718\n",
      "Norm of gradient at iteration 1994: 9.578927523466366\n",
      "Norm of gradient at iteration 1995: 9.534342320908952\n",
      "Norm of gradient at iteration 1996: 9.489964640605043\n",
      "Norm of gradient at iteration 1997: 9.445793516564251\n",
      "Norm of gradient at iteration 1998: 9.401827987419983\n",
      "Norm of gradient at iteration 1999: 9.358067096255366\n",
      "Norm of gradient at iteration 2000: 9.314509890499885\n",
      "Norm of gradient at iteration 2001: 9.271155422181161\n",
      "Norm of gradient at iteration 2002: 9.22800274760715\n",
      "Norm of gradient at iteration 2003: 9.185050927498544\n",
      "Norm of gradient at iteration 2004: 9.14229902704787\n",
      "Norm of gradient at iteration 2005: 9.099746115694096\n",
      "Norm of gradient at iteration 2006: 9.057391267228523\n",
      "Norm of gradient at iteration 2007: 9.015233559825518\n",
      "Norm of gradient at iteration 2008: 8.973272075800239\n",
      "Norm of gradient at iteration 2009: 8.931505901858282\n",
      "Norm of gradient at iteration 2010: 8.889934128986107\n",
      "Norm of gradient at iteration 2011: 8.848555852256602\n",
      "Norm of gradient at iteration 2012: 8.807370171105617\n",
      "Norm of gradient at iteration 2013: 8.766376189055954\n",
      "Norm of gradient at iteration 2014: 8.725573013842505\n",
      "Norm of gradient at iteration 2015: 8.684959757391347\n",
      "Norm of gradient at iteration 2016: 8.644535535702081\n",
      "Norm of gradient at iteration 2017: 8.604299468894489\n",
      "Norm of gradient at iteration 2018: 8.56425068122994\n",
      "Norm of gradient at iteration 2019: 8.524388300992184\n",
      "Norm of gradient at iteration 2020: 8.484711460582004\n",
      "Norm of gradient at iteration 2021: 8.445219296337717\n",
      "Norm of gradient at iteration 2022: 8.40591094874093\n",
      "Norm of gradient at iteration 2023: 8.36678556219816\n",
      "Norm of gradient at iteration 2024: 8.327842285101802\n",
      "Norm of gradient at iteration 2025: 8.28908026980795\n",
      "Norm of gradient at iteration 2026: 8.250498672684225\n",
      "Norm of gradient at iteration 2027: 8.212096653935754\n",
      "Norm of gradient at iteration 2028: 8.173873377717396\n",
      "Norm of gradient at iteration 2029: 8.13582801207931\n",
      "Norm of gradient at iteration 2030: 8.097959728929116\n",
      "Norm of gradient at iteration 2031: 8.060267704035828\n",
      "Norm of gradient at iteration 2032: 8.022751117002166\n",
      "Norm of gradient at iteration 2033: 7.98540915125361\n",
      "Norm of gradient at iteration 2034: 7.948240994017914\n",
      "Norm of gradient at iteration 2035: 7.911245836286924\n",
      "Norm of gradient at iteration 2036: 7.874422872888446\n",
      "Norm of gradient at iteration 2037: 7.837771302243304\n",
      "Norm of gradient at iteration 2038: 7.801290326667701\n",
      "Norm of gradient at iteration 2039: 7.764979152123986\n",
      "Norm of gradient at iteration 2040: 7.728836988259816\n",
      "Norm of gradient at iteration 2041: 7.69286304843994\n",
      "Norm of gradient at iteration 2042: 7.657056549627023\n",
      "Norm of gradient at iteration 2043: 7.621416712458646\n",
      "Norm of gradient at iteration 2044: 7.585942761233153\n",
      "Norm of gradient at iteration 2045: 7.550633923827682\n",
      "Norm of gradient at iteration 2046: 7.5154894317064835\n",
      "Norm of gradient at iteration 2047: 7.480508519963599\n",
      "Norm of gradient at iteration 2048: 7.445690427168812\n",
      "Norm of gradient at iteration 2049: 7.411034395483254\n",
      "Norm of gradient at iteration 2050: 7.376539670633347\n",
      "Norm of gradient at iteration 2051: 7.342205501769772\n",
      "Norm of gradient at iteration 2052: 7.308031141562537\n",
      "Norm of gradient at iteration 2053: 7.274015846215775\n",
      "Norm of gradient at iteration 2054: 7.240158875424784\n",
      "Norm of gradient at iteration 2055: 7.206459492141358\n",
      "Norm of gradient at iteration 2056: 7.172916962945028\n",
      "Norm of gradient at iteration 2057: 7.139530557767993\n",
      "Norm of gradient at iteration 2058: 7.106299549905729\n",
      "Norm of gradient at iteration 2059: 7.073223216030508\n",
      "Norm of gradient at iteration 2060: 7.040300836253548\n",
      "Norm of gradient at iteration 2061: 7.007531693990526\n",
      "Norm of gradient at iteration 2062: 6.974915075992338\n",
      "Norm of gradient at iteration 2063: 6.942450272359502\n",
      "Norm of gradient at iteration 2064: 6.910136576404547\n",
      "Norm of gradient at iteration 2065: 6.877973284838223\n",
      "Norm of gradient at iteration 2066: 6.845959697606884\n",
      "Norm of gradient at iteration 2067: 6.814095117883885\n",
      "Norm of gradient at iteration 2068: 6.782378852146729\n",
      "Norm of gradient at iteration 2069: 6.7508102100434915\n",
      "Norm of gradient at iteration 2070: 6.719388504434371\n",
      "Norm of gradient at iteration 2071: 6.688113051485558\n",
      "Norm of gradient at iteration 2072: 6.656983170379232\n",
      "Norm of gradient at iteration 2073: 6.6259981835774635\n",
      "Norm of gradient at iteration 2074: 6.595157416663829\n",
      "Norm of gradient at iteration 2075: 6.564460198381807\n",
      "Norm of gradient at iteration 2076: 6.533905860569856\n",
      "Norm of gradient at iteration 2077: 6.503493738194083\n",
      "Norm of gradient at iteration 2078: 6.473223169320873\n",
      "Norm of gradient at iteration 2079: 6.443093495055181\n",
      "Norm of gradient at iteration 2080: 6.4131040596370275\n",
      "Norm of gradient at iteration 2081: 6.383254210306942\n",
      "Norm of gradient at iteration 2082: 6.353543297370786\n",
      "Norm of gradient at iteration 2083: 6.3239706741227755\n",
      "Norm of gradient at iteration 2084: 6.294535696905189\n",
      "Norm of gradient at iteration 2085: 6.265237725077005\n",
      "Norm of gradient at iteration 2086: 6.236076120870669\n",
      "Norm of gradient at iteration 2087: 6.207050249647231\n",
      "Norm of gradient at iteration 2088: 6.178159479587179\n",
      "Norm of gradient at iteration 2089: 6.14940318186713\n",
      "Norm of gradient at iteration 2090: 6.120780730588485\n",
      "Norm of gradient at iteration 2091: 6.0922915027704345\n",
      "Norm of gradient at iteration 2092: 6.063934878315778\n",
      "Norm of gradient at iteration 2093: 6.035710239994486\n",
      "Norm of gradient at iteration 2094: 6.007616973524885\n",
      "Norm of gradient at iteration 2095: 5.979654467400186\n",
      "Norm of gradient at iteration 2096: 5.95182211302003\n",
      "Norm of gradient at iteration 2097: 5.924119304545833\n",
      "Norm of gradient at iteration 2098: 5.896545439066246\n",
      "Norm of gradient at iteration 2099: 5.869099916380538\n",
      "Norm of gradient at iteration 2100: 5.841782139122763\n",
      "Norm of gradient at iteration 2101: 5.814591512696914\n",
      "Norm of gradient at iteration 2102: 5.787527445275517\n",
      "Norm of gradient at iteration 2103: 5.760589347805559\n",
      "Norm of gradient at iteration 2104: 5.733776633951782\n",
      "Norm of gradient at iteration 2105: 5.7070887201002325\n",
      "Norm of gradient at iteration 2106: 5.680525025363294\n",
      "Norm of gradient at iteration 2107: 5.654084971625061\n",
      "Norm of gradient at iteration 2108: 5.627767983302878\n",
      "Norm of gradient at iteration 2109: 5.6015734876818915\n",
      "Norm of gradient at iteration 2110: 5.575500914520719\n",
      "Norm of gradient at iteration 2111: 5.54954969641701\n",
      "Norm of gradient at iteration 2112: 5.523719268472518\n",
      "Norm of gradient at iteration 2113: 5.498009068472784\n",
      "Norm of gradient at iteration 2114: 5.472418536826335\n",
      "Norm of gradient at iteration 2115: 5.446947116549232\n",
      "Norm of gradient at iteration 2116: 5.421594253201061\n",
      "Norm of gradient at iteration 2117: 5.396359395009496\n",
      "Norm of gradient at iteration 2118: 5.371241992675001\n",
      "Norm of gradient at iteration 2119: 5.346241499498799\n",
      "Norm of gradient at iteration 2120: 5.321357371395283\n",
      "Norm of gradient at iteration 2121: 5.296589066616626\n",
      "Norm of gradient at iteration 2122: 5.271936046167818\n",
      "Norm of gradient at iteration 2123: 5.247397773402656\n",
      "Norm of gradient at iteration 2124: 5.222973714253116\n",
      "Norm of gradient at iteration 2125: 5.198663337078956\n",
      "Norm of gradient at iteration 2126: 5.174466112796947\n",
      "Norm of gradient at iteration 2127: 5.150381514692292\n",
      "Norm of gradient at iteration 2128: 5.126409018567185\n",
      "Norm of gradient at iteration 2129: 5.1025481026486785\n",
      "Norm of gradient at iteration 2130: 5.078798247553948\n",
      "Norm of gradient at iteration 2131: 5.055158936381367\n",
      "Norm of gradient at iteration 2132: 5.031629654579499\n",
      "Norm of gradient at iteration 2133: 5.008209890048165\n",
      "Norm of gradient at iteration 2134: 4.984899133019896\n",
      "Norm of gradient at iteration 2135: 4.961696876081873\n",
      "Norm of gradient at iteration 2136: 4.938602614257306\n",
      "Norm of gradient at iteration 2137: 4.915615844899162\n",
      "Norm of gradient at iteration 2138: 4.892736067658834\n",
      "Norm of gradient at iteration 2139: 4.869962784536516\n",
      "Norm of gradient at iteration 2140: 4.8472954998246385\n",
      "Norm of gradient at iteration 2141: 4.824733720240318\n",
      "Norm of gradient at iteration 2142: 4.8022769546308535\n",
      "Norm of gradient at iteration 2143: 4.7799247142683985\n",
      "Norm of gradient at iteration 2144: 4.7576765125638945\n",
      "Norm of gradient at iteration 2145: 4.7355318653280625\n",
      "Norm of gradient at iteration 2146: 4.713490290551471\n",
      "Norm of gradient at iteration 2147: 4.691551308489852\n",
      "Norm of gradient at iteration 2148: 4.669714441603264\n",
      "Norm of gradient at iteration 2149: 4.647979214584733\n",
      "Norm of gradient at iteration 2150: 4.626345154395903\n",
      "Norm of gradient at iteration 2151: 4.6048117901300305\n",
      "Norm of gradient at iteration 2152: 4.583378653082034\n",
      "Norm of gradient at iteration 2153: 4.562045276767054\n",
      "Norm of gradient at iteration 2154: 4.540811196826855\n",
      "Norm of gradient at iteration 2155: 4.519675951103097\n",
      "Norm of gradient at iteration 2156: 4.498639079611092\n",
      "Norm of gradient at iteration 2157: 4.477700124390742\n",
      "Norm of gradient at iteration 2158: 4.456858629709813\n",
      "Norm of gradient at iteration 2159: 4.436114141955296\n",
      "Norm of gradient at iteration 2160: 4.415466209600573\n",
      "Norm of gradient at iteration 2161: 4.3949143832464985\n",
      "Norm of gradient at iteration 2162: 4.37445821555749\n",
      "Norm of gradient at iteration 2163: 4.354097261241516\n",
      "Norm of gradient at iteration 2164: 4.333831077173453\n",
      "Norm of gradient at iteration 2165: 4.313659222278158\n",
      "Norm of gradient at iteration 2166: 4.2935812574324475\n",
      "Norm of gradient at iteration 2167: 4.273596745653679\n",
      "Norm of gradient at iteration 2168: 4.253705251929974\n",
      "Norm of gradient at iteration 2169: 4.2339063433681625\n",
      "Norm of gradient at iteration 2170: 4.214199588996689\n",
      "Norm of gradient at iteration 2171: 4.194584559891473\n",
      "Norm of gradient at iteration 2172: 4.1750608291413185\n",
      "Norm of gradient at iteration 2173: 4.155627971691663\n",
      "Norm of gradient at iteration 2174: 4.13628556468017\n",
      "Norm of gradient at iteration 2175: 4.117033187110203\n",
      "Norm of gradient at iteration 2176: 4.097870419877789\n",
      "Norm of gradient at iteration 2177: 4.078796845911454\n",
      "Norm of gradient at iteration 2178: 4.059812050088621\n",
      "Norm of gradient at iteration 2179: 4.040915619129465\n",
      "Norm of gradient at iteration 2180: 4.02210714179158\n",
      "Norm of gradient at iteration 2181: 4.0033862086891885\n",
      "Norm of gradient at iteration 2182: 3.984752412323179\n",
      "Norm of gradient at iteration 2183: 3.9662053471157313\n",
      "Norm of gradient at iteration 2184: 3.947744609404559\n",
      "Norm of gradient at iteration 2185: 3.929369797337966\n",
      "Norm of gradient at iteration 2186: 3.9110805110092444\n",
      "Norm of gradient at iteration 2187: 3.8928763523277654\n",
      "Norm of gradient at iteration 2188: 3.874756925059477\n",
      "Norm of gradient at iteration 2189: 3.856721834811218\n",
      "Norm of gradient at iteration 2190: 3.8387706890538884\n",
      "Norm of gradient at iteration 2191: 3.820903097077106\n",
      "Norm of gradient at iteration 2192: 3.803118669940807\n",
      "Norm of gradient at iteration 2193: 3.785417020596765\n",
      "Norm of gradient at iteration 2194: 3.7677977637345115\n",
      "Norm of gradient at iteration 2195: 3.7502605158447206\n",
      "Norm of gradient at iteration 2196: 3.7328048952562214\n",
      "Norm of gradient at iteration 2197: 3.715430522006187\n",
      "Norm of gradient at iteration 2198: 3.6981370178800868\n",
      "Norm of gradient at iteration 2199: 3.6809240065712863\n",
      "Norm of gradient at iteration 2200: 3.66379111336472\n",
      "Norm of gradient at iteration 2201: 3.6467379653449\n",
      "Norm of gradient at iteration 2202: 3.629764191383964\n",
      "Norm of gradient at iteration 2203: 3.6128694219815127\n",
      "Norm of gradient at iteration 2204: 3.596053289425344\n",
      "Norm of gradient at iteration 2205: 3.5793154277052435\n",
      "Norm of gradient at iteration 2206: 3.5626554725236352\n",
      "Norm of gradient at iteration 2207: 3.546073061259826\n",
      "Norm of gradient at iteration 2208: 3.5295678329507116\n",
      "Norm of gradient at iteration 2209: 3.5131394283612036\n",
      "Norm of gradient at iteration 2210: 3.496787489953263\n",
      "Norm of gradient at iteration 2211: 3.4805116618041763\n",
      "Norm of gradient at iteration 2212: 3.4643115896125525\n",
      "Norm of gradient at iteration 2213: 3.448186920805173\n",
      "Norm of gradient at iteration 2214: 3.432137304418942\n",
      "Norm of gradient at iteration 2215: 3.4161623911208263\n",
      "Norm of gradient at iteration 2216: 3.4002618331574226\n",
      "Norm of gradient at iteration 2217: 3.3844352845096655\n",
      "Norm of gradient at iteration 2218: 3.368682400679247\n",
      "Norm of gradient at iteration 2219: 3.3530028387477113\n",
      "Norm of gradient at iteration 2220: 3.3373962575266964\n",
      "Norm of gradient at iteration 2221: 3.3218623172445585\n",
      "Norm of gradient at iteration 2222: 3.306400679820631\n",
      "Norm of gradient at iteration 2223: 3.2910110087324034\n",
      "Norm of gradient at iteration 2224: 3.275692968991697\n",
      "Norm of gradient at iteration 2225: 3.2604462272240466\n",
      "Norm of gradient at iteration 2226: 3.2452704515147413\n",
      "Norm of gradient at iteration 2227: 3.2301653116305378\n",
      "Norm of gradient at iteration 2228: 3.215130478705507\n",
      "Norm of gradient at iteration 2229: 3.200165625591215\n",
      "Norm of gradient at iteration 2230: 3.1852704264836715\n",
      "Norm of gradient at iteration 2231: 3.1704445572259625\n",
      "Norm of gradient at iteration 2232: 3.155687695096332\n",
      "Norm of gradient at iteration 2233: 3.14099951894911\n",
      "Norm of gradient at iteration 2234: 3.12637970902838\n",
      "Norm of gradient at iteration 2235: 3.111827947138239\n",
      "Norm of gradient at iteration 2236: 3.097343916530454\n",
      "Norm of gradient at iteration 2237: 3.082927301990721\n",
      "Norm of gradient at iteration 2238: 3.068577789701697\n",
      "Norm of gradient at iteration 2239: 3.0542950673423794\n",
      "Norm of gradient at iteration 2240: 3.040078824053087\n",
      "Norm of gradient at iteration 2241: 3.0259287503929087\n",
      "Norm of gradient at iteration 2242: 3.0118445383612267\n",
      "Norm of gradient at iteration 2243: 2.997825881441502\n",
      "Norm of gradient at iteration 2244: 2.9838724744660934\n",
      "Norm of gradient at iteration 2245: 2.969984013744141\n",
      "Norm of gradient at iteration 2246: 2.9561601969942366\n",
      "Norm of gradient at iteration 2247: 2.9424007233193405\n",
      "Norm of gradient at iteration 2248: 2.9287052932302333\n",
      "Norm of gradient at iteration 2249: 2.915073608648496\n",
      "Norm of gradient at iteration 2250: 2.901505372853048\n",
      "Norm of gradient at iteration 2251: 2.8880002905324687\n",
      "Norm of gradient at iteration 2252: 2.874558067728663\n",
      "Norm of gradient at iteration 2253: 2.8611784118980186\n",
      "Norm of gradient at iteration 2254: 2.847861031782211\n",
      "Norm of gradient at iteration 2255: 2.834605637506921\n",
      "Norm of gradient at iteration 2256: 2.8214119406065006\n",
      "Norm of gradient at iteration 2257: 2.808279653884165\n",
      "Norm of gradient at iteration 2258: 2.7952084914902366\n",
      "Norm of gradient at iteration 2259: 2.782198168930822\n",
      "Norm of gradient at iteration 2260: 2.769248403061529\n",
      "Norm of gradient at iteration 2261: 2.756358911966914\n",
      "Norm of gradient at iteration 2262: 2.7435294151436747\n",
      "Norm of gradient at iteration 2263: 2.7307596332855204\n",
      "Norm of gradient at iteration 2264: 2.7180492885478724\n",
      "Norm of gradient at iteration 2265: 2.705398104197103\n",
      "Norm of gradient at iteration 2266: 2.6928058048960994\n",
      "Norm of gradient at iteration 2267: 2.680272116551477\n",
      "Norm of gradient at iteration 2268: 2.667796766379397\n",
      "Norm of gradient at iteration 2269: 2.655379482836797\n",
      "Norm of gradient at iteration 2270: 2.64301999561984\n",
      "Norm of gradient at iteration 2271: 2.630718035767666\n",
      "Norm of gradient at iteration 2272: 2.6184733354925074\n",
      "Norm of gradient at iteration 2273: 2.606285628329766\n",
      "Norm of gradient at iteration 2274: 2.594154648872484\n",
      "Norm of gradient at iteration 2275: 2.582080133225799\n",
      "Norm of gradient at iteration 2276: 2.5700618185049886\n",
      "Norm of gradient at iteration 2277: 2.5580994431374084\n",
      "Norm of gradient at iteration 2278: 2.546192746741023\n",
      "Norm of gradient at iteration 2279: 2.534341470168387\n",
      "Norm of gradient at iteration 2280: 2.522545355474116\n",
      "Norm of gradient at iteration 2281: 2.510804145900796\n",
      "Norm of gradient at iteration 2282: 2.4991175859025003\n",
      "Norm of gradient at iteration 2283: 2.4874854210822055\n",
      "Norm of gradient at iteration 2284: 2.4759073982830464\n",
      "Norm of gradient at iteration 2285: 2.4643832654878484\n",
      "Norm of gradient at iteration 2286: 2.45291277188605\n",
      "Norm of gradient at iteration 2287: 2.441495667780023\n",
      "Norm of gradient at iteration 2288: 2.430131704698618\n",
      "Norm of gradient at iteration 2289: 2.4188206352632045\n",
      "Norm of gradient at iteration 2290: 2.4075622133050034\n",
      "Norm of gradient at iteration 2291: 2.3963561937766054\n",
      "Norm of gradient at iteration 2292: 2.385202332763832\n",
      "Norm of gradient at iteration 2293: 2.3741003875005147\n",
      "Norm of gradient at iteration 2294: 2.3630501163130457\n",
      "Norm of gradient at iteration 2295: 2.352051278743216\n",
      "Norm of gradient at iteration 2296: 2.3411036353528942\n",
      "Norm of gradient at iteration 2297: 2.33020694786915\n",
      "Norm of gradient at iteration 2298: 2.3193609790877505\n",
      "Norm of gradient at iteration 2299: 2.3085654929949593\n",
      "Norm of gradient at iteration 2300: 2.2978202545596087\n",
      "Norm of gradient at iteration 2301: 2.287125029958114\n",
      "Norm of gradient at iteration 2302: 2.2764795863445353\n",
      "Norm of gradient at iteration 2303: 2.26588369205196\n",
      "Norm of gradient at iteration 2304: 2.2553371164585174\n",
      "Norm of gradient at iteration 2305: 2.244839629984554\n",
      "Norm of gradient at iteration 2306: 2.2343910041608916\n",
      "Norm of gradient at iteration 2307: 2.2239910115514867\n",
      "Norm of gradient at iteration 2308: 2.213639425811977\n",
      "Norm of gradient at iteration 2309: 2.2033360215984628\n",
      "Norm of gradient at iteration 2310: 2.1930805746695032\n",
      "Norm of gradient at iteration 2311: 2.182872861829882\n",
      "Norm of gradient at iteration 2312: 2.1727126608515626\n",
      "Norm of gradient at iteration 2313: 2.162599750639373\n",
      "Norm of gradient at iteration 2314: 2.1525339110506163\n",
      "Norm of gradient at iteration 2315: 2.14251492301131\n",
      "Norm of gradient at iteration 2316: 2.132542568423911\n",
      "Norm of gradient at iteration 2317: 2.122616630246251\n",
      "Norm of gradient at iteration 2318: 2.1127368924609993\n",
      "Norm of gradient at iteration 2319: 2.102903139996624\n",
      "Norm of gradient at iteration 2320: 2.0931151588030885\n",
      "Norm of gradient at iteration 2321: 2.0833727358341005\n",
      "Norm of gradient at iteration 2322: 2.0736756590803567\n",
      "Norm of gradient at iteration 2323: 2.0640237174825766\n",
      "Norm of gradient at iteration 2324: 2.0544167009167604\n",
      "Norm of gradient at iteration 2325: 2.0448544002757068\n",
      "Norm of gradient at iteration 2326: 2.0353366074743535\n",
      "Norm of gradient at iteration 2327: 2.0258631152877418\n",
      "Norm of gradient at iteration 2328: 2.016433717563003\n",
      "Norm of gradient at iteration 2329: 2.0070482090578268\n",
      "Norm of gradient at iteration 2330: 1.9977063854924286\n",
      "Norm of gradient at iteration 2331: 1.988408043522852\n",
      "Norm of gradient at iteration 2332: 1.9791529807738737\n",
      "Norm of gradient at iteration 2333: 1.9699409957934837\n",
      "Norm of gradient at iteration 2334: 1.960771888075745\n",
      "Norm of gradient at iteration 2335: 1.9516454580456843\n",
      "Norm of gradient at iteration 2336: 1.9425615070766973\n",
      "Norm of gradient at iteration 2337: 1.9335198374326616\n",
      "Norm of gradient at iteration 2338: 1.9245202523288736\n",
      "Norm of gradient at iteration 2339: 1.9155625558734886\n",
      "Norm of gradient at iteration 2340: 1.90664655308255\n",
      "Norm of gradient at iteration 2341: 1.8977720499057829\n",
      "Norm of gradient at iteration 2342: 1.8889388531819458\n",
      "Norm of gradient at iteration 2343: 1.8801467706499226\n",
      "Norm of gradient at iteration 2344: 1.8713956109175014\n",
      "Norm of gradient at iteration 2345: 1.8626851835695863\n",
      "Norm of gradient at iteration 2346: 1.8540152989631424\n",
      "Norm of gradient at iteration 2347: 1.8453857684403785\n",
      "Norm of gradient at iteration 2348: 1.8367964041153189\n",
      "Norm of gradient at iteration 2349: 1.8282470190762306\n",
      "Norm of gradient at iteration 2350: 1.8197374272161224\n",
      "Norm of gradient at iteration 2351: 1.8112674433233835\n",
      "Norm of gradient at iteration 2352: 1.802836883051686\n",
      "Norm of gradient at iteration 2353: 1.794445562884179\n",
      "Norm of gradient at iteration 2354: 1.7860933002190693\n",
      "Norm of gradient at iteration 2355: 1.777779913197177\n",
      "Norm of gradient at iteration 2356: 1.7695052209209257\n",
      "Norm of gradient at iteration 2357: 1.761269043295219\n",
      "Norm of gradient at iteration 2358: 1.7530712010198843\n",
      "Norm of gradient at iteration 2359: 1.7449115156759978\n",
      "Norm of gradient at iteration 2360: 1.7367898096481105\n",
      "Norm of gradient at iteration 2361: 1.7287059061940337\n",
      "Norm of gradient at iteration 2362: 1.7206596293340664\n",
      "Norm of gradient at iteration 2363: 1.7126508039329114\n",
      "Norm of gradient at iteration 2364: 1.7046792556738826\n",
      "Norm of gradient at iteration 2365: 1.696744811068326\n",
      "Norm of gradient at iteration 2366: 1.6888472974135333\n",
      "Norm of gradient at iteration 2367: 1.6809865427976551\n",
      "Norm of gradient at iteration 2368: 1.6731623761137069\n",
      "Norm of gradient at iteration 2369: 1.6653746271102408\n",
      "Norm of gradient at iteration 2370: 1.6576231262313414\n",
      "Norm of gradient at iteration 2371: 1.6499077047833641\n",
      "Norm of gradient at iteration 2372: 1.642228194851219\n",
      "Norm of gradient at iteration 2373: 1.634584429282278\n",
      "Norm of gradient at iteration 2374: 1.626976241625255\n",
      "Norm of gradient at iteration 2375: 1.6194034664015768\n",
      "Norm of gradient at iteration 2376: 1.6118659386900374\n",
      "Norm of gradient at iteration 2377: 1.6043634944957432\n",
      "Norm of gradient at iteration 2378: 1.5968959704668817\n",
      "Norm of gradient at iteration 2379: 1.589463204106548\n",
      "Norm of gradient at iteration 2380: 1.582065033635471\n",
      "Norm of gradient at iteration 2381: 1.5747012979884827\n",
      "Norm of gradient at iteration 2382: 1.5673718369421141\n",
      "Norm of gradient at iteration 2383: 1.5600764909308027\n",
      "Norm of gradient at iteration 2384: 1.5528151011577402\n",
      "Norm of gradient at iteration 2385: 1.5455875095897076\n",
      "Norm of gradient at iteration 2386: 1.5383935589145854\n",
      "Norm of gradient at iteration 2387: 1.5312330925329825\n",
      "Norm of gradient at iteration 2388: 1.5241059546107394\n",
      "Norm of gradient at iteration 2389: 1.5170119900150676\n",
      "Norm of gradient at iteration 2390: 1.5099510443533846\n",
      "Norm of gradient at iteration 2391: 1.502922963916306\n",
      "Norm of gradient at iteration 2392: 1.4959275957729778\n",
      "Norm of gradient at iteration 2393: 1.4889647875842147\n",
      "Norm of gradient at iteration 2394: 1.482034387872237\n",
      "Norm of gradient at iteration 2395: 1.4751362457643786\n",
      "Norm of gradient at iteration 2396: 1.4682702111245811\n",
      "Norm of gradient at iteration 2397: 1.4614361344787243\n",
      "Norm of gradient at iteration 2398: 1.4546338671187662\n",
      "Norm of gradient at iteration 2399: 1.4478632609820985\n",
      "Norm of gradient at iteration 2400: 1.4411241686666416\n",
      "Norm of gradient at iteration 2401: 1.4344164435469888\n",
      "Norm of gradient at iteration 2402: 1.4277399395559272\n",
      "Norm of gradient at iteration 2403: 1.4210945114450275\n",
      "Norm of gradient at iteration 2404: 1.4144800145065817\n",
      "Norm of gradient at iteration 2405: 1.4078963048365085\n",
      "Norm of gradient at iteration 2406: 1.4013432390771603\n",
      "Norm of gradient at iteration 2407: 1.3948206746270353\n",
      "Norm of gradient at iteration 2408: 1.3883284695127376\n",
      "Norm of gradient at iteration 2409: 1.3818664824269877\n",
      "Norm of gradient at iteration 2410: 1.3754345726909987\n",
      "Norm of gradient at iteration 2411: 1.3690326003473121\n",
      "Norm of gradient at iteration 2412: 1.362660426079943\n",
      "Norm of gradient at iteration 2413: 1.3563179111079149\n",
      "Norm of gradient at iteration 2414: 1.3500049174261233\n",
      "Norm of gradient at iteration 2415: 1.3437213076656533\n",
      "Norm of gradient at iteration 2416: 1.337466945018038\n",
      "Norm of gradient at iteration 2417: 1.3312416933382294\n",
      "Norm of gradient at iteration 2418: 1.3250454171472603\n",
      "Norm of gradient at iteration 2419: 1.3188779815511293\n",
      "Norm of gradient at iteration 2420: 1.3127392524175012\n",
      "Norm of gradient at iteration 2421: 1.3066290959954776\n",
      "Norm of gradient at iteration 2422: 1.300547379369684\n",
      "Norm of gradient at iteration 2423: 1.2944939701340212\n",
      "Norm of gradient at iteration 2424: 1.2884687365555763\n",
      "Norm of gradient at iteration 2425: 1.2824715474641772\n",
      "Norm of gradient at iteration 2426: 1.276502272353938\n",
      "Norm of gradient at iteration 2427: 1.270560781295931\n",
      "Norm of gradient at iteration 2428: 1.26464694492597\n",
      "Norm of gradient at iteration 2429: 1.258760634582168\n",
      "Norm of gradient at iteration 2430: 1.252901722121428\n",
      "Norm of gradient at iteration 2431: 1.2470700800308463\n",
      "Norm of gradient at iteration 2432: 1.2412655813425615\n",
      "Norm of gradient at iteration 2433: 1.2354880997486508\n",
      "Norm of gradient at iteration 2434: 1.229737509515216\n",
      "Norm of gradient at iteration 2435: 1.2240136854535897\n",
      "Norm of gradient at iteration 2436: 1.2183165029522889\n",
      "Norm of gradient at iteration 2437: 1.212645838065889\n",
      "Norm of gradient at iteration 2438: 1.2070015673332577\n",
      "Norm of gradient at iteration 2439: 1.201383567934097\n",
      "Norm of gradient at iteration 2440: 1.1957917175211523\n",
      "Norm of gradient at iteration 2441: 1.1902258944267536\n",
      "Norm of gradient at iteration 2442: 1.1846859775497431\n",
      "Norm of gradient at iteration 2443: 1.1791718462391179\n",
      "Norm of gradient at iteration 2444: 1.1736833804716857\n",
      "Norm of gradient at iteration 2445: 1.1682204608422109\n",
      "Norm of gradient at iteration 2446: 1.1627829684184914\n",
      "Norm of gradient at iteration 2447: 1.1573707848801624\n",
      "Norm of gradient at iteration 2448: 1.151983792351798\n",
      "Norm of gradient at iteration 2449: 1.1466218736363296\n",
      "Norm of gradient at iteration 2450: 1.141284912028476\n",
      "Norm of gradient at iteration 2451: 1.1359727913401136\n",
      "Norm of gradient at iteration 2452: 1.1306853959844567\n",
      "Norm of gradient at iteration 2453: 1.1254226108303558\n",
      "Norm of gradient at iteration 2454: 1.12018432138845\n",
      "Norm of gradient at iteration 2455: 1.11497041363008\n",
      "Norm of gradient at iteration 2456: 1.1097807739800702\n",
      "Norm of gradient at iteration 2457: 1.10461528962082\n",
      "Norm of gradient at iteration 2458: 1.0994738480216844\n",
      "Norm of gradient at iteration 2459: 1.094356337308393\n",
      "Norm of gradient at iteration 2460: 1.0892626460933563\n",
      "Norm of gradient at iteration 2461: 1.084192663520539\n",
      "Norm of gradient at iteration 2462: 1.0791462792081783\n",
      "Norm of gradient at iteration 2463: 1.0741233833484654\n",
      "Norm of gradient at iteration 2464: 1.0691238666077971\n",
      "Norm of gradient at iteration 2465: 1.064147620149767\n",
      "Norm of gradient at iteration 2466: 1.0591945356666714\n",
      "Norm of gradient at iteration 2467: 1.054264505353302\n",
      "Norm of gradient at iteration 2468: 1.049357421935104\n",
      "Norm of gradient at iteration 2469: 1.044473178590508\n",
      "Norm of gradient at iteration 2470: 1.0396116689796477\n",
      "Norm of gradient at iteration 2471: 1.0347727872923933\n",
      "Norm of gradient at iteration 2472: 1.029956428238158\n",
      "Norm of gradient at iteration 2473: 1.0251624869710299\n",
      "Norm of gradient at iteration 2474: 1.0203908591442237\n",
      "Norm of gradient at iteration 2475: 1.0156414409121803\n",
      "Norm of gradient at iteration 2476: 1.010914128873675\n",
      "Norm of gradient at iteration 2477: 1.0062088201530734\n",
      "Norm of gradient at iteration 2478: 1.0015254123294752\n",
      "Norm of gradient at iteration 2479: 0.996863803461091\n",
      "Norm of gradient at iteration 2480: 0.9922238921166483\n",
      "Norm of gradient at iteration 2481: 0.9876055772927101\n",
      "Norm of gradient at iteration 2482: 0.9830087584320542\n",
      "Norm of gradient at iteration 2483: 0.9784333354966448\n",
      "Norm of gradient at iteration 2484: 0.9738792089234147\n",
      "Norm of gradient at iteration 2485: 0.969346279574802\n",
      "Norm of gradient at iteration 2486: 0.9648344487800504\n",
      "Norm of gradient at iteration 2487: 0.9603436183528163\n",
      "Norm of gradient at iteration 2488: 0.9558736905319921\n",
      "Norm of gradient at iteration 2489: 0.951424567993899\n",
      "Norm of gradient at iteration 2490: 0.9469961539651557\n",
      "Norm of gradient at iteration 2491: 0.9425883520423752\n",
      "Norm of gradient at iteration 2492: 0.9382010662582879\n",
      "Norm of gradient at iteration 2493: 0.9338342011391889\n",
      "Norm of gradient at iteration 2494: 0.9294876616279861\n",
      "Norm of gradient at iteration 2495: 0.9251613531128695\n",
      "Norm of gradient at iteration 2496: 0.9208551814413725\n",
      "Norm of gradient at iteration 2497: 0.9165690528570423\n",
      "Norm of gradient at iteration 2498: 0.9123028741467726\n",
      "Norm of gradient at iteration 2499: 0.9080565523774035\n",
      "Norm of gradient at iteration 2500: 0.9038299951683152\n",
      "Norm of gradient at iteration 2501: 0.899623110475992\n",
      "Norm of gradient at iteration 2502: 0.8954358068153188\n",
      "Norm of gradient at iteration 2503: 0.8912679929339735\n",
      "Norm of gradient at iteration 2504: 0.8871195782282394\n",
      "Norm of gradient at iteration 2505: 0.8829904723142267\n",
      "Norm of gradient at iteration 2506: 0.8788805854000967\n",
      "Norm of gradient at iteration 2507: 0.8747898279801474\n",
      "Norm of gradient at iteration 2508: 0.870718111030993\n",
      "Norm of gradient at iteration 2509: 0.8666653459099914\n",
      "Norm of gradient at iteration 2510: 0.862631444415963\n",
      "Norm of gradient at iteration 2511: 0.8586163187881755\n",
      "Norm of gradient at iteration 2512: 0.8546198815549456\n",
      "Norm of gradient at iteration 2513: 0.8506420457991047\n",
      "Norm of gradient at iteration 2514: 0.846682724911706\n",
      "Norm of gradient at iteration 2515: 0.8427418327032724\n",
      "Norm of gradient at iteration 2516: 0.8388192834152371\n",
      "Norm of gradient at iteration 2517: 0.8349149916773966\n",
      "Norm of gradient at iteration 2518: 0.8310288724986585\n",
      "Norm of gradient at iteration 2519: 0.8271608412668141\n",
      "Norm of gradient at iteration 2520: 0.8233108138505348\n",
      "Norm of gradient at iteration 2521: 0.8194787064111961\n",
      "Norm of gradient at iteration 2522: 0.8156644355547725\n",
      "Norm of gradient at iteration 2523: 0.8118679182747489\n",
      "Norm of gradient at iteration 2524: 0.8080890718672257\n",
      "Norm of gradient at iteration 2525: 0.8043278141958474\n",
      "Norm of gradient at iteration 2526: 0.8005840632800812\n",
      "Norm of gradient at iteration 2527: 0.7968577376980261\n",
      "Norm of gradient at iteration 2528: 0.7931487563634194\n",
      "Norm of gradient at iteration 2529: 0.7894570384966721\n",
      "Norm of gradient at iteration 2530: 0.785782503750704\n",
      "Norm of gradient at iteration 2531: 0.7821250721480002\n",
      "Norm of gradient at iteration 2532: 0.7784846641253345\n",
      "Norm of gradient at iteration 2533: 0.7748612003928083\n",
      "Norm of gradient at iteration 2534: 0.7712546021087834\n",
      "Norm of gradient at iteration 2535: 0.7676647907615984\n",
      "Norm of gradient at iteration 2536: 0.7640916882536869\n",
      "Norm of gradient at iteration 2537: 0.760535216754734\n",
      "Norm of gradient at iteration 2538: 0.756995298891694\n",
      "Norm of gradient at iteration 2539: 0.75347185761453\n",
      "Norm of gradient at iteration 2540: 0.7499648162413463\n",
      "Norm of gradient at iteration 2541: 0.7464740983643248\n",
      "Norm of gradient at iteration 2542: 0.7429996281088764\n",
      "Norm of gradient at iteration 2543: 0.7395413297921335\n",
      "Norm of gradient at iteration 2544: 0.7360991281773458\n",
      "Norm of gradient at iteration 2545: 0.7326729482767269\n",
      "Norm of gradient at iteration 2546: 0.7292627155924168\n",
      "Norm of gradient at iteration 2547: 0.7258683558767662\n",
      "Norm of gradient at iteration 2548: 0.7224897952277144\n",
      "Norm of gradient at iteration 2549: 0.719126960122788\n",
      "Norm of gradient at iteration 2550: 0.7157797773404763\n",
      "Norm of gradient at iteration 2551: 0.7124481740774232\n",
      "Norm of gradient at iteration 2552: 0.7091320777791063\n",
      "Norm of gradient at iteration 2553: 0.7058314162868523\n",
      "Norm of gradient at iteration 2554: 0.7025461177219495\n",
      "Norm of gradient at iteration 2555: 0.6992761106433539\n",
      "Norm of gradient at iteration 2556: 0.6960213238290989\n",
      "Norm of gradient at iteration 2557: 0.692781686455754\n",
      "Norm of gradient at iteration 2558: 0.6895571279841415\n",
      "Norm of gradient at iteration 2559: 0.686347578279715\n",
      "Norm of gradient at iteration 2560: 0.6831529674244199\n",
      "Norm of gradient at iteration 2561: 0.6799732259061244\n",
      "Norm of gradient at iteration 2562: 0.676808284532101\n",
      "Norm of gradient at iteration 2563: 0.6736580744002645\n",
      "Norm of gradient at iteration 2564: 0.6705225269772073\n",
      "Norm of gradient at iteration 2565: 0.6674015739681598\n",
      "Norm of gradient at iteration 2566: 0.6642951474584117\n",
      "Norm of gradient at iteration 2567: 0.6612031798414832\n",
      "Norm of gradient at iteration 2568: 0.6581256038182164\n",
      "Norm of gradient at iteration 2569: 0.6550623523912701\n",
      "Norm of gradient at iteration 2570: 0.6520133589169411\n",
      "Norm of gradient at iteration 2571: 0.6489785569856643\n",
      "Norm of gradient at iteration 2572: 0.6459578805913158\n",
      "Norm of gradient at iteration 2573: 0.6429512639473917\n",
      "Norm of gradient at iteration 2574: 0.6399586416184877\n",
      "Norm of gradient at iteration 2575: 0.6369799485048979\n",
      "Norm of gradient at iteration 2576: 0.6340151197105504\n",
      "Norm of gradient at iteration 2577: 0.6310640907674138\n",
      "Norm of gradient at iteration 2578: 0.6281267974048355\n",
      "Norm of gradient at iteration 2579: 0.6252031756723633\n",
      "Norm of gradient at iteration 2580: 0.6222931619839005\n",
      "Norm of gradient at iteration 2581: 0.6193966929896951\n",
      "Norm of gradient at iteration 2582: 0.616513705638434\n",
      "Norm of gradient at iteration 2583: 0.6136441371424886\n",
      "Norm of gradient at iteration 2584: 0.6107879251116256\n",
      "Norm of gradient at iteration 2585: 0.6079450073270031\n",
      "Norm of gradient at iteration 2586: 0.6051153219266933\n",
      "Norm of gradient at iteration 2587: 0.6022988073398994\n",
      "Norm of gradient at iteration 2588: 0.599495402238686\n",
      "Norm of gradient at iteration 2589: 0.596705045584965\n",
      "Norm of gradient at iteration 2590: 0.593927676689827\n",
      "Norm of gradient at iteration 2591: 0.5911632351198444\n",
      "Norm of gradient at iteration 2592: 0.5884116606233848\n",
      "Norm of gradient at iteration 2593: 0.5856728933557462\n",
      "Norm of gradient at iteration 2594: 0.5829468737247627\n",
      "Norm of gradient at iteration 2595: 0.5802335423713022\n",
      "Norm of gradient at iteration 2596: 0.577532840235438\n",
      "Norm of gradient at iteration 2597: 0.5748447085263377\n",
      "Norm of gradient at iteration 2598: 0.5721690888079454\n",
      "Norm of gradient at iteration 2599: 0.5695059227412366\n",
      "Norm of gradient at iteration 2600: 0.5668551524047513\n",
      "Norm of gradient at iteration 2601: 0.5642167201041847\n",
      "Norm of gradient at iteration 2602: 0.5615905684220743\n",
      "Norm of gradient at iteration 2603: 0.5589766401733418\n",
      "Norm of gradient at iteration 2604: 0.5563748784829344\n",
      "Norm of gradient at iteration 2605: 0.5537852267277336\n",
      "Norm of gradient at iteration 2606: 0.55120762849989\n",
      "Norm of gradient at iteration 2607: 0.5486420277649046\n",
      "Norm of gradient at iteration 2608: 0.5460883685951385\n",
      "Norm of gradient at iteration 2609: 0.5435465954705622\n",
      "Norm of gradient at iteration 2610: 0.5410166530629618\n",
      "Norm of gradient at iteration 2611: 0.538498486261328\n",
      "Norm of gradient at iteration 2612: 0.5359920403458729\n",
      "Norm of gradient at iteration 2613: 0.5334972606740462\n",
      "Norm of gradient at iteration 2614: 0.531014092979237\n",
      "Norm of gradient at iteration 2615: 0.52854248319512\n",
      "Norm of gradient at iteration 2616: 0.5260823775516197\n",
      "Norm of gradient at iteration 2617: 0.523633722492\n",
      "Norm of gradient at iteration 2618: 0.5211964647067153\n",
      "Norm of gradient at iteration 2619: 0.5187705511796457\n",
      "Norm of gradient at iteration 2620: 0.5163559290837862\n",
      "Norm of gradient at iteration 2621: 0.5139525458517082\n",
      "Norm of gradient at iteration 2622: 0.5115603491923633\n",
      "Norm of gradient at iteration 2623: 0.5091792870564097\n",
      "Norm of gradient at iteration 2624: 0.5068093075694595\n",
      "Norm of gradient at iteration 2625: 0.5044503592002852\n",
      "Norm of gradient at iteration 2626: 0.5021023905750337\n",
      "Norm of gradient at iteration 2627: 0.49976535056128757\n",
      "Norm of gradient at iteration 2628: 0.4974391883271894\n",
      "Norm of gradient at iteration 2629: 0.49512385323549135\n",
      "Norm of gradient at iteration 2630: 0.492819294907902\n",
      "Norm of gradient at iteration 2631: 0.4905254631700854\n",
      "Norm of gradient at iteration 2632: 0.48824230807139524\n",
      "Norm of gradient at iteration 2633: 0.4859697799431428\n",
      "Norm of gradient at iteration 2634: 0.48370782932767326\n",
      "Norm of gradient at iteration 2635: 0.4814564069947633\n",
      "Norm of gradient at iteration 2636: 0.4792154639089086\n",
      "Norm of gradient at iteration 2637: 0.47698495128722745\n",
      "Norm of gradient at iteration 2638: 0.4747648206621379\n",
      "Norm of gradient at iteration 2639: 0.47255502360109863\n",
      "Norm of gradient at iteration 2640: 0.4703555120714424\n",
      "Norm of gradient at iteration 2641: 0.4681662382128644\n",
      "Norm of gradient at iteration 2642: 0.4659871543147197\n",
      "Norm of gradient at iteration 2643: 0.4638182130253696\n",
      "Norm of gradient at iteration 2644: 0.46165936706789495\n",
      "Norm of gradient at iteration 2645: 0.4595105694897652\n",
      "Norm of gradient at iteration 2646: 0.4573717734673319\n",
      "Norm of gradient at iteration 2647: 0.4552429325079557\n",
      "Norm of gradient at iteration 2648: 0.4531240003030106\n",
      "Norm of gradient at iteration 2649: 0.45101493064835446\n",
      "Norm of gradient at iteration 2650: 0.44891567769147694\n",
      "Norm of gradient at iteration 2651: 0.4468261957089614\n",
      "Norm of gradient at iteration 2652: 0.44474643926666974\n",
      "Norm of gradient at iteration 2653: 0.44267636303864094\n",
      "Norm of gradient at iteration 2654: 0.4406159220015758\n",
      "Norm of gradient at iteration 2655: 0.43856507132577405\n",
      "Norm of gradient at iteration 2656: 0.4365237663296957\n",
      "Norm of gradient at iteration 2657: 0.4344919626219025\n",
      "Norm of gradient at iteration 2658: 0.43246961594950656\n",
      "Norm of gradient at iteration 2659: 0.4304566823110161\n",
      "Norm of gradient at iteration 2660: 0.42845311789072665\n",
      "Norm of gradient at iteration 2661: 0.42645887906597124\n",
      "Norm of gradient at iteration 2662: 0.42447392246504656\n",
      "Norm of gradient at iteration 2663: 0.42249820484488976\n",
      "Norm of gradient at iteration 2664: 0.4205316832439887\n",
      "Norm of gradient at iteration 2665: 0.418574314820102\n",
      "Norm of gradient at iteration 2666: 0.4166260569938344\n",
      "Norm of gradient at iteration 2667: 0.4146868673275991\n",
      "Norm of gradient at iteration 2668: 0.4127567036415916\n",
      "Norm of gradient at iteration 2669: 0.4108355239433571\n",
      "Norm of gradient at iteration 2670: 0.40892328639568404\n",
      "Norm of gradient at iteration 2671: 0.4070199493483983\n",
      "Norm of gradient at iteration 2672: 0.4051254713828496\n",
      "Norm of gradient at iteration 2673: 0.4032398113142776\n",
      "Norm of gradient at iteration 2674: 0.4013629280272233\n",
      "Norm of gradient at iteration 2675: 0.39949478076756234\n",
      "Norm of gradient at iteration 2676: 0.3976353287833832\n",
      "Norm of gradient at iteration 2677: 0.39578453165509514\n",
      "Norm of gradient at iteration 2678: 0.39394234904985403\n",
      "Norm of gradient at iteration 2679: 0.39210874091870435\n",
      "Norm of gradient at iteration 2680: 0.39028366734812836\n",
      "Norm of gradient at iteration 2681: 0.38846708857067935\n",
      "Norm of gradient at iteration 2682: 0.3866589650662762\n",
      "Norm of gradient at iteration 2683: 0.3848592575236755\n",
      "Norm of gradient at iteration 2684: 0.3830679267242153\n",
      "Norm of gradient at iteration 2685: 0.3812849336966804\n",
      "Norm of gradient at iteration 2686: 0.37951023959557867\n",
      "Norm of gradient at iteration 2687: 0.3777438058558677\n",
      "Norm of gradient at iteration 2688: 0.3759855939635586\n",
      "Norm of gradient at iteration 2689: 0.37423556571371924\n",
      "Norm of gradient at iteration 2690: 0.3724936829896657\n",
      "Norm of gradient at iteration 2691: 0.37075990785066176\n",
      "Norm of gradient at iteration 2692: 0.3690342025697598\n",
      "Norm of gradient at iteration 2693: 0.36731652965368655\n",
      "Norm of gradient at iteration 2694: 0.36560685161367745\n",
      "Norm of gradient at iteration 2695: 0.3639051313092905\n",
      "Norm of gradient at iteration 2696: 0.3622113316752701\n",
      "Norm of gradient at iteration 2697: 0.3605254158391829\n",
      "Norm of gradient at iteration 2698: 0.35884734711262534\n",
      "Norm of gradient at iteration 2699: 0.35717708897889067\n",
      "Norm of gradient at iteration 2700: 0.35551460505988924\n",
      "Norm of gradient at iteration 2701: 0.35385985922069596\n",
      "Norm of gradient at iteration 2702: 0.3522128153897588\n",
      "Norm of gradient at iteration 2703: 0.3505734377518462\n",
      "Norm of gradient at iteration 2704: 0.3489416905742566\n",
      "Norm of gradient at iteration 2705: 0.34731753840013735\n",
      "Norm of gradient at iteration 2706: 0.34570094584411604\n",
      "Norm of gradient at iteration 2707: 0.34409187774844346\n",
      "Norm of gradient at iteration 2708: 0.34249029907899126\n",
      "Norm of gradient at iteration 2709: 0.34089617496928276\n",
      "Norm of gradient at iteration 2710: 0.3393094707330579\n",
      "Norm of gradient at iteration 2711: 0.33773015180560906\n",
      "Norm of gradient at iteration 2712: 0.33615818383696944\n",
      "Norm of gradient at iteration 2713: 0.3345935325819204\n",
      "Norm of gradient at iteration 2714: 0.33303616406147973\n",
      "Norm of gradient at iteration 2715: 0.33148604428456585\n",
      "Norm of gradient at iteration 2716: 0.32994313956272825\n",
      "Norm of gradient at iteration 2717: 0.3284074163284814\n",
      "Norm of gradient at iteration 2718: 0.32687884112659443\n",
      "Norm of gradient at iteration 2719: 0.3253573806535933\n",
      "Norm of gradient at iteration 2720: 0.32384300186762577\n",
      "Norm of gradient at iteration 2721: 0.32233567178627764\n",
      "Norm of gradient at iteration 2722: 0.3208353575309056\n",
      "Norm of gradient at iteration 2723: 0.3193420265800211\n",
      "Norm of gradient at iteration 2724: 0.3178556462841747\n",
      "Norm of gradient at iteration 2725: 0.316376184390335\n",
      "Norm of gradient at iteration 2726: 0.3149036086394921\n",
      "Norm of gradient at iteration 2727: 0.31343788703059833\n",
      "Norm of gradient at iteration 2728: 0.3119789876152698\n",
      "Norm of gradient at iteration 2729: 0.3105268786647472\n",
      "Norm of gradient at iteration 2730: 0.3090815285761184\n",
      "Norm of gradient at iteration 2731: 0.3076429058650007\n",
      "Norm of gradient at iteration 2732: 0.3062109792647859\n",
      "Norm of gradient at iteration 2733: 0.3047857175530531\n",
      "Norm of gradient at iteration 2734: 0.303367089735272\n",
      "Norm of gradient at iteration 2735: 0.3019550649486147\n",
      "Norm of gradient at iteration 2736: 0.3005496124401716\n",
      "Norm of gradient at iteration 2737: 0.29915070161922097\n",
      "Norm of gradient at iteration 2738: 0.2977583020557066\n",
      "Norm of gradient at iteration 2739: 0.2963723833999838\n",
      "Norm of gradient at iteration 2740: 0.2949929155222257\n",
      "Norm of gradient at iteration 2741: 0.2936198683836838\n",
      "Norm of gradient at iteration 2742: 0.2922532121254712\n",
      "Norm of gradient at iteration 2743: 0.29089291696551295\n",
      "Norm of gradient at iteration 2744: 0.28953895333596785\n",
      "Norm of gradient at iteration 2745: 0.28819129172234187\n",
      "Norm of gradient at iteration 2746: 0.28684990281199796\n",
      "Norm of gradient at iteration 2747: 0.28551475740579113\n",
      "Norm of gradient at iteration 2748: 0.2841858264661949\n",
      "Norm of gradient at iteration 2749: 0.28286308103393015\n",
      "Norm of gradient at iteration 2750: 0.28154649231752826\n",
      "Norm of gradient at iteration 2751: 0.2802360316807742\n",
      "Norm of gradient at iteration 2752: 0.27893167063506863\n",
      "Norm of gradient at iteration 2753: 0.27763338069552573\n",
      "Norm of gradient at iteration 2754: 0.2763411336681756\n",
      "Norm of gradient at iteration 2755: 0.2750549014391053\n",
      "Norm of gradient at iteration 2756: 0.2737746559706691\n",
      "Norm of gradient at iteration 2757: 0.27250036942473127\n",
      "Norm of gradient at iteration 2758: 0.27123201406169917\n",
      "Norm of gradient at iteration 2759: 0.2699695622492004\n",
      "Norm of gradient at iteration 2760: 0.268712986543653\n",
      "Norm of gradient at iteration 2761: 0.2674622595793858\n",
      "Norm of gradient at iteration 2762: 0.26621735413922065\n",
      "Norm of gradient at iteration 2763: 0.26497824311300594\n",
      "Norm of gradient at iteration 2764: 0.26374489956087044\n",
      "Norm of gradient at iteration 2765: 0.26251729658119244\n",
      "Norm of gradient at iteration 2766: 0.26129540751441394\n",
      "Norm of gradient at iteration 2767: 0.260079205764997\n",
      "Norm of gradient at iteration 2768: 0.25886866480896326\n",
      "Norm of gradient at iteration 2769: 0.25766375831541966\n",
      "Norm of gradient at iteration 2770: 0.2564644600972454\n",
      "Norm of gradient at iteration 2771: 0.25527074403296995\n",
      "Norm of gradient at iteration 2772: 0.254082584087471\n",
      "Norm of gradient at iteration 2773: 0.2528999544725607\n",
      "Norm of gradient at iteration 2774: 0.2517228294149588\n",
      "Norm of gradient at iteration 2775: 0.2505511832822646\n",
      "Norm of gradient at iteration 2776: 0.2493849905629238\n",
      "Norm of gradient at iteration 2777: 0.2482242259565176\n",
      "Norm of gradient at iteration 2778: 0.24706886409760542\n",
      "Norm of gradient at iteration 2779: 0.24591887989555974\n",
      "Norm of gradient at iteration 2780: 0.24477424827607\n",
      "Norm of gradient at iteration 2781: 0.24363494438493644\n",
      "Norm of gradient at iteration 2782: 0.2425009433980821\n",
      "Norm of gradient at iteration 2783: 0.24137222063801655\n",
      "Norm of gradient at iteration 2784: 0.24024875149412805\n",
      "Norm of gradient at iteration 2785: 0.23913051156302104\n",
      "Norm of gradient at iteration 2786: 0.23801747649104804\n",
      "Norm of gradient at iteration 2787: 0.23690962205698357\n",
      "Norm of gradient at iteration 2788: 0.23580692414052207\n",
      "Norm of gradient at iteration 2789: 0.23470935868957776\n",
      "Norm of gradient at iteration 2790: 0.23361690192921378\n",
      "Norm of gradient at iteration 2791: 0.2325295299815846\n",
      "Norm of gradient at iteration 2792: 0.23144721925110648\n",
      "Norm of gradient at iteration 2793: 0.23036994611520806\n",
      "Norm of gradient at iteration 2794: 0.22929768718942437\n",
      "Norm of gradient at iteration 2795: 0.2282304190696587\n",
      "Norm of gradient at iteration 2796: 0.22716811857969077\n",
      "Norm of gradient at iteration 2797: 0.22611076259007415\n",
      "Norm of gradient at iteration 2798: 0.22505832805901949\n",
      "Norm of gradient at iteration 2799: 0.22401079206913554\n",
      "Norm of gradient at iteration 2800: 0.22296813188393308\n",
      "Norm of gradient at iteration 2801: 0.22193032475182656\n",
      "Norm of gradient at iteration 2802: 0.22089734809334904\n",
      "Norm of gradient at iteration 2803: 0.21986917944622783\n",
      "Norm of gradient at iteration 2804: 0.21884579639436455\n",
      "Norm of gradient at iteration 2805: 0.2178271767192542\n",
      "Norm of gradient at iteration 2806: 0.216813298205953\n",
      "Norm of gradient at iteration 2807: 0.2158041387976437\n",
      "Norm of gradient at iteration 2808: 0.2147996765288714\n",
      "Norm of gradient at iteration 2809: 0.21379988955660473\n",
      "Norm of gradient at iteration 2810: 0.21280475607800106\n",
      "Norm of gradient at iteration 2811: 0.21181425447619537\n",
      "Norm of gradient at iteration 2812: 0.2108283631590237\n",
      "Norm of gradient at iteration 2813: 0.20984706068993672\n",
      "Norm of gradient at iteration 2814: 0.20887032568805547\n",
      "Norm of gradient at iteration 2815: 0.20789813691145265\n",
      "Norm of gradient at iteration 2816: 0.20693047319677055\n",
      "Norm of gradient at iteration 2817: 0.2059673135000157\n",
      "Norm of gradient at iteration 2818: 0.20500863680731946\n",
      "Norm of gradient at iteration 2819: 0.20405442229874388\n",
      "Norm of gradient at iteration 2820: 0.2031046491861236\n",
      "Norm of gradient at iteration 2821: 0.2021592967912846\n",
      "Norm of gradient at iteration 2822: 0.20121834457864293\n",
      "Norm of gradient at iteration 2823: 0.20028177203652966\n",
      "Norm of gradient at iteration 2824: 0.19934955877287916\n",
      "Norm of gradient at iteration 2825: 0.1984216844729888\n",
      "Norm of gradient at iteration 2826: 0.19749812899716507\n",
      "Norm of gradient at iteration 2827: 0.19657887221726267\n",
      "Norm of gradient at iteration 2828: 0.19566389412017102\n",
      "Norm of gradient at iteration 2829: 0.19475317481455065\n",
      "Norm of gradient at iteration 2830: 0.19384669443027042\n",
      "Norm of gradient at iteration 2831: 0.19294443329906028\n",
      "Norm of gradient at iteration 2832: 0.19204637173247632\n",
      "Norm of gradient at iteration 2833: 0.19115249019558803\n",
      "Norm of gradient at iteration 2834: 0.19026276922921168\n",
      "Norm of gradient at iteration 2835: 0.18937718949254126\n",
      "Norm of gradient at iteration 2836: 0.18849573170266704\n",
      "Norm of gradient at iteration 2837: 0.18761837664779155\n",
      "Norm of gradient at iteration 2838: 0.18674510525835186\n",
      "Norm of gradient at iteration 2839: 0.1858758985152749\n",
      "Norm of gradient at iteration 2840: 0.18501073749327077\n",
      "Norm of gradient at iteration 2841: 0.18414960340539568\n",
      "Norm of gradient at iteration 2842: 0.18329247743758056\n",
      "Norm of gradient at iteration 2843: 0.18243934099884354\n",
      "Norm of gradient at iteration 2844: 0.1815901754714701\n",
      "Norm of gradient at iteration 2845: 0.18074496240759533\n",
      "Norm of gradient at iteration 2846: 0.17990368335167695\n",
      "Norm of gradient at iteration 2847: 0.1790663200933622\n",
      "Norm of gradient at iteration 2848: 0.1782328543350332\n",
      "Norm of gradient at iteration 2849: 0.17740326793306724\n",
      "Norm of gradient at iteration 2850: 0.1765775428677265\n",
      "Norm of gradient at iteration 2851: 0.17575566114137203\n",
      "Norm of gradient at iteration 2852: 0.17493760487285903\n",
      "Norm of gradient at iteration 2853: 0.1741233562480472\n",
      "Norm of gradient at iteration 2854: 0.17331289756833418\n",
      "Norm of gradient at iteration 2855: 0.17250621114287354\n",
      "Norm of gradient at iteration 2856: 0.17170327946545738\n",
      "Norm of gradient at iteration 2857: 0.1709040850538073\n",
      "Norm of gradient at iteration 2858: 0.170108610478784\n",
      "Norm of gradient at iteration 2859: 0.16931683845927195\n",
      "Norm of gradient at iteration 2860: 0.16852875173204662\n",
      "Norm of gradient at iteration 2861: 0.1677443331697278\n",
      "Norm of gradient at iteration 2862: 0.16696356572135354\n",
      "Norm of gradient at iteration 2863: 0.1661864323247475\n",
      "Norm of gradient at iteration 2864: 0.1654129161040381\n",
      "Norm of gradient at iteration 2865: 0.16464300022822836\n",
      "Norm of gradient at iteration 2866: 0.16387666794831326\n",
      "Norm of gradient at iteration 2867: 0.16311390254699085\n",
      "Norm of gradient at iteration 2868: 0.16235468744401904\n",
      "Norm of gradient at iteration 2869: 0.16159900613765169\n",
      "Norm of gradient at iteration 2870: 0.16084684215930475\n",
      "Norm of gradient at iteration 2871: 0.1600981790918345\n",
      "Norm of gradient at iteration 2872: 0.15935300073510336\n",
      "Norm of gradient at iteration 2873: 0.1586112907621068\n",
      "Norm of gradient at iteration 2874: 0.15787303312024653\n",
      "Norm of gradient at iteration 2875: 0.15713821168269695\n",
      "Norm of gradient at iteration 2876: 0.1564068105085175\n",
      "Norm of gradient at iteration 2877: 0.15567881360184663\n",
      "Norm of gradient at iteration 2878: 0.15495420520876754\n",
      "Norm of gradient at iteration 2879: 0.15423296948446377\n",
      "Norm of gradient at iteration 2880: 0.15351509078658865\n",
      "Norm of gradient at iteration 2881: 0.15280055342281904\n",
      "Norm of gradient at iteration 2882: 0.15208934191841356\n",
      "Norm of gradient at iteration 2883: 0.15138144073042467\n",
      "Norm of gradient at iteration 2884: 0.15067683448629116\n",
      "Norm of gradient at iteration 2885: 0.1499755078460074\n",
      "Norm of gradient at iteration 2886: 0.14927744549798821\n",
      "Norm of gradient at iteration 2887: 0.14858263231599642\n",
      "Norm of gradient at iteration 2888: 0.14789105313703846\n",
      "Norm of gradient at iteration 2889: 0.1472026929421673\n",
      "Norm of gradient at iteration 2890: 0.1465175367173986\n",
      "Norm of gradient at iteration 2891: 0.14583556954138427\n",
      "Norm of gradient at iteration 2892: 0.14515677661920753\n",
      "Norm of gradient at iteration 2893: 0.14448114309436455\n",
      "Norm of gradient at iteration 2894: 0.1438086543628434\n",
      "Norm of gradient at iteration 2895: 0.14313929572899595\n",
      "Norm of gradient at iteration 2896: 0.1424730526124802\n",
      "Norm of gradient at iteration 2897: 0.1418099105288008\n",
      "Norm of gradient at iteration 2898: 0.14114985505322714\n",
      "Norm of gradient at iteration 2899: 0.14049287181382367\n",
      "Norm of gradient at iteration 2900: 0.13983894650700499\n",
      "Norm of gradient at iteration 2901: 0.13918806491465535\n",
      "Norm of gradient at iteration 2902: 0.13854021285379947\n",
      "Norm of gradient at iteration 2903: 0.1378953761713663\n",
      "Norm of gradient at iteration 2904: 0.13725354095900125\n",
      "Norm of gradient at iteration 2905: 0.13661469313389152\n",
      "Norm of gradient at iteration 2906: 0.13597881886185154\n",
      "Norm of gradient at iteration 2907: 0.13534590425417192\n",
      "Norm of gradient at iteration 2908: 0.1347159355340819\n",
      "Norm of gradient at iteration 2909: 0.13408889903610927\n",
      "Norm of gradient at iteration 2910: 0.1334647810903884\n",
      "Norm of gradient at iteration 2911: 0.13284356806200637\n",
      "Norm of gradient at iteration 2912: 0.13222524650340714\n",
      "Norm of gradient at iteration 2913: 0.13160980291074345\n",
      "Norm of gradient at iteration 2914: 0.13099722394504376\n",
      "Norm of gradient at iteration 2915: 0.13038749621332588\n",
      "Norm of gradient at iteration 2916: 0.1297806064450473\n",
      "Norm of gradient at iteration 2917: 0.12917654147497717\n",
      "Norm of gradient at iteration 2918: 0.1285752881209529\n",
      "Norm of gradient at iteration 2919: 0.12797683331555354\n",
      "Norm of gradient at iteration 2920: 0.12738116401937796\n",
      "Norm of gradient at iteration 2921: 0.12678826727937087\n",
      "Norm of gradient at iteration 2922: 0.12619813018066167\n",
      "Norm of gradient at iteration 2923: 0.12561073986524418\n",
      "Norm of gradient at iteration 2924: 0.12502608355608524\n",
      "Norm of gradient at iteration 2925: 0.1244441485630118\n",
      "Norm of gradient at iteration 2926: 0.1238649221665729\n",
      "Norm of gradient at iteration 2927: 0.12328839180247779\n",
      "Norm of gradient at iteration 2928: 0.12271454489833883\n",
      "Norm of gradient at iteration 2929: 0.12214336895799172\n",
      "Norm of gradient at iteration 2930: 0.12157485157274507\n",
      "Norm of gradient at iteration 2931: 0.12100898034996532\n",
      "Norm of gradient at iteration 2932: 0.12044574301095315\n",
      "Norm of gradient at iteration 2933: 0.11988512721748393\n",
      "Norm of gradient at iteration 2934: 0.11932712085152092\n",
      "Norm of gradient at iteration 2935: 0.1187717117076008\n",
      "Norm of gradient at iteration 2936: 0.11821888774305354\n",
      "Norm of gradient at iteration 2937: 0.11766863690052279\n",
      "Norm of gradient at iteration 2938: 0.11712094717177936\n",
      "Norm of gradient at iteration 2939: 0.1165758066914358\n",
      "Norm of gradient at iteration 2940: 0.11603320358045457\n",
      "Norm of gradient at iteration 2941: 0.11549312600012948\n",
      "Norm of gradient at iteration 2942: 0.11495556223747844\n",
      "Norm of gradient at iteration 2943: 0.1144205005666508\n",
      "Norm of gradient at iteration 2944: 0.11388792931801578\n",
      "Norm of gradient at iteration 2945: 0.11335783694988094\n",
      "Norm of gradient at iteration 2946: 0.11283021190357512\n",
      "Norm of gradient at iteration 2947: 0.11230504266652887\n",
      "Norm of gradient at iteration 2948: 0.11178231786808097\n",
      "Norm of gradient at iteration 2949: 0.1112620260838379\n",
      "Norm of gradient at iteration 2950: 0.11074415600777855\n",
      "Norm of gradient at iteration 2951: 0.11022869633259455\n",
      "Norm of gradient at iteration 2952: 0.10971563591512927\n",
      "Norm of gradient at iteration 2953: 0.10920496351354203\n",
      "Norm of gradient at iteration 2954: 0.10869666805083947\n",
      "Norm of gradient at iteration 2955: 0.10819073845552875\n",
      "Norm of gradient at iteration 2956: 0.10768716370561994\n",
      "Norm of gradient at iteration 2957: 0.10718593284992221\n",
      "Norm of gradient at iteration 2958: 0.10668703496009628\n",
      "Norm of gradient at iteration 2959: 0.1061904592135627\n",
      "Norm of gradient at iteration 2960: 0.10569619478669345\n",
      "Norm of gradient at iteration 2961: 0.1052042309113727\n",
      "Norm of gradient at iteration 2962: 0.10471455690087117\n",
      "Norm of gradient at iteration 2963: 0.10422716207609295\n",
      "Norm of gradient at iteration 2964: 0.10374203580324054\n",
      "Norm of gradient at iteration 2965: 0.10325916757368211\n",
      "Norm of gradient at iteration 2966: 0.10277854688964429\n",
      "Norm of gradient at iteration 2967: 0.10230016324128445\n",
      "Norm of gradient at iteration 2968: 0.10182400620975372\n",
      "Norm of gradient at iteration 2969: 0.10135006547893001\n",
      "Norm of gradient at iteration 2970: 0.10087833069899325\n",
      "Norm of gradient at iteration 2971: 0.10040879161939795\n",
      "Norm of gradient at iteration 2972: 0.09994143803487222\n",
      "Norm of gradient at iteration 2973: 0.09947625972888759\n",
      "Norm of gradient at iteration 2974: 0.09901324658779223\n",
      "Norm of gradient at iteration 2975: 0.09855238856074774\n",
      "Norm of gradient at iteration 2976: 0.09809367560949138\n",
      "Norm of gradient at iteration 2977: 0.09763709770858044\n",
      "Norm of gradient at iteration 2978: 0.09718264496739712\n",
      "Norm of gradient at iteration 2979: 0.09673030751027022\n",
      "Norm of gradient at iteration 2980: 0.0962800754383379\n",
      "Norm of gradient at iteration 2981: 0.09583193897301494\n",
      "Norm of gradient at iteration 2982: 0.09538588838837724\n",
      "Norm of gradient at iteration 2983: 0.09494191393194323\n",
      "Norm of gradient at iteration 2984: 0.09450000593133512\n",
      "Norm of gradient at iteration 2985: 0.09406015480145391\n",
      "Norm of gradient at iteration 2986: 0.0936223510243808\n",
      "Norm of gradient at iteration 2987: 0.09318658496584706\n",
      "Norm of gradient at iteration 2988: 0.09275284720096182\n",
      "Norm of gradient at iteration 2989: 0.09232112823643311\n",
      "Norm of gradient at iteration 2990: 0.09189141872311299\n",
      "Norm of gradient at iteration 2991: 0.09146370931205536\n",
      "Norm of gradient at iteration 2992: 0.09103799065304696\n",
      "Norm of gradient at iteration 2993: 0.0906142535224895\n",
      "Norm of gradient at iteration 2994: 0.09019248867958606\n",
      "Norm of gradient at iteration 2995: 0.08977268693105016\n",
      "Norm of gradient at iteration 2996: 0.08935483920466628\n",
      "Norm of gradient at iteration 2997: 0.08893893629508597\n",
      "Norm of gradient at iteration 2998: 0.08852496919814673\n",
      "Norm of gradient at iteration 2999: 0.0881129289791044\n",
      "Norm of gradient at iteration 3000: 0.08770280656946111\n",
      "Norm of gradient at iteration 3001: 0.08729459309802333\n",
      "Norm of gradient at iteration 3002: 0.08688827964960351\n",
      "Norm of gradient at iteration 3003: 0.08648385737153721\n",
      "Norm of gradient at iteration 3004: 0.08608131750149865\n",
      "Norm of gradient at iteration 3005: 0.0856806512502786\n",
      "Norm of gradient at iteration 3006: 0.08528184990397474\n",
      "Norm of gradient at iteration 3007: 0.08488490477956522\n",
      "Norm of gradient at iteration 3008: 0.08448980724172084\n",
      "Norm of gradient at iteration 3009: 0.08409654868297475\n",
      "Norm of gradient at iteration 3010: 0.08370512055844143\n",
      "Norm of gradient at iteration 3011: 0.08331551435046829\n",
      "Norm of gradient at iteration 3012: 0.08292772154721856\n",
      "Norm of gradient at iteration 3013: 0.08254173372963186\n",
      "Norm of gradient at iteration 3014: 0.08215754248549777\n",
      "Norm of gradient at iteration 3015: 0.08177513950522143\n",
      "Norm of gradient at iteration 3016: 0.08139451639182045\n",
      "Norm of gradient at iteration 3017: 0.08101566488936915\n",
      "Norm of gradient at iteration 3018: 0.08063857676647122\n",
      "Norm of gradient at iteration 3019: 0.08026324382273126\n",
      "Norm of gradient at iteration 3020: 0.07988965782579402\n",
      "Norm of gradient at iteration 3021: 0.07951781072552377\n",
      "Norm of gradient at iteration 3022: 0.07914769438645981\n",
      "Norm of gradient at iteration 3023: 0.07877930075548766\n",
      "Norm of gradient at iteration 3024: 0.07841262180490431\n",
      "Norm of gradient at iteration 3025: 0.07804764956377681\n",
      "Norm of gradient at iteration 3026: 0.07768437607657001\n",
      "Norm of gradient at iteration 3027: 0.07732279346585216\n",
      "Norm of gradient at iteration 3028: 0.07696289384308495\n",
      "Norm of gradient at iteration 3029: 0.07660466935489499\n",
      "Norm of gradient at iteration 3030: 0.07624811223105181\n",
      "Norm of gradient at iteration 3031: 0.07589321473557796\n",
      "Norm of gradient at iteration 3032: 0.07553996912765264\n",
      "Norm of gradient at iteration 3033: 0.07518836765882103\n",
      "Norm of gradient at iteration 3034: 0.07483840273074205\n",
      "Norm of gradient at iteration 3035: 0.07449006670610005\n",
      "Norm of gradient at iteration 3036: 0.07414335204748101\n",
      "Norm of gradient at iteration 3037: 0.07379825118791694\n",
      "Norm of gradient at iteration 3038: 0.07345475656235487\n",
      "Norm of gradient at iteration 3039: 0.07311286074820907\n",
      "Norm of gradient at iteration 3040: 0.07277255629712533\n",
      "Norm of gradient at iteration 3041: 0.07243383576426672\n",
      "Norm of gradient at iteration 3042: 0.0720966918363892\n",
      "Norm of gradient at iteration 3043: 0.07176111715428564\n",
      "Norm of gradient at iteration 3044: 0.07142710441647945\n",
      "Norm of gradient at iteration 3045: 0.0710946463209596\n",
      "Norm of gradient at iteration 3046: 0.07076373564846015\n",
      "Norm of gradient at iteration 3047: 0.07043436523077776\n",
      "Norm of gradient at iteration 3048: 0.07010652785189855\n",
      "Norm of gradient at iteration 3049: 0.06978021640962079\n",
      "Norm of gradient at iteration 3050: 0.06945542378310555\n",
      "Norm of gradient at iteration 3051: 0.06913214288480306\n",
      "Norm of gradient at iteration 3052: 0.06881036674452937\n",
      "Norm of gradient at iteration 3053: 0.06849008826286615\n",
      "Norm of gradient at iteration 3054: 0.06817130056308263\n",
      "Norm of gradient at iteration 3055: 0.06785399665031404\n",
      "Norm of gradient at iteration 3056: 0.06753816960645927\n",
      "Norm of gradient at iteration 3057: 0.06722381261441748\n",
      "Norm of gradient at iteration 3058: 0.06691091878434788\n",
      "Norm of gradient at iteration 3059: 0.06659948130438602\n",
      "Norm of gradient at iteration 3060: 0.06628949345228943\n",
      "Norm of gradient at iteration 3061: 0.06598094843223491\n",
      "Norm of gradient at iteration 3062: 0.06567383952659686\n",
      "Norm of gradient at iteration 3063: 0.06536816005330813\n",
      "Norm of gradient at iteration 3064: 0.06506390336786777\n",
      "Norm of gradient at iteration 3065: 0.06476106287697965\n",
      "Norm of gradient at iteration 3066: 0.06445963192955498\n",
      "Norm of gradient at iteration 3067: 0.06415960399216483\n",
      "Norm of gradient at iteration 3068: 0.06386097254759109\n",
      "Norm of gradient at iteration 3069: 0.06356373109253405\n",
      "Norm of gradient at iteration 3070: 0.06326787313896944\n",
      "Norm of gradient at iteration 3071: 0.0629733922602703\n",
      "Norm of gradient at iteration 3072: 0.06268028205422066\n",
      "Norm of gradient at iteration 3073: 0.06238853611171603\n",
      "Norm of gradient at iteration 3074: 0.06209814812984197\n",
      "Norm of gradient at iteration 3075: 0.061809111759889186\n",
      "Norm of gradient at iteration 3076: 0.06152142071456142\n",
      "Norm of gradient at iteration 3077: 0.06123506869891217\n",
      "Norm of gradient at iteration 3078: 0.0609500495292661\n",
      "Norm of gradient at iteration 3079: 0.06066635698118561\n",
      "Norm of gradient at iteration 3080: 0.06038398487634432\n",
      "Norm of gradient at iteration 3081: 0.06010292710089189\n",
      "Norm of gradient at iteration 3082: 0.059823177493453165\n",
      "Norm of gradient at iteration 3083: 0.05954472997270116\n",
      "Norm of gradient at iteration 3084: 0.05926757850803595\n",
      "Norm of gradient at iteration 3085: 0.05899171704145366\n",
      "Norm of gradient at iteration 3086: 0.05871713956307457\n",
      "Norm of gradient at iteration 3087: 0.05844384012390364\n",
      "Norm of gradient at iteration 3088: 0.05817181276074464\n",
      "Norm of gradient at iteration 3089: 0.05790105153504638\n",
      "Norm of gradient at iteration 3090: 0.05763155061407404\n",
      "Norm of gradient at iteration 3091: 0.057363304027624566\n",
      "Norm of gradient at iteration 3092: 0.05709630602492996\n",
      "Norm of gradient at iteration 3093: 0.056830550774245814\n",
      "Norm of gradient at iteration 3094: 0.056566032463489034\n",
      "Norm of gradient at iteration 3095: 0.056302745382239686\n",
      "Norm of gradient at iteration 3096: 0.056040683754570664\n",
      "Norm of gradient at iteration 3097: 0.05577984190523593\n",
      "Norm of gradient at iteration 3098: 0.05552021413278275\n",
      "Norm of gradient at iteration 3099: 0.055261794818416164\n",
      "Norm of gradient at iteration 3100: 0.055004578299785736\n",
      "Norm of gradient at iteration 3101: 0.054748559019863356\n",
      "Norm of gradient at iteration 3102: 0.05449373135917158\n",
      "Norm of gradient at iteration 3103: 0.05424008980887508\n",
      "Norm of gradient at iteration 3104: 0.05398762884573524\n",
      "Norm of gradient at iteration 3105: 0.05373634296286434\n",
      "Norm of gradient at iteration 3106: 0.05348622665702633\n",
      "Norm of gradient at iteration 3107: 0.053237274530074166\n",
      "Norm of gradient at iteration 3108: 0.052989481155563865\n",
      "Norm of gradient at iteration 3109: 0.05274284117206256\n",
      "Norm of gradient at iteration 3110: 0.0524973491309126\n",
      "Norm of gradient at iteration 3111: 0.05225299977199697\n",
      "Norm of gradient at iteration 3112: 0.05200978774179535\n",
      "Norm of gradient at iteration 3113: 0.051767707717034005\n",
      "Norm of gradient at iteration 3114: 0.05152675448559267\n",
      "Norm of gradient at iteration 3115: 0.051286922738111584\n",
      "Norm of gradient at iteration 3116: 0.051048207275242945\n",
      "Norm of gradient at iteration 3117: 0.05081060295940052\n",
      "Norm of gradient at iteration 3118: 0.050574104573907416\n",
      "Norm of gradient at iteration 3119: 0.05033870692733381\n",
      "Norm of gradient at iteration 3120: 0.05010440498243299\n",
      "Norm of gradient at iteration 3121: 0.049871193587651484\n",
      "Norm of gradient at iteration 3122: 0.04963906767235569\n",
      "Norm of gradient at iteration 3123: 0.049408022198760684\n",
      "Norm of gradient at iteration 3124: 0.04917805211136178\n",
      "Norm of gradient at iteration 3125: 0.04894915245130708\n",
      "Norm of gradient at iteration 3126: 0.04872131818212023\n",
      "Norm of gradient at iteration 3127: 0.048494544398764376\n",
      "Norm of gradient at iteration 3128: 0.0482688261134794\n",
      "Norm of gradient at iteration 3129: 0.04804415844560366\n",
      "Norm of gradient at iteration 3130: 0.047820536459878125\n",
      "Norm of gradient at iteration 3131: 0.04759795533841662\n",
      "Norm of gradient at iteration 3132: 0.047376410237369444\n",
      "Norm of gradient at iteration 3133: 0.047155896304045535\n",
      "Norm of gradient at iteration 3134: 0.046936408790794436\n",
      "Norm of gradient at iteration 3135: 0.046717942837235564\n",
      "Norm of gradient at iteration 3136: 0.04650049376136801\n",
      "Norm of gradient at iteration 3137: 0.04628405681187235\n",
      "Norm of gradient at iteration 3138: 0.0460686272720494\n",
      "Norm of gradient at iteration 3139: 0.045854200458099556\n",
      "Norm of gradient at iteration 3140: 0.04564077167290692\n",
      "Norm of gradient at iteration 3141: 0.04542833629781364\n",
      "Norm of gradient at iteration 3142: 0.045216889706201906\n",
      "Norm of gradient at iteration 3143: 0.04500642730523967\n",
      "Norm of gradient at iteration 3144: 0.04479694449589101\n",
      "Norm of gradient at iteration 3145: 0.044588436731900646\n",
      "Norm of gradient at iteration 3146: 0.044380899475526106\n",
      "Norm of gradient at iteration 3147: 0.044174328159168545\n",
      "Norm of gradient at iteration 3148: 0.043968718362088\n",
      "Norm of gradient at iteration 3149: 0.043764065566165855\n",
      "Norm of gradient at iteration 3150: 0.04356036536903648\n",
      "Norm of gradient at iteration 3151: 0.04335761324699715\n",
      "Norm of gradient at iteration 3152: 0.04315580486127777\n",
      "Norm of gradient at iteration 3153: 0.04295493577356252\n",
      "Norm of gradient at iteration 3154: 0.042755001629023744\n",
      "Norm of gradient at iteration 3155: 0.042555998129884386\n",
      "Norm of gradient at iteration 3156: 0.0423579208509121\n",
      "Norm of gradient at iteration 3157: 0.04216076553741541\n",
      "Norm of gradient at iteration 3158: 0.04196452790064455\n",
      "Norm of gradient at iteration 3159: 0.041769203638072336\n",
      "Norm of gradient at iteration 3160: 0.041574788512986016\n",
      "Norm of gradient at iteration 3161: 0.041381278298353766\n",
      "Norm of gradient at iteration 3162: 0.04118866877041587\n",
      "Norm of gradient at iteration 3163: 0.04099695574790718\n",
      "Norm of gradient at iteration 3164: 0.04080613505429248\n",
      "Norm of gradient at iteration 3165: 0.04061620254617284\n",
      "Norm of gradient at iteration 3166: 0.040427154061142355\n",
      "Norm of gradient at iteration 3167: 0.04023898552476044\n",
      "Norm of gradient at iteration 3168: 0.04005169282171703\n",
      "Norm of gradient at iteration 3169: 0.03986527187803504\n",
      "Norm of gradient at iteration 3170: 0.03967971859493253\n",
      "Norm of gradient at iteration 3171: 0.03949502899658801\n",
      "Norm of gradient at iteration 3172: 0.03931119903728017\n",
      "Norm of gradient at iteration 3173: 0.03912822471225026\n",
      "Norm of gradient at iteration 3174: 0.038946102038496105\n",
      "Norm of gradient at iteration 3175: 0.03876482707018561\n",
      "Norm of gradient at iteration 3176: 0.0385843958391859\n",
      "Norm of gradient at iteration 3177: 0.03840480443854866\n",
      "Norm of gradient at iteration 3178: 0.03822604893664742\n",
      "Norm of gradient at iteration 3179: 0.03804812545613514\n",
      "Norm of gradient at iteration 3180: 0.03787103012265381\n",
      "Norm of gradient at iteration 3181: 0.037694759074840094\n",
      "Norm of gradient at iteration 3182: 0.037519308469405425\n",
      "Norm of gradient at iteration 3183: 0.03734467453926506\n",
      "Norm of gradient at iteration 3184: 0.03717085340916631\n",
      "Norm of gradient at iteration 3185: 0.036997841341188144\n",
      "Norm of gradient at iteration 3186: 0.03682563455605016\n",
      "Norm of gradient at iteration 3187: 0.03665422933143588\n",
      "Norm of gradient at iteration 3188: 0.03648362190448152\n",
      "Norm of gradient at iteration 3189: 0.03631380856883789\n",
      "Norm of gradient at iteration 3190: 0.03614478564125171\n",
      "Norm of gradient at iteration 3191: 0.035976549412066655\n",
      "Norm of gradient at iteration 3192: 0.03580909622449683\n",
      "Norm of gradient at iteration 3193: 0.035642422473803254\n",
      "Norm of gradient at iteration 3194: 0.0354765245207756\n",
      "Norm of gradient at iteration 3195: 0.035311398702148666\n",
      "Norm of gradient at iteration 3196: 0.035147041482802385\n",
      "Norm of gradient at iteration 3197: 0.03498344928383206\n",
      "Norm of gradient at iteration 3198: 0.03482061848433214\n",
      "Norm of gradient at iteration 3199: 0.034658545620685634\n",
      "Norm of gradient at iteration 3200: 0.03449722711515763\n",
      "Norm of gradient at iteration 3201: 0.034336659478928645\n",
      "Norm of gradient at iteration 3202: 0.034176839185812206\n",
      "Norm of gradient at iteration 3203: 0.03401776278652733\n",
      "Norm of gradient at iteration 3204: 0.03385942682246464\n",
      "Norm of gradient at iteration 3205: 0.03370182781560194\n",
      "Norm of gradient at iteration 3206: 0.033544962365521264\n",
      "Norm of gradient at iteration 3207: 0.033388827036791614\n",
      "Norm of gradient at iteration 3208: 0.033233418466378346\n",
      "Norm of gradient at iteration 3209: 0.03307873321978694\n",
      "Norm of gradient at iteration 3210: 0.03292476795591924\n",
      "Norm of gradient at iteration 3211: 0.03277151933984815\n",
      "Norm of gradient at iteration 3212: 0.0326189840228133\n",
      "Norm of gradient at iteration 3213: 0.03246715866972992\n",
      "Norm of gradient at iteration 3214: 0.032316040009098095\n",
      "Norm of gradient at iteration 3215: 0.03216562473169492\n",
      "Norm of gradient at iteration 3216: 0.032015909527299505\n",
      "Norm of gradient at iteration 3217: 0.03186689120275685\n",
      "Norm of gradient at iteration 3218: 0.03171856648010737\n",
      "Norm of gradient at iteration 3219: 0.03157093213022607\n",
      "Norm of gradient at iteration 3220: 0.03142398495165655\n",
      "Norm of gradient at iteration 3221: 0.031277721764950285\n",
      "Norm of gradient at iteration 3222: 0.0311321393016494\n",
      "Norm of gradient at iteration 3223: 0.03098723449540541\n",
      "Norm of gradient at iteration 3224: 0.030843004143504334\n",
      "Norm of gradient at iteration 3225: 0.03069944511780525\n",
      "Norm of gradient at iteration 3226: 0.030556554262041003\n",
      "Norm of gradient at iteration 3227: 0.030414328517872947\n",
      "Norm of gradient at iteration 3228: 0.03027276475987585\n",
      "Norm of gradient at iteration 3229: 0.030131859889247655\n",
      "Norm of gradient at iteration 3230: 0.029991610901163212\n",
      "Norm of gradient at iteration 3231: 0.029852014676536445\n",
      "Norm of gradient at iteration 3232: 0.02971306821457049\n",
      "Norm of gradient at iteration 3233: 0.02957476846783447\n",
      "Norm of gradient at iteration 3234: 0.029437112456569846\n",
      "Norm of gradient at iteration 3235: 0.02930009718829118\n",
      "Norm of gradient at iteration 3236: 0.02916371963054071\n",
      "Norm of gradient at iteration 3237: 0.02902797682899349\n",
      "Norm of gradient at iteration 3238: 0.028892865839314028\n",
      "Norm of gradient at iteration 3239: 0.02875838377009177\n",
      "Norm of gradient at iteration 3240: 0.028624527615443603\n",
      "Norm of gradient at iteration 3241: 0.028491294493298115\n",
      "Norm of gradient at iteration 3242: 0.0283586815161307\n",
      "Norm of gradient at iteration 3243: 0.02822668578110182\n",
      "Norm of gradient at iteration 3244: 0.028095304421129414\n",
      "Norm of gradient at iteration 3245: 0.027964534554359582\n",
      "Norm of gradient at iteration 3246: 0.027834373404752234\n",
      "Norm of gradient at iteration 3247: 0.027704818068579315\n",
      "Norm of gradient at iteration 3248: 0.027575865759448846\n",
      "Norm of gradient at iteration 3249: 0.02744751363771302\n",
      "Norm of gradient at iteration 3250: 0.02731975893727198\n",
      "Norm of gradient at iteration 3251: 0.027192598876896405\n",
      "Norm of gradient at iteration 3252: 0.027066030689733213\n",
      "Norm of gradient at iteration 3253: 0.02694005163215376\n",
      "Norm of gradient at iteration 3254: 0.026814658893322123\n",
      "Norm of gradient at iteration 3255: 0.02668984983447517\n",
      "Norm of gradient at iteration 3256: 0.026565621700300836\n",
      "Norm of gradient at iteration 3257: 0.02644197180641201\n",
      "Norm of gradient at iteration 3258: 0.026318897431476865\n",
      "Norm of gradient at iteration 3259: 0.0261963958761474\n",
      "Norm of gradient at iteration 3260: 0.026074464498157413\n",
      "Norm of gradient at iteration 3261: 0.025953100689382353\n",
      "Norm of gradient at iteration 3262: 0.025832301771800292\n",
      "Norm of gradient at iteration 3263: 0.025712065093071283\n",
      "Norm of gradient at iteration 3264: 0.02559238804268434\n",
      "Norm of gradient at iteration 3265: 0.025473268057314626\n",
      "Norm of gradient at iteration 3266: 0.025354702507166975\n",
      "Norm of gradient at iteration 3267: 0.02523668881481028\n",
      "Norm of gradient at iteration 3268: 0.025119224455550093\n",
      "Norm of gradient at iteration 3269: 0.02500230677823603\n",
      "Norm of gradient at iteration 3270: 0.024885933324890055\n",
      "Norm of gradient at iteration 3271: 0.024770101514991965\n",
      "Norm of gradient at iteration 3272: 0.024654808862162064\n",
      "Norm of gradient at iteration 3273: 0.024540052827757803\n",
      "Norm of gradient at iteration 3274: 0.024425830942712893\n",
      "Norm of gradient at iteration 3275: 0.024312140705007517\n",
      "Norm of gradient at iteration 3276: 0.02419897963050662\n",
      "Norm of gradient at iteration 3277: 0.024086345276319168\n",
      "Norm of gradient at iteration 3278: 0.0239742351505963\n",
      "Norm of gradient at iteration 3279: 0.023862646900757113\n",
      "Norm of gradient at iteration 3280: 0.02375157796165728\n",
      "Norm of gradient at iteration 3281: 0.02364102603438285\n",
      "Norm of gradient at iteration 3282: 0.02353098866280773\n",
      "Norm of gradient at iteration 3283: 0.02342146346060473\n",
      "Norm of gradient at iteration 3284: 0.023312448052641217\n",
      "Norm of gradient at iteration 3285: 0.02320394006442101\n",
      "Norm of gradient at iteration 3286: 0.023095937124654364\n",
      "Norm of gradient at iteration 3287: 0.02298843689159713\n",
      "Norm of gradient at iteration 3288: 0.022881436988509255\n",
      "Norm of gradient at iteration 3289: 0.022774935124052095\n",
      "Norm of gradient at iteration 3290: 0.022668929022874883\n",
      "Norm of gradient at iteration 3291: 0.022563416277443616\n",
      "Norm of gradient at iteration 3292: 0.022458394659039194\n",
      "Norm of gradient at iteration 3293: 0.022353861855578607\n",
      "Norm of gradient at iteration 3294: 0.02224981560891703\n",
      "Norm of gradient at iteration 3295: 0.022146253638703706\n",
      "Norm of gradient at iteration 3296: 0.022043173733269875\n",
      "Norm of gradient at iteration 3297: 0.02194057355099592\n",
      "Norm of gradient at iteration 3298: 0.021838450959827352\n",
      "Norm of gradient at iteration 3299: 0.021736803701012383\n",
      "Norm of gradient at iteration 3300: 0.021635629563213177\n",
      "Norm of gradient at iteration 3301: 0.021534926339170583\n",
      "Norm of gradient at iteration 3302: 0.02143469184221117\n",
      "Norm of gradient at iteration 3303: 0.02133492388219173\n",
      "Norm of gradient at iteration 3304: 0.02123562027486125\n",
      "Norm of gradient at iteration 3305: 0.021136778915144316\n",
      "Norm of gradient at iteration 3306: 0.021038397579730583\n",
      "Norm of gradient at iteration 3307: 0.020940474176646084\n",
      "Norm of gradient at iteration 3308: 0.020843006570051607\n",
      "Norm of gradient at iteration 3309: 0.02074599259770163\n",
      "Norm of gradient at iteration 3310: 0.020649430180895524\n",
      "Norm of gradient at iteration 3311: 0.020553317222675383\n",
      "Norm of gradient at iteration 3312: 0.020457651626474005\n",
      "Norm of gradient at iteration 3313: 0.020362431299585614\n",
      "Norm of gradient at iteration 3314: 0.020267654186005145\n",
      "Norm of gradient at iteration 3315: 0.020173318196393845\n",
      "Norm of gradient at iteration 3316: 0.020079421316945886\n",
      "Norm of gradient at iteration 3317: 0.019985961459729\n",
      "Norm of gradient at iteration 3318: 0.01989293662959249\n",
      "Norm of gradient at iteration 3319: 0.019800344786250725\n",
      "Norm of gradient at iteration 3320: 0.019708183890463204\n",
      "Norm of gradient at iteration 3321: 0.019616452000469048\n",
      "Norm of gradient at iteration 3322: 0.01952514703609127\n",
      "Norm of gradient at iteration 3323: 0.019434267084271137\n",
      "Norm of gradient at iteration 3324: 0.019343810098391475\n",
      "Norm of gradient at iteration 3325: 0.019253774167317425\n",
      "Norm of gradient at iteration 3326: 0.01916415729405007\n",
      "Norm of gradient at iteration 3327: 0.0190749575576892\n",
      "Norm of gradient at iteration 3328: 0.01898617299844952\n",
      "Norm of gradient at iteration 3329: 0.018897801681692836\n",
      "Norm of gradient at iteration 3330: 0.01880984166721014\n",
      "Norm of gradient at iteration 3331: 0.018722291128904146\n",
      "Norm of gradient at iteration 3332: 0.01863514803011086\n",
      "Norm of gradient at iteration 3333: 0.01854841057662173\n",
      "Norm of gradient at iteration 3334: 0.01846207682181461\n",
      "Norm of gradient at iteration 3335: 0.018376144931343527\n",
      "Norm of gradient at iteration 3336: 0.018290612982939894\n",
      "Norm of gradient at iteration 3337: 0.01820547916771106\n",
      "Norm of gradient at iteration 3338: 0.01812074159951427\n",
      "Norm of gradient at iteration 3339: 0.018036398477220595\n",
      "Norm of gradient at iteration 3340: 0.01795244790069215\n",
      "Norm of gradient at iteration 3341: 0.01786888808104177\n",
      "Norm of gradient at iteration 3342: 0.01778571717890477\n",
      "Norm of gradient at iteration 3343: 0.01770293341971836\n",
      "Norm of gradient at iteration 3344: 0.017620534955403225\n",
      "Norm of gradient at iteration 3345: 0.0175385200101163\n",
      "Norm of gradient at iteration 3346: 0.01745688681118204\n",
      "Norm of gradient at iteration 3347: 0.017375633588347858\n",
      "Norm of gradient at iteration 3348: 0.017294758556319182\n",
      "Norm of gradient at iteration 3349: 0.017214259939511936\n",
      "Norm of gradient at iteration 3350: 0.01713413601023344\n",
      "Norm of gradient at iteration 3351: 0.017054385037868224\n",
      "Norm of gradient at iteration 3352: 0.016975005252682782\n",
      "Norm of gradient at iteration 3353: 0.01689599494307831\n",
      "Norm of gradient at iteration 3354: 0.01681735238137976\n",
      "Norm of gradient at iteration 3355: 0.016739075877665325\n",
      "Norm of gradient at iteration 3356: 0.016661163704754834\n",
      "Norm of gradient at iteration 3357: 0.01658361417065765\n",
      "Norm of gradient at iteration 3358: 0.016506425590425707\n",
      "Norm of gradient at iteration 3359: 0.016429596273833936\n",
      "Norm of gradient at iteration 3360: 0.01635312458309736\n",
      "Norm of gradient at iteration 3361: 0.016277008823573365\n",
      "Norm of gradient at iteration 3362: 0.016201247349924373\n",
      "Norm of gradient at iteration 3363: 0.016125838494316414\n",
      "Norm of gradient at iteration 3364: 0.016050780653489975\n",
      "Norm of gradient at iteration 3365: 0.015976072160828202\n",
      "Norm of gradient at iteration 3366: 0.015901711380502975\n",
      "Norm of gradient at iteration 3367: 0.01582769671895412\n",
      "Norm of gradient at iteration 3368: 0.01575402656686065\n",
      "Norm of gradient at iteration 3369: 0.01568069931568554\n",
      "Norm of gradient at iteration 3370: 0.015607713352504228\n",
      "Norm of gradient at iteration 3371: 0.015535067131862475\n",
      "Norm of gradient at iteration 3372: 0.015462759020303854\n",
      "Norm of gradient at iteration 3373: 0.015390787473615474\n",
      "Norm of gradient at iteration 3374: 0.015319150938350151\n",
      "Norm of gradient at iteration 3375: 0.015247847804210138\n",
      "Norm of gradient at iteration 3376: 0.015176876564520604\n",
      "Norm of gradient at iteration 3377: 0.015106235668781585\n",
      "Norm of gradient at iteration 3378: 0.015035923560540556\n",
      "Norm of gradient at iteration 3379: 0.014965938729496394\n",
      "Norm of gradient at iteration 3380: 0.014896279612350814\n",
      "Norm of gradient at iteration 3381: 0.014826944745463854\n",
      "Norm of gradient at iteration 3382: 0.014757932606793511\n",
      "Norm of gradient at iteration 3383: 0.014689241682228479\n",
      "Norm of gradient at iteration 3384: 0.014620870481540022\n",
      "Norm of gradient at iteration 3385: 0.014552817524394036\n",
      "Norm of gradient at iteration 3386: 0.014485081291877536\n",
      "Norm of gradient at iteration 3387: 0.014417660348590914\n",
      "Norm of gradient at iteration 3388: 0.01435055321625056\n",
      "Norm of gradient at iteration 3389: 0.014283758453757647\n",
      "Norm of gradient at iteration 3390: 0.01421727456612285\n",
      "Norm of gradient at iteration 3391: 0.014151100134685572\n",
      "Norm of gradient at iteration 3392: 0.014085233714569847\n",
      "Norm of gradient at iteration 3393: 0.014019673889660649\n",
      "Norm of gradient at iteration 3394: 0.013954419188583828\n",
      "Norm of gradient at iteration 3395: 0.01388946820154864\n",
      "Norm of gradient at iteration 3396: 0.01382481956423645\n",
      "Norm of gradient at iteration 3397: 0.013760471852255518\n",
      "Norm of gradient at iteration 3398: 0.013696423608005529\n",
      "Norm of gradient at iteration 3399: 0.013632673471065858\n",
      "Norm of gradient at iteration 3400: 0.013569220051335257\n",
      "Norm of gradient at iteration 3401: 0.013506061997162045\n",
      "Norm of gradient at iteration 3402: 0.013443197919604818\n",
      "Norm of gradient at iteration 3403: 0.013380626444805163\n",
      "Norm of gradient at iteration 3404: 0.013318346206205374\n",
      "Norm of gradient at iteration 3405: 0.013256355820278865\n",
      "Norm of gradient at iteration 3406: 0.013194654000758702\n",
      "Norm of gradient at iteration 3407: 0.013133239370193013\n",
      "Norm of gradient at iteration 3408: 0.013072110603653425\n",
      "Norm of gradient at iteration 3409: 0.013011266321752965\n",
      "Norm of gradient at iteration 3410: 0.012950705272050602\n",
      "Norm of gradient at iteration 3411: 0.012890426091392546\n",
      "Norm of gradient at iteration 3412: 0.01283042751382931\n",
      "Norm of gradient at iteration 3413: 0.012770708138010985\n",
      "Norm of gradient at iteration 3414: 0.012711266798289388\n",
      "Norm of gradient at iteration 3415: 0.012652102080553056\n",
      "Norm of gradient at iteration 3416: 0.012593212745040952\n",
      "Norm of gradient at iteration 3417: 0.012534597554829632\n",
      "Norm of gradient at iteration 3418: 0.012476255145497916\n",
      "Norm of gradient at iteration 3419: 0.012418184301964178\n",
      "Norm of gradient at iteration 3420: 0.012360383762801476\n",
      "Norm of gradient at iteration 3421: 0.012302852234110153\n",
      "Norm of gradient at iteration 3422: 0.012245588508202726\n",
      "Norm of gradient at iteration 3423: 0.012188591297955716\n",
      "Norm of gradient at iteration 3424: 0.01213185941545401\n",
      "Norm of gradient at iteration 3425: 0.012075391576237781\n",
      "Norm of gradient at iteration 3426: 0.012019186561157276\n",
      "Norm of gradient at iteration 3427: 0.011963243148665705\n",
      "Norm of gradient at iteration 3428: 0.011907560132327643\n",
      "Norm of gradient at iteration 3429: 0.011852136271935543\n",
      "Norm of gradient at iteration 3430: 0.01179697040026846\n",
      "Norm of gradient at iteration 3431: 0.011742061316598622\n",
      "Norm of gradient at iteration 3432: 0.011687407767006715\n",
      "Norm of gradient at iteration 3433: 0.01163300863480003\n",
      "Norm of gradient at iteration 3434: 0.011578862687765505\n",
      "Norm of gradient at iteration 3435: 0.011524968778516494\n",
      "Norm of gradient at iteration 3436: 0.011471325728425184\n",
      "Norm of gradient at iteration 3437: 0.011417932342258429\n",
      "Norm of gradient at iteration 3438: 0.011364787475937057\n",
      "Norm of gradient at iteration 3439: 0.011311889978655983\n",
      "Norm of gradient at iteration 3440: 0.01125923867779671\n",
      "Norm of gradient at iteration 3441: 0.011206832465653373\n",
      "Norm of gradient at iteration 3442: 0.011154670158376703\n",
      "Norm of gradient at iteration 3443: 0.011102750655388677\n",
      "Norm of gradient at iteration 3444: 0.011051072765373683\n",
      "Norm of gradient at iteration 3445: 0.01099963545716401\n",
      "Norm of gradient at iteration 3446: 0.010948437568975173\n",
      "Norm of gradient at iteration 3447: 0.01089747797564654\n",
      "Norm of gradient at iteration 3448: 0.01084675558235325\n",
      "Norm of gradient at iteration 3449: 0.010796269244634976\n",
      "Norm of gradient at iteration 3450: 0.010746017922180415\n",
      "Norm of gradient at iteration 3451: 0.010696000486219027\n",
      "Norm of gradient at iteration 3452: 0.010646215853822305\n",
      "Norm of gradient at iteration 3453: 0.0105966629397014\n",
      "Norm of gradient at iteration 3454: 0.010547340678122796\n",
      "Norm of gradient at iteration 3455: 0.010498247988329653\n",
      "Norm of gradient at iteration 3456: 0.01044938379588333\n",
      "Norm of gradient at iteration 3457: 0.010400747042464801\n",
      "Norm of gradient at iteration 3458: 0.010352336688935437\n",
      "Norm of gradient at iteration 3459: 0.010304151641177406\n",
      "Norm of gradient at iteration 3460: 0.010256190868113284\n",
      "Norm of gradient at iteration 3461: 0.010208453326850815\n",
      "Norm of gradient at iteration 3462: 0.010160938009527847\n",
      "Norm of gradient at iteration 3463: 0.010113643825462593\n",
      "Norm of gradient at iteration 3464: 0.010066569767900399\n",
      "Norm of gradient at iteration 3465: 0.010019714839334455\n",
      "Norm of gradient at iteration 3466: 0.00997307796422632\n",
      "Norm of gradient at iteration 3467: 0.009926658200398673\n",
      "Norm of gradient at iteration 3468: 0.009880454519114788\n",
      "Norm of gradient at iteration 3469: 0.009834465840706026\n",
      "Norm of gradient at iteration 3470: 0.009788691234120296\n",
      "Norm of gradient at iteration 3471: 0.009743129685028959\n",
      "Norm of gradient at iteration 3472: 0.009697780213235693\n",
      "Norm of gradient at iteration 3473: 0.009652641803647683\n",
      "Norm of gradient at iteration 3474: 0.009607713488139023\n",
      "Norm of gradient at iteration 3475: 0.009562994316325488\n",
      "Norm of gradient at iteration 3476: 0.00951848326162312\n",
      "Norm of gradient at iteration 3477: 0.009474179410860165\n",
      "Norm of gradient at iteration 3478: 0.009430081743753711\n",
      "Norm of gradient at iteration 3479: 0.009386189337433053\n",
      "Norm of gradient at iteration 3480: 0.009342501228274193\n",
      "Norm of gradient at iteration 3481: 0.00929901648310955\n",
      "Norm of gradient at iteration 3482: 0.009255734131807806\n",
      "Norm of gradient at iteration 3483: 0.009212653215884227\n",
      "Norm of gradient at iteration 3484: 0.009169772865963694\n",
      "Norm of gradient at iteration 3485: 0.009127092080842976\n",
      "Norm of gradient at iteration 3486: 0.00908460994425819\n",
      "Norm of gradient at iteration 3487: 0.009042325529787213\n",
      "Norm of gradient at iteration 3488: 0.00900023794502183\n",
      "Norm of gradient at iteration 3489: 0.00895834626370547\n",
      "Norm of gradient at iteration 3490: 0.00891664955488533\n",
      "Norm of gradient at iteration 3491: 0.008875146935787096\n",
      "Norm of gradient at iteration 3492: 0.008833837487510194\n",
      "Norm of gradient at iteration 3493: 0.008792720308571726\n",
      "Norm of gradient at iteration 3494: 0.008751794505739341\n",
      "Norm of gradient at iteration 3495: 0.008711059193383408\n",
      "Norm of gradient at iteration 3496: 0.008670513497055964\n",
      "Norm of gradient at iteration 3497: 0.008630156503369867\n",
      "Norm of gradient at iteration 3498: 0.008589987371344285\n",
      "Norm of gradient at iteration 3499: 0.008550005200817203\n",
      "Norm of gradient at iteration 3500: 0.008510209124573022\n",
      "Norm of gradient at iteration 3501: 0.008470598292461834\n",
      "Norm of gradient at iteration 3502: 0.008431171806016583\n",
      "Norm of gradient at iteration 3503: 0.008391928845084306\n",
      "Norm of gradient at iteration 3504: 0.008352868522421604\n",
      "Norm of gradient at iteration 3505: 0.00831399004727314\n",
      "Norm of gradient at iteration 3506: 0.008275292494709364\n",
      "Norm of gradient at iteration 3507: 0.008236775096227172\n",
      "Norm of gradient at iteration 3508: 0.008198436952257412\n",
      "Norm of gradient at iteration 3509: 0.008160277260785399\n",
      "Norm of gradient at iteration 3510: 0.008122295160503905\n",
      "Norm of gradient at iteration 3511: 0.008084489871862317\n",
      "Norm of gradient at iteration 3512: 0.008046860553327663\n",
      "Norm of gradient at iteration 3513: 0.008009406363435391\n",
      "Norm of gradient at iteration 3514: 0.007972126492088538\n",
      "Norm of gradient at iteration 3515: 0.00793502016082457\n",
      "Norm of gradient at iteration 3516: 0.007898086541299622\n",
      "Norm of gradient at iteration 3517: 0.007861324831809808\n",
      "Norm of gradient at iteration 3518: 0.007824734244687616\n",
      "Norm of gradient at iteration 3519: 0.0077883139404725\n",
      "Norm of gradient at iteration 3520: 0.007752063147283094\n",
      "Norm of gradient at iteration 3521: 0.007715981105872982\n",
      "Norm of gradient at iteration 3522: 0.007680066992133555\n",
      "Norm of gradient at iteration 3523: 0.007644320033433106\n",
      "Norm of gradient at iteration 3524: 0.007608739515257925\n",
      "Norm of gradient at iteration 3525: 0.007573324552062552\n",
      "Norm of gradient at iteration 3526: 0.00753807444067112\n",
      "Norm of gradient at iteration 3527: 0.007502988397138582\n",
      "Norm of gradient at iteration 3528: 0.00746806566418267\n",
      "Norm of gradient at iteration 3529: 0.007433305500479233\n",
      "Norm of gradient at iteration 3530: 0.00739870710263357\n",
      "Norm of gradient at iteration 3531: 0.0073642697583957235\n",
      "Norm of gradient at iteration 3532: 0.00732999270423061\n",
      "Norm of gradient at iteration 3533: 0.007295875174078152\n",
      "Norm of gradient at iteration 3534: 0.0072619164739829165\n",
      "Norm of gradient at iteration 3535: 0.007228115823492161\n",
      "Norm of gradient at iteration 3536: 0.007194472517162129\n",
      "Norm of gradient at iteration 3537: 0.007160985766046399\n",
      "Norm of gradient at iteration 3538: 0.007127654892935994\n",
      "Norm of gradient at iteration 3539: 0.007094479159929589\n",
      "Norm of gradient at iteration 3540: 0.007061457864265961\n",
      "Norm of gradient at iteration 3541: 0.007028590253925506\n",
      "Norm of gradient at iteration 3542: 0.006995875586737234\n",
      "Norm of gradient at iteration 3543: 0.00696331321670263\n",
      "Norm of gradient at iteration 3544: 0.006930902437062525\n",
      "Norm of gradient at iteration 3545: 0.006898642461532078\n",
      "Norm of gradient at iteration 3546: 0.006866532661358332\n",
      "Norm of gradient at iteration 3547: 0.006834572323005608\n",
      "Norm of gradient at iteration 3548: 0.0068027607459817535\n",
      "Norm of gradient at iteration 3549: 0.0067710972537939305\n",
      "Norm of gradient at iteration 3550: 0.006739581080414212\n",
      "Norm of gradient at iteration 3551: 0.006708211655135164\n",
      "Norm of gradient at iteration 3552: 0.006676988202366219\n",
      "Norm of gradient at iteration 3553: 0.006645910101985324\n",
      "Norm of gradient at iteration 3554: 0.006614976661492192\n",
      "Norm of gradient at iteration 3555: 0.0065841872027004094\n",
      "Norm of gradient at iteration 3556: 0.006553541034495776\n",
      "Norm of gradient at iteration 3557: 0.006523037514198774\n",
      "Norm of gradient at iteration 3558: 0.006492675984558819\n",
      "Norm of gradient at iteration 3559: 0.00646245577667129\n",
      "Norm of gradient at iteration 3560: 0.00643237621350972\n",
      "Norm of gradient at iteration 3561: 0.006402436657051935\n",
      "Norm of gradient at iteration 3562: 0.0063726364568757925\n",
      "Norm of gradient at iteration 3563: 0.006342974970427366\n",
      "Norm of gradient at iteration 3564: 0.006313451535872382\n",
      "Norm of gradient at iteration 3565: 0.006284065509259191\n",
      "Norm of gradient at iteration 3566: 0.006254816269702019\n",
      "Norm of gradient at iteration 3567: 0.006225703171708139\n",
      "Norm of gradient at iteration 3568: 0.006196725571552986\n",
      "Norm of gradient at iteration 3569: 0.006167882879488437\n",
      "Norm of gradient at iteration 3570: 0.006139174418462652\n",
      "Norm of gradient at iteration 3571: 0.006110599561726682\n",
      "Norm of gradient at iteration 3572: 0.006082157744500551\n",
      "Norm of gradient at iteration 3573: 0.0060538482709449485\n",
      "Norm of gradient at iteration 3574: 0.0060256705771890426\n",
      "Norm of gradient at iteration 3575: 0.00599762405046503\n",
      "Norm of gradient at iteration 3576: 0.005969708053238472\n",
      "Norm of gradient at iteration 3577: 0.005941922003136967\n",
      "Norm of gradient at iteration 3578: 0.005914265256317872\n",
      "Norm of gradient at iteration 3579: 0.005886737276376296\n",
      "Norm of gradient at iteration 3580: 0.005859337397184493\n",
      "Norm of gradient at iteration 3581: 0.005832065063943065\n",
      "Norm of gradient at iteration 3582: 0.005804919657753644\n",
      "Norm of gradient at iteration 3583: 0.005777900596250916\n",
      "Norm of gradient at iteration 3584: 0.005751007323848357\n",
      "Norm of gradient at iteration 3585: 0.0057242391974007285\n",
      "Norm of gradient at iteration 3586: 0.005697595673297938\n",
      "Norm of gradient at iteration 3587: 0.005671076172491247\n",
      "Norm of gradient at iteration 3588: 0.005644680085589265\n",
      "Norm of gradient at iteration 3589: 0.005618406879783296\n",
      "Norm of gradient at iteration 3590: 0.005592255971566538\n",
      "Norm of gradient at iteration 3591: 0.005566226740293038\n",
      "Norm of gradient at iteration 3592: 0.0055403187103208705\n",
      "Norm of gradient at iteration 3593: 0.0055145312420628095\n",
      "Norm of gradient at iteration 3594: 0.005488863809185842\n",
      "Norm of gradient at iteration 3595: 0.0054633158409319515\n",
      "Norm of gradient at iteration 3596: 0.005437886806453198\n",
      "Norm of gradient at iteration 3597: 0.00541257609527576\n",
      "Norm of gradient at iteration 3598: 0.005387383228131175\n",
      "Norm of gradient at iteration 3599: 0.005362307596977099\n",
      "Norm of gradient at iteration 3600: 0.005337348696430905\n",
      "Norm of gradient at iteration 3601: 0.005312505966201413\n",
      "Norm of gradient at iteration 3602: 0.005287778854955643\n",
      "Norm of gradient at iteration 3603: 0.005263166849250052\n",
      "Norm of gradient at iteration 3604: 0.005238669381789216\n",
      "Norm of gradient at iteration 3605: 0.005214285950945865\n",
      "Norm of gradient at iteration 3606: 0.005190015984011318\n",
      "Norm of gradient at iteration 3607: 0.005165859014581463\n",
      "Norm of gradient at iteration 3608: 0.005141814475082613\n",
      "Norm of gradient at iteration 3609: 0.005117881855627242\n",
      "Norm of gradient at iteration 3610: 0.0050940606320221266\n",
      "Norm of gradient at iteration 3611: 0.005070350296581467\n",
      "Norm of gradient at iteration 3612: 0.005046750310245285\n",
      "Norm of gradient at iteration 3613: 0.005023260149131974\n",
      "Norm of gradient at iteration 3614: 0.0049998793557412885\n",
      "Norm of gradient at iteration 3615: 0.004976607357813776\n",
      "Norm of gradient at iteration 3616: 0.0049534436829644325\n",
      "Norm of gradient at iteration 3617: 0.0049303878499058155\n",
      "Norm of gradient at iteration 3618: 0.004907439318084573\n",
      "Norm of gradient at iteration 3619: 0.004884597600930779\n",
      "Norm of gradient at iteration 3620: 0.004861862193876577\n",
      "Norm of gradient at iteration 3621: 0.004839232619521979\n",
      "Norm of gradient at iteration 3622: 0.0048167083804312024\n",
      "Norm of gradient at iteration 3623: 0.004794288965660046\n",
      "Norm of gradient at iteration 3624: 0.004771973908783995\n",
      "Norm of gradient at iteration 3625: 0.004749762706585261\n",
      "Norm of gradient at iteration 3626: 0.0047276548882208835\n",
      "Norm of gradient at iteration 3627: 0.0047056499836538816\n",
      "Norm of gradient at iteration 3628: 0.0046837474817030544\n",
      "Norm of gradient at iteration 3629: 0.0046619469201558865\n",
      "Norm of gradient at iteration 3630: 0.004640247872507732\n",
      "Norm of gradient at iteration 3631: 0.0046186497946838646\n",
      "Norm of gradient at iteration 3632: 0.004597152272830032\n",
      "Norm of gradient at iteration 3633: 0.004575754773587674\n",
      "Norm of gradient at iteration 3634: 0.004554456872217578\n",
      "Norm of gradient at iteration 3635: 0.004533258102780691\n",
      "Norm of gradient at iteration 3636: 0.004512158040959743\n",
      "Norm of gradient at iteration 3637: 0.004491156157803783\n",
      "Norm of gradient at iteration 3638: 0.0044702520244981805\n",
      "Norm of gradient at iteration 3639: 0.004449445207159872\n",
      "Norm of gradient at iteration 3640: 0.00442873524089917\n",
      "Norm of gradient at iteration 3641: 0.004408121639681264\n",
      "Norm of gradient at iteration 3642: 0.004387603991929786\n",
      "Norm of gradient at iteration 3643: 0.004367181846039689\n",
      "Norm of gradient at iteration 3644: 0.004346854737020412\n",
      "Norm of gradient at iteration 3645: 0.004326622278565521\n",
      "Norm of gradient at iteration 3646: 0.00430648396690079\n",
      "Norm of gradient at iteration 3647: 0.004286439401884187\n",
      "Norm of gradient at iteration 3648: 0.004266488096411365\n",
      "Norm of gradient at iteration 3649: 0.004246629708250323\n",
      "Norm of gradient at iteration 3650: 0.004226863763213098\n",
      "Norm of gradient at iteration 3651: 0.004207189780171994\n",
      "Norm of gradient at iteration 3652: 0.004187607365576338\n",
      "Norm of gradient at iteration 3653: 0.004168116120569983\n",
      "Norm of gradient at iteration 3654: 0.0041487155717054485\n",
      "Norm of gradient at iteration 3655: 0.004129405325297583\n",
      "Norm of gradient at iteration 3656: 0.004110184980358561\n",
      "Norm of gradient at iteration 3657: 0.00409105407632511\n",
      "Norm of gradient at iteration 3658: 0.004072012232311673\n",
      "Norm of gradient at iteration 3659: 0.004053059028308913\n",
      "Norm of gradient at iteration 3660: 0.00403419398296225\n",
      "Norm of gradient at iteration 3661: 0.004015416807837738\n",
      "Norm of gradient at iteration 3662: 0.003996727022324021\n",
      "Norm of gradient at iteration 3663: 0.003978124240934766\n",
      "Norm of gradient at iteration 3664: 0.003959608015954815\n",
      "Norm of gradient at iteration 3665: 0.003941178005042197\n",
      "Norm of gradient at iteration 3666: 0.003922833748554273\n",
      "Norm of gradient at iteration 3667: 0.0039045748881056056\n",
      "Norm of gradient at iteration 3668: 0.00388640101145808\n",
      "Norm of gradient at iteration 3669: 0.0038683117190606237\n",
      "Norm of gradient at iteration 3670: 0.003850306631043086\n",
      "Norm of gradient at iteration 3671: 0.003832385340211708\n",
      "Norm of gradient at iteration 3672: 0.0038145474688761737\n",
      "Norm of gradient at iteration 3673: 0.0037967926350663253\n",
      "Norm of gradient at iteration 3674: 0.003779120438740827\n",
      "Norm of gradient at iteration 3675: 0.003761530467398109\n",
      "Norm of gradient at iteration 3676: 0.003744022380617711\n",
      "Norm of gradient at iteration 3677: 0.00372659580378574\n",
      "Norm of gradient at iteration 3678: 0.0037092503198979687\n",
      "Norm of gradient at iteration 3679: 0.0036919855663166937\n",
      "Norm of gradient at iteration 3680: 0.003674801211403769\n",
      "Norm of gradient at iteration 3681: 0.0036576968258328233\n",
      "Norm of gradient at iteration 3682: 0.003640672016814229\n",
      "Norm of gradient at iteration 3683: 0.003623726470920676\n",
      "Norm of gradient at iteration 3684: 0.0036068598012605423\n",
      "Norm of gradient at iteration 3685: 0.0035900716538240815\n",
      "Norm of gradient at iteration 3686: 0.003573361632187236\n",
      "Norm of gradient at iteration 3687: 0.0035567293622814035\n",
      "Norm of gradient at iteration 3688: 0.0035401745456267193\n",
      "Norm of gradient at iteration 3689: 0.0035236967659146657\n",
      "Norm of gradient at iteration 3690: 0.0035072956873098836\n",
      "Norm of gradient at iteration 3691: 0.003490970918647904\n",
      "Norm of gradient at iteration 3692: 0.0034747222116095645\n",
      "Norm of gradient at iteration 3693: 0.0034585490626381056\n",
      "Norm of gradient at iteration 3694: 0.0034424512312945326\n",
      "Norm of gradient at iteration 3695: 0.0034264282982207836\n",
      "Norm of gradient at iteration 3696: 0.0034104799615991997\n",
      "Norm of gradient at iteration 3697: 0.0033946058299303833\n",
      "Norm of gradient at iteration 3698: 0.0033788056056286955\n",
      "Norm of gradient at iteration 3699: 0.003363078933845076\n",
      "Norm of gradient at iteration 3700: 0.003347425429887599\n",
      "Norm of gradient at iteration 3701: 0.0033318447989359045\n",
      "Norm of gradient at iteration 3702: 0.0033163367046102005\n",
      "Norm of gradient at iteration 3703: 0.0033009007891227266\n",
      "Norm of gradient at iteration 3704: 0.0032855367141052393\n",
      "Norm of gradient at iteration 3705: 0.0032702441671397936\n",
      "Norm of gradient at iteration 3706: 0.003255022790613622\n",
      "Norm of gradient at iteration 3707: 0.003239872245000389\n",
      "Norm of gradient at iteration 3708: 0.003224792217360243\n",
      "Norm of gradient at iteration 3709: 0.0032097823929251733\n",
      "Norm of gradient at iteration 3710: 0.0031948424294159315\n",
      "Norm of gradient at iteration 3711: 0.0031799719708792925\n",
      "Norm of gradient at iteration 3712: 0.003165170766325693\n",
      "Norm of gradient at iteration 3713: 0.0031504384520199564\n",
      "Norm of gradient at iteration 3714: 0.003135774703206322\n",
      "Norm of gradient at iteration 3715: 0.0031211792286145405\n",
      "Norm of gradient at iteration 3716: 0.003106651651668841\n",
      "Norm of gradient at iteration 3717: 0.003092191719031706\n",
      "Norm of gradient at iteration 3718: 0.0030777991014757167\n",
      "Norm of gradient at iteration 3719: 0.003063473437188459\n",
      "Norm of gradient at iteration 3720: 0.0030492144760796746\n",
      "Norm of gradient at iteration 3721: 0.0030350218914778795\n",
      "Norm of gradient at iteration 3722: 0.003020895353090822\n",
      "Norm of gradient at iteration 3723: 0.003006834554903325\n",
      "Norm of gradient at iteration 3724: 0.0029928392482027233\n",
      "Norm of gradient at iteration 3725: 0.0029789090390999547\n",
      "Norm of gradient at iteration 3726: 0.002965043684930575\n",
      "Norm of gradient at iteration 3727: 0.002951242868937266\n",
      "Norm of gradient at iteration 3728: 0.002937506258437928\n",
      "Norm of gradient at iteration 3729: 0.0029238336464390527\n",
      "Norm of gradient at iteration 3730: 0.0029102246002362143\n",
      "Norm of gradient at iteration 3731: 0.0028966789525401424\n",
      "Norm of gradient at iteration 3732: 0.0028831963349627994\n",
      "Norm of gradient at iteration 3733: 0.002869776460677464\n",
      "Norm of gradient at iteration 3734: 0.0028564190683774164\n",
      "Norm of gradient at iteration 3735: 0.0028431238269422347\n",
      "Norm of gradient at iteration 3736: 0.002829890478642111\n",
      "Norm of gradient at iteration 3737: 0.002816718738470641\n",
      "Norm of gradient at iteration 3738: 0.002803608300883135\n",
      "Norm of gradient at iteration 3739: 0.002790558873733866\n",
      "Norm of gradient at iteration 3740: 0.0027775701759628476\n",
      "Norm of gradient at iteration 3741: 0.0027646419733602066\n",
      "Norm of gradient at iteration 3742: 0.0027517739178860743\n",
      "Norm of gradient at iteration 3743: 0.0027389657619676408\n",
      "Norm of gradient at iteration 3744: 0.00272621721707716\n",
      "Norm of gradient at iteration 3745: 0.0027135280216565006\n",
      "Norm of gradient at iteration 3746: 0.0027008979012965455\n",
      "Norm of gradient at iteration 3747: 0.0026883265345044116\n",
      "Norm of gradient at iteration 3748: 0.0026758136710737864\n",
      "Norm of gradient at iteration 3749: 0.002663359084248496\n",
      "Norm of gradient at iteration 3750: 0.0026509624728882518\n",
      "Norm of gradient at iteration 3751: 0.0026386235243087953\n",
      "Norm of gradient at iteration 3752: 0.002626342026949541\n",
      "Norm of gradient at iteration 3753: 0.002614117670540531\n",
      "Norm of gradient at iteration 3754: 0.0026019502682383564\n",
      "Norm of gradient at iteration 3755: 0.0025898394554601353\n",
      "Norm of gradient at iteration 3756: 0.0025777850408485316\n",
      "Norm of gradient at iteration 3757: 0.002565786726837926\n",
      "Norm of gradient at iteration 3758: 0.002553844233073995\n",
      "Norm of gradient at iteration 3759: 0.002541957336189609\n",
      "Norm of gradient at iteration 3760: 0.0025301257767859475\n",
      "Norm of gradient at iteration 3761: 0.002518349278241318\n",
      "Norm of gradient at iteration 3762: 0.0025066276022047617\n",
      "Norm of gradient at iteration 3763: 0.0024949604928515045\n",
      "Norm of gradient at iteration 3764: 0.002483347676671313\n",
      "Norm of gradient at iteration 3765: 0.0024717889186230265\n",
      "Norm of gradient at iteration 3766: 0.0024602839489048295\n",
      "Norm of gradient at iteration 3767: 0.002448832514754976\n",
      "Norm of gradient at iteration 3768: 0.0024374344304862847\n",
      "Norm of gradient at iteration 3769: 0.0024260893700724312\n",
      "Norm of gradient at iteration 3770: 0.002414797136416192\n",
      "Norm of gradient at iteration 3771: 0.002403557452424235\n",
      "Norm of gradient at iteration 3772: 0.0023923700393080035\n",
      "Norm of gradient at iteration 3773: 0.0023812347500909575\n",
      "Norm of gradient at iteration 3774: 0.0023701513007093546\n",
      "Norm of gradient at iteration 3775: 0.0023591193881976427\n",
      "Norm of gradient at iteration 3776: 0.0023481388508445906\n",
      "Norm of gradient at iteration 3777: 0.0023372094210955805\n",
      "Norm of gradient at iteration 3778: 0.002326330854853401\n",
      "Norm of gradient at iteration 3779: 0.0023155029283381365\n",
      "Norm of gradient at iteration 3780: 0.0023047253932754978\n",
      "Norm of gradient at iteration 3781: 0.0022939980337185117\n",
      "Norm of gradient at iteration 3782: 0.002283320597991703\n",
      "Norm of gradient at iteration 3783: 0.002272692847891296\n",
      "Norm of gradient at iteration 3784: 0.002262114599102039\n",
      "Norm of gradient at iteration 3785: 0.002251585571057423\n",
      "Norm of gradient at iteration 3786: 0.0022411055376694105\n",
      "Norm of gradient at iteration 3787: 0.0022306742876919633\n",
      "Norm of gradient at iteration 3788: 0.0022202916138150774\n",
      "Norm of gradient at iteration 3789: 0.0022099572613018077\n",
      "Norm of gradient at iteration 3790: 0.0021996709749573045\n",
      "Norm of gradient at iteration 3791: 0.0021894326037330152\n",
      "Norm of gradient at iteration 3792: 0.002179241863794027\n",
      "Norm of gradient at iteration 3793: 0.0021690985730968664\n",
      "Norm of gradient at iteration 3794: 0.002159002488895769\n",
      "Norm of gradient at iteration 3795: 0.0021489533885607898\n",
      "Norm of gradient at iteration 3796: 0.002138951070609914\n",
      "Norm of gradient at iteration 3797: 0.0021289952993454727\n",
      "Norm of gradient at iteration 3798: 0.002119085861044111\n",
      "Norm of gradient at iteration 3799: 0.0021092225660396665\n",
      "Norm of gradient at iteration 3800: 0.002099405177660835\n",
      "Norm of gradient at iteration 3801: 0.002089633474852337\n",
      "Norm of gradient at iteration 3802: 0.0020799072397998416\n",
      "Norm of gradient at iteration 3803: 0.0020702262852959714\n",
      "Norm of gradient at iteration 3804: 0.0020605903903170605\n",
      "Norm of gradient at iteration 3805: 0.002050999370408839\n",
      "Norm of gradient at iteration 3806: 0.0020414529688385337\n",
      "Norm of gradient at iteration 3807: 0.002031951032193062\n",
      "Norm of gradient at iteration 3808: 0.0020224932736714633\n",
      "Norm of gradient at iteration 3809: 0.002013079555963713\n",
      "Norm of gradient at iteration 3810: 0.0020037096602336176\n",
      "Norm of gradient at iteration 3811: 0.0019943833756024903\n",
      "Norm of gradient at iteration 3812: 0.0019851004942505676\n",
      "Norm of gradient at iteration 3813: 0.001975860822765225\n",
      "Norm of gradient at iteration 3814: 0.001966664168008419\n",
      "Norm of gradient at iteration 3815: 0.0019575103101972737\n",
      "Norm of gradient at iteration 3816: 0.0019483990667971804\n",
      "Norm of gradient at iteration 3817: 0.0019393302270942308\n",
      "Norm of gradient at iteration 3818: 0.0019303035682164248\n",
      "Norm of gradient at iteration 3819: 0.0019213189672127643\n",
      "Norm of gradient at iteration 3820: 0.001912376168507236\n",
      "Norm of gradient at iteration 3821: 0.0019034749763711437\n",
      "Norm of gradient at iteration 3822: 0.0018946152252047935\n",
      "Norm of gradient at iteration 3823: 0.0018857967287437037\n",
      "Norm of gradient at iteration 3824: 0.0018770192568899422\n",
      "Norm of gradient at iteration 3825: 0.0018682826673968756\n",
      "Norm of gradient at iteration 3826: 0.001859586697820622\n",
      "Norm of gradient at iteration 3827: 0.0018509312717987756\n",
      "Norm of gradient at iteration 3828: 0.00184231609065457\n",
      "Norm of gradient at iteration 3829: 0.0018337410015374345\n",
      "Norm of gradient at iteration 3830: 0.0018252058444741374\n",
      "Norm of gradient at iteration 3831: 0.0018167104037929889\n",
      "Norm of gradient at iteration 3832: 0.001808254517136667\n",
      "Norm of gradient at iteration 3833: 0.00179983799072254\n",
      "Norm of gradient at iteration 3834: 0.0017914606213301442\n",
      "Norm of gradient at iteration 3835: 0.001783122255709267\n",
      "Norm of gradient at iteration 3836: 0.0017748227008674892\n",
      "Norm of gradient at iteration 3837: 0.0017665617806507147\n",
      "Norm of gradient at iteration 3838: 0.0017583392869880063\n",
      "Norm of gradient at iteration 3839: 0.0017501550951722167\n",
      "Norm of gradient at iteration 3840: 0.0017420089808179169\n",
      "Norm of gradient at iteration 3841: 0.0017339007822261337\n",
      "Norm of gradient at iteration 3842: 0.0017258303141527\n",
      "Norm of gradient at iteration 3843: 0.0017177974063123755\n",
      "Norm of gradient at iteration 3844: 0.001709801931534556\n",
      "Norm of gradient at iteration 3845: 0.0017018436478486634\n",
      "Norm of gradient at iteration 3846: 0.0016939223962192105\n",
      "Norm of gradient at iteration 3847: 0.001686038022752007\n",
      "Norm of gradient at iteration 3848: 0.0016781903493761647\n",
      "Norm of gradient at iteration 3849: 0.0016703792061870024\n",
      "Norm of gradient at iteration 3850: 0.0016626044141721432\n",
      "Norm of gradient at iteration 3851: 0.0016548658274253365\n",
      "Norm of gradient at iteration 3852: 0.0016471632348151258\n",
      "Norm of gradient at iteration 3853: 0.00163949649033493\n",
      "Norm of gradient at iteration 3854: 0.0016318654410954416\n",
      "Norm of gradient at iteration 3855: 0.0016242699233718057\n",
      "Norm of gradient at iteration 3856: 0.0016167097402145\n",
      "Norm of gradient at iteration 3857: 0.0016091847667137255\n",
      "Norm of gradient at iteration 3858: 0.0016016948046350605\n",
      "Norm of gradient at iteration 3859: 0.0015942397037473127\n",
      "Norm of gradient at iteration 3860: 0.0015868192916553613\n",
      "Norm of gradient at iteration 3861: 0.0015794334387225827\n",
      "Norm of gradient at iteration 3862: 0.001572081953409042\n",
      "Norm of gradient at iteration 3863: 0.0015647646673620703\n",
      "Norm of gradient at iteration 3864: 0.0015574814574477478\n",
      "Norm of gradient at iteration 3865: 0.0015502321616119195\n",
      "Norm of gradient at iteration 3866: 0.001543016582798508\n",
      "Norm of gradient at iteration 3867: 0.0015358346098726162\n",
      "Norm of gradient at iteration 3868: 0.0015286860525208564\n",
      "Norm of gradient at iteration 3869: 0.0015215707813467552\n",
      "Norm of gradient at iteration 3870: 0.0015144886002834085\n",
      "Norm of gradient at iteration 3871: 0.00150743942501552\n",
      "Norm of gradient at iteration 3872: 0.0015004230142170007\n",
      "Norm of gradient at iteration 3873: 0.0014934393094871896\n",
      "Norm of gradient at iteration 3874: 0.001486488086579122\n",
      "Norm of gradient at iteration 3875: 0.0014795692083128327\n",
      "Norm of gradient at iteration 3876: 0.0014726825459332345\n",
      "Norm of gradient at iteration 3877: 0.001465827930083113\n",
      "Norm of gradient at iteration 3878: 0.0014590052202426021\n",
      "Norm of gradient at iteration 3879: 0.0014522142505074603\n",
      "Norm of gradient at iteration 3880: 0.0014454549148570854\n",
      "Norm of gradient at iteration 3881: 0.0014387270505353137\n",
      "Norm of gradient at iteration 3882: 0.0014320304693060202\n",
      "Norm of gradient at iteration 3883: 0.0014253650506436464\n",
      "Norm of gradient at iteration 3884: 0.0014187307129317603\n",
      "Norm of gradient at iteration 3885: 0.0014121272115209117\n",
      "Norm of gradient at iteration 3886: 0.0014055544456559245\n",
      "Norm of gradient at iteration 3887: 0.0013990122927991441\n",
      "Norm of gradient at iteration 3888: 0.001392500576867378\n",
      "Norm of gradient at iteration 3889: 0.0013860191657165835\n",
      "Norm of gradient at iteration 3890: 0.001379567910007604\n",
      "Norm of gradient at iteration 3891: 0.0013731466900436609\n",
      "Norm of gradient at iteration 3892: 0.001366755376503742\n",
      "Norm of gradient at iteration 3893: 0.0013603938056884722\n",
      "Norm of gradient at iteration 3894: 0.0013540618425577561\n",
      "Norm of gradient at iteration 3895: 0.0013477593580547664\n",
      "Norm of gradient at iteration 3896: 0.0013414861899471663\n",
      "Norm of gradient at iteration 3897: 0.0013352422610063296\n",
      "Norm of gradient at iteration 3898: 0.0013290273423691725\n",
      "Norm of gradient at iteration 3899: 0.0013228413688235665\n",
      "Norm of gradient at iteration 3900: 0.001316684190790857\n",
      "Norm of gradient at iteration 3901: 0.0013105556762319432\n",
      "Norm of gradient at iteration 3902: 0.0013044556611350364\n",
      "Norm of gradient at iteration 3903: 0.001298384074168915\n",
      "Norm of gradient at iteration 3904: 0.0012923407427605285\n",
      "Norm of gradient at iteration 3905: 0.001286325544036397\n",
      "Norm of gradient at iteration 3906: 0.0012803383202312332\n",
      "Norm of gradient at iteration 3907: 0.0012743789688565664\n",
      "Norm of gradient at iteration 3908: 0.0012684473587120455\n",
      "Norm of gradient at iteration 3909: 0.0012625433329627844\n",
      "Norm of gradient at iteration 3910: 0.0012566668268435596\n",
      "Norm of gradient at iteration 3911: 0.0012508176901120085\n",
      "Norm of gradient at iteration 3912: 0.0012449957296019952\n",
      "Norm of gradient at iteration 3913: 0.0012392008864960497\n",
      "Norm of gradient at iteration 3914: 0.0012334330025471768\n",
      "Norm of gradient at iteration 3915: 0.001227691983480889\n",
      "Norm of gradient at iteration 3916: 0.0012219776819004616\n",
      "Norm of gradient at iteration 3917: 0.0012162899906359396\n",
      "Norm of gradient at iteration 3918: 0.0012106287591303524\n",
      "Norm of gradient at iteration 3919: 0.0012049938834298242\n",
      "Norm of gradient at iteration 3920: 0.0011993852243728524\n",
      "Norm of gradient at iteration 3921: 0.0011938026847308333\n",
      "Norm of gradient at iteration 3922: 0.001188246100406396\n",
      "Norm of gradient at iteration 3923: 0.0011827153811563079\n",
      "Norm of gradient at iteration 3924: 0.0011772104117894731\n",
      "Norm of gradient at iteration 3925: 0.0011717310879679988\n",
      "Norm of gradient at iteration 3926: 0.0011662772741103168\n",
      "Norm of gradient at iteration 3927: 0.001160848825985901\n",
      "Norm of gradient at iteration 3928: 0.0011554456571240043\n",
      "Norm of gradient at iteration 3929: 0.001150067593933056\n",
      "Norm of gradient at iteration 3930: 0.0011447146043758911\n",
      "Norm of gradient at iteration 3931: 0.0011393864988322592\n",
      "Norm of gradient at iteration 3932: 0.0011340832330803852\n",
      "Norm of gradient at iteration 3933: 0.0011288046274647253\n",
      "Norm of gradient at iteration 3934: 0.001123550579892285\n",
      "Norm of gradient at iteration 3935: 0.0011183210144490444\n",
      "Norm of gradient at iteration 3936: 0.00111311578729258\n",
      "Norm of gradient at iteration 3937: 0.0011079347806097375\n",
      "Norm of gradient at iteration 3938: 0.0011027778789877883\n",
      "Norm of gradient at iteration 3939: 0.0010976449914185992\n",
      "Norm of gradient at iteration 3940: 0.001092536014839888\n",
      "Norm of gradient at iteration 3941: 0.001087450790555926\n",
      "Norm of gradient at iteration 3942: 0.001082389229869337\n",
      "Norm of gradient at iteration 3943: 0.0010773512480840772\n",
      "Norm of gradient at iteration 3944: 0.0010723366974653235\n",
      "Norm of gradient at iteration 3945: 0.0010673455203754983\n",
      "Norm of gradient at iteration 3946: 0.001062377538741226\n",
      "Norm of gradient at iteration 3947: 0.0010574327058883136\n",
      "Norm of gradient at iteration 3948: 0.0010525108758189163\n",
      "Norm of gradient at iteration 3949: 0.0010476119348556945\n",
      "Norm of gradient at iteration 3950: 0.001042735813864903\n",
      "Norm of gradient at iteration 3951: 0.0010378823928217488\n",
      "Norm of gradient at iteration 3952: 0.0010330515780033462\n",
      "Norm of gradient at iteration 3953: 0.0010282432089830373\n",
      "Norm of gradient at iteration 3954: 0.001023457251877055\n",
      "Norm of gradient at iteration 3955: 0.0010186935570737385\n",
      "Norm of gradient at iteration 3956: 0.0010139520295550934\n",
      "Norm of gradient at iteration 3957: 0.001009232588160684\n",
      "Norm of gradient at iteration 3958: 0.001004535105219848\n",
      "Norm of gradient at iteration 3959: 0.000999859464672055\n",
      "Norm of gradient at iteration 3960: 0.0009952056349159426\n",
      "Norm of gradient at iteration 3961: 0.0009905734313087119\n",
      "Norm of gradient at iteration 3962: 0.000985962795417772\n",
      "Norm of gradient at iteration 3963: 0.000981373616648872\n",
      "Norm of gradient at iteration 3964: 0.0009768058142969435\n",
      "Norm of gradient at iteration 3965: 0.000972259265322121\n",
      "Norm of gradient at iteration 3966: 0.000967733882498358\n",
      "Norm of gradient at iteration 3967: 0.0009632295480018941\n",
      "Norm of gradient at iteration 3968: 0.0009587461724609645\n",
      "Norm of gradient at iteration 3969: 0.0009542836872658519\n",
      "Norm of gradient at iteration 3970: 0.0009498419646351382\n",
      "Norm of gradient at iteration 3971: 0.0009454209164447569\n",
      "Norm of gradient at iteration 3972: 0.0009410204499950161\n",
      "Norm of gradient at iteration 3973: 0.0009366404745963495\n",
      "Norm of gradient at iteration 3974: 0.0009322808777286443\n",
      "Norm of gradient at iteration 3975: 0.0009279415625459405\n",
      "Norm of gradient at iteration 3976: 0.0009236224306558179\n",
      "Norm of gradient at iteration 3977: 0.0009193234468163895\n",
      "Norm of gradient at iteration 3978: 0.0009150444440031372\n",
      "Norm of gradient at iteration 3979: 0.0009107853677387003\n",
      "Norm of gradient at iteration 3980: 0.0009065460861562485\n",
      "Norm of gradient at iteration 3981: 0.0009023265727994385\n",
      "Norm of gradient at iteration 3982: 0.0008981266927092853\n",
      "Norm of gradient at iteration 3983: 0.0008939463517414343\n",
      "Norm of gradient at iteration 3984: 0.0008897854801679711\n",
      "Norm of gradient at iteration 3985: 0.0008856439527822898\n",
      "Norm of gradient at iteration 3986: 0.0008815217276607859\n",
      "Norm of gradient at iteration 3987: 0.00087741865711115\n",
      "Norm of gradient at iteration 3988: 0.0008733347247311775\n",
      "Norm of gradient at iteration 3989: 0.000869269760935451\n",
      "Norm of gradient at iteration 3990: 0.0008652237402760444\n",
      "Norm of gradient at iteration 3991: 0.0008611965508464014\n",
      "Norm of gradient at iteration 3992: 0.0008571881189016195\n",
      "Norm of gradient at iteration 3993: 0.0008531983483950808\n",
      "Norm of gradient at iteration 3994: 0.0008492270972547079\n",
      "Norm of gradient at iteration 3995: 0.0008452743953476041\n",
      "Norm of gradient at iteration 3996: 0.0008413400314628923\n",
      "Norm of gradient at iteration 3997: 0.0008374240291473814\n",
      "Norm of gradient at iteration 3998: 0.0008335262286455001\n",
      "Norm of gradient at iteration 3999: 0.0008296465579419048\n",
      "Norm of gradient at iteration 4000: 0.0008257849808871673\n",
      "Norm of gradient at iteration 4001: 0.0008219413505872065\n",
      "Norm of gradient at iteration 4002: 0.0008181156204734086\n",
      "Norm of gradient at iteration 4003: 0.0008143076903652995\n",
      "Norm of gradient at iteration 4004: 0.0008105174896666998\n",
      "Norm of gradient at iteration 4005: 0.0008067449395298246\n",
      "Norm of gradient at iteration 4006: 0.0008029899170106097\n",
      "Norm of gradient at iteration 4007: 0.0007992524043692981\n",
      "Norm of gradient at iteration 4008: 0.0007955322786582696\n",
      "Norm of gradient at iteration 4009: 0.0007918294649519246\n",
      "Norm of gradient at iteration 4010: 0.0007881439180710752\n",
      "Norm of gradient at iteration 4011: 0.0007844754660563415\n",
      "Norm of gradient at iteration 4012: 0.0007808241251745842\n",
      "Norm of gradient at iteration 4013: 0.0007771897678255535\n",
      "Norm of gradient at iteration 4014: 0.0007735723386504035\n",
      "Norm of gradient at iteration 4015: 0.0007699717406581783\n",
      "Norm of gradient at iteration 4016: 0.0007663879062349508\n",
      "Norm of gradient at iteration 4017: 0.0007628207402866594\n",
      "Norm of gradient at iteration 4018: 0.0007592701757814518\n",
      "Norm of gradient at iteration 4019: 0.0007557361400266599\n",
      "Norm of gradient at iteration 4020: 0.0007522185526266721\n",
      "Norm of gradient at iteration 4021: 0.0007487173433577284\n",
      "Norm of gradient at iteration 4022: 0.0007452324347323087\n",
      "Norm of gradient at iteration 4023: 0.0007417637203232716\n",
      "Norm of gradient at iteration 4024: 0.0007383111888215892\n",
      "Norm of gradient at iteration 4025: 0.0007348747181690304\n",
      "Norm of gradient at iteration 4026: 0.0007314542157480535\n",
      "Norm of gradient at iteration 4027: 0.0007280496800269827\n",
      "Norm of gradient at iteration 4028: 0.0007246609482205766\n",
      "Norm of gradient at iteration 4029: 0.0007212880230884752\n",
      "Norm of gradient at iteration 4030: 0.0007179307845101174\n",
      "Norm of gradient at iteration 4031: 0.0007145891677230899\n",
      "Norm of gradient at iteration 4032: 0.0007112630907013781\n",
      "Norm of gradient at iteration 4033: 0.0007079525070903645\n",
      "Norm of gradient at iteration 4034: 0.0007046573593973877\n",
      "Norm of gradient at iteration 4035: 0.0007013775365545965\n",
      "Norm of gradient at iteration 4036: 0.0006981129433185159\n",
      "Norm of gradient at iteration 4037: 0.0006948635482847995\n",
      "Norm of gradient at iteration 4038: 0.0006916293367718357\n",
      "Norm of gradient at iteration 4039: 0.0006884101271966334\n",
      "Norm of gradient at iteration 4040: 0.0006852058921057589\n",
      "Norm of gradient at iteration 4041: 0.0006820166228663454\n",
      "Norm of gradient at iteration 4042: 0.0006788421453781772\n",
      "Norm of gradient at iteration 4043: 0.0006756824764290903\n",
      "Norm of gradient at iteration 4044: 0.0006725375193495843\n",
      "Norm of gradient at iteration 4045: 0.0006694072012632356\n",
      "Norm of gradient at iteration 4046: 0.000666291429402819\n",
      "Norm of gradient at iteration 4047: 0.0006631901805665574\n",
      "Norm of gradient at iteration 4048: 0.0006601033682902599\n",
      "Norm of gradient at iteration 4049: 0.0006570308949245424\n",
      "Norm of gradient at iteration 4050: 0.0006539727356584068\n",
      "Norm of gradient at iteration 4051: 0.0006509288064289086\n",
      "Norm of gradient at iteration 4052: 0.0006478990579375842\n",
      "Norm of gradient at iteration 4053: 0.0006448834075224824\n",
      "Norm of gradient at iteration 4054: 0.0006418817595664841\n",
      "Norm of gradient at iteration 4055: 0.0006388941280615014\n",
      "Norm of gradient at iteration 4056: 0.0006359203997886923\n",
      "Norm of gradient at iteration 4057: 0.0006329605167895992\n",
      "Norm of gradient at iteration 4058: 0.0006300143609525879\n",
      "Norm of gradient at iteration 4059: 0.0006270819672416955\n",
      "Norm of gradient at iteration 4060: 0.0006241632048423432\n",
      "Norm of gradient at iteration 4061: 0.0006212580472340848\n",
      "Norm of gradient at iteration 4062: 0.0006183663803709533\n",
      "Norm of gradient at iteration 4063: 0.0006154881886559387\n",
      "Norm of gradient at iteration 4064: 0.0006126233903485347\n",
      "Norm of gradient at iteration 4065: 0.0006097719468735798\n",
      "Norm of gradient at iteration 4066: 0.0006069337366971806\n",
      "Norm of gradient at iteration 4067: 0.0006041087599698903\n",
      "Norm of gradient at iteration 4068: 0.0006012969328325409\n",
      "Norm of gradient at iteration 4069: 0.0005984981883641572\n",
      "Norm of gradient at iteration 4070: 0.0005957124629162052\n",
      "Norm of gradient at iteration 4071: 0.0005929397210309278\n",
      "Norm of gradient at iteration 4072: 0.0005901798677143223\n",
      "Norm of gradient at iteration 4073: 0.0005874328932134685\n",
      "Norm of gradient at iteration 4074: 0.0005846986818650093\n",
      "Norm of gradient at iteration 4075: 0.000581977201592784\n",
      "Norm of gradient at iteration 4076: 0.0005792683765481367\n",
      "Norm of gradient at iteration 4077: 0.0005765721737272649\n",
      "Norm of gradient at iteration 4078: 0.0005738885311841929\n",
      "Norm of gradient at iteration 4079: 0.0005712173627711303\n",
      "Norm of gradient at iteration 4080: 0.0005685586260385215\n",
      "Norm of gradient at iteration 4081: 0.0005659122724695334\n",
      "Norm of gradient at iteration 4082: 0.0005632782462644564\n",
      "Norm of gradient at iteration 4083: 0.0005606564473033397\n",
      "Norm of gradient at iteration 4084: 0.0005580468665014022\n",
      "Norm of gradient at iteration 4085: 0.0005554494212820721\n",
      "Norm of gradient at iteration 4086: 0.0005528640782565861\n",
      "Norm of gradient at iteration 4087: 0.000550290765814239\n",
      "Norm of gradient at iteration 4088: 0.0005477294182007791\n",
      "Norm of gradient at iteration 4089: 0.0005451800216824642\n",
      "Norm of gradient at iteration 4090: 0.0005426424942052288\n",
      "Norm of gradient at iteration 4091: 0.0005401167531639333\n",
      "Norm of gradient at iteration 4092: 0.0005376027894027773\n",
      "Norm of gradient at iteration 4093: 0.0005351004795747462\n",
      "Norm of gradient at iteration 4094: 0.000532609856939682\n",
      "Norm of gradient at iteration 4095: 0.0005301308144933773\n",
      "Norm of gradient at iteration 4096: 0.0005276633453208024\n",
      "Norm of gradient at iteration 4097: 0.0005252073322194742\n",
      "Norm of gradient at iteration 4098: 0.0005227627569107947\n",
      "Norm of gradient at iteration 4099: 0.0005203295289601786\n",
      "Norm of gradient at iteration 4100: 0.0005179076514149153\n",
      "Norm of gradient at iteration 4101: 0.0005154970393386176\n",
      "Norm of gradient at iteration 4102: 0.0005130976558214011\n",
      "Norm of gradient at iteration 4103: 0.0005107094607942117\n",
      "Norm of gradient at iteration 4104: 0.0005083323772683045\n",
      "Norm of gradient at iteration 4105: 0.0005059663186595861\n",
      "Norm of gradient at iteration 4106: 0.0005036112908282536\n",
      "Norm of gradient at iteration 4107: 0.0005012672206245276\n",
      "Norm of gradient at iteration 4108: 0.0004989340808712891\n",
      "Norm of gradient at iteration 4109: 0.0004966117843426617\n",
      "Norm of gradient at iteration 4110: 0.0004943003031239339\n",
      "Norm of gradient at iteration 4111: 0.0004919995545529395\n",
      "Norm of gradient at iteration 4112: 0.0004897095489859126\n",
      "Norm of gradient at iteration 4113: 0.00048743020374539465\n",
      "Norm of gradient at iteration 4114: 0.000485161447133926\n",
      "Norm of gradient at iteration 4115: 0.00048290326505451883\n",
      "Norm of gradient at iteration 4116: 0.00048065558611466914\n",
      "Norm of gradient at iteration 4117: 0.00047841838290744434\n",
      "Norm of gradient at iteration 4118: 0.00047619158235702425\n",
      "Norm of gradient at iteration 4119: 0.0004739751216951367\n",
      "Norm of gradient at iteration 4120: 0.00047176901618344296\n",
      "Norm of gradient at iteration 4121: 0.00046957316780147127\n",
      "Norm of gradient at iteration 4122: 0.0004673875383941545\n",
      "Norm of gradient at iteration 4123: 0.0004652120695949929\n",
      "Norm of gradient at iteration 4124: 0.0004630467389970561\n",
      "Norm of gradient at iteration 4125: 0.00046089146219641716\n",
      "Norm of gradient at iteration 4126: 0.00045874625444697727\n",
      "Norm of gradient at iteration 4127: 0.00045661100986224004\n",
      "Norm of gradient at iteration 4128: 0.0004544857128281801\n",
      "Norm of gradient at iteration 4129: 0.0004523703009556971\n",
      "Norm of gradient at iteration 4130: 0.00045026473340830964\n",
      "Norm of gradient at iteration 4131: 0.00044816897110625637\n",
      "Norm of gradient at iteration 4132: 0.0004460829646754685\n",
      "Norm of gradient at iteration 4133: 0.00044400666894700585\n",
      "Norm of gradient at iteration 4134: 0.00044194001543044326\n",
      "Norm of gradient at iteration 4135: 0.0004398830125289444\n",
      "Norm of gradient at iteration 4136: 0.00043783558055115047\n",
      "Norm of gradient at iteration 4137: 0.0004357976685371809\n",
      "Norm of gradient at iteration 4138: 0.00043376925724862233\n",
      "Norm of gradient at iteration 4139: 0.0004317502431748547\n",
      "Norm of gradient at iteration 4140: 0.0004297406689145419\n",
      "Norm of gradient at iteration 4141: 0.0004277404497051607\n",
      "Norm of gradient at iteration 4142: 0.0004257495163818308\n",
      "Norm of gradient at iteration 4143: 0.0004237678431036036\n",
      "Norm of gradient at iteration 4144: 0.0004217954227602423\n",
      "Norm of gradient at iteration 4145: 0.0004198321710344698\n",
      "Norm of gradient at iteration 4146: 0.0004178780520281729\n",
      "Norm of gradient at iteration 4147: 0.0004159330272480121\n",
      "Norm of gradient at iteration 4148: 0.0004139970662705241\n",
      "Norm of gradient at iteration 4149: 0.0004120701063217638\n",
      "Norm of gradient at iteration 4150: 0.0004101521469551172\n",
      "Norm of gradient at iteration 4151: 0.00040824308409833894\n",
      "Norm of gradient at iteration 4152: 0.0004063429201596561\n",
      "Norm of gradient at iteration 4153: 0.00040445159817216366\n",
      "Norm of gradient at iteration 4154: 0.00040256908980388544\n",
      "Norm of gradient at iteration 4155: 0.0004006953251460023\n",
      "Norm of gradient at iteration 4156: 0.00039883026208143536\n",
      "Norm of gradient at iteration 4157: 0.0003969739097995504\n",
      "Norm of gradient at iteration 4158: 0.0003951261933589697\n",
      "Norm of gradient at iteration 4159: 0.0003932870813551832\n",
      "Norm of gradient at iteration 4160: 0.00039145651158095386\n",
      "Norm of gradient at iteration 4161: 0.0003896344717757271\n",
      "Norm of gradient at iteration 4162: 0.0003878209395493828\n",
      "Norm of gradient at iteration 4163: 0.0003860158069121512\n",
      "Norm of gradient at iteration 4164: 0.00038421909577356534\n",
      "Norm of gradient at iteration 4165: 0.00038243076689051123\n",
      "Norm of gradient at iteration 4166: 0.0003806507258971159\n",
      "Norm of gradient at iteration 4167: 0.0003788789904758864\n",
      "Norm of gradient at iteration 4168: 0.0003771154749993857\n",
      "Norm of gradient at iteration 4169: 0.0003753601911436378\n",
      "Norm of gradient at iteration 4170: 0.0003736130831864272\n",
      "Norm of gradient at iteration 4171: 0.0003718740932357249\n",
      "Norm of gradient at iteration 4172: 0.0003701431955654761\n",
      "Norm of gradient at iteration 4173: 0.00036842036349682986\n",
      "Norm of gradient at iteration 4174: 0.0003667055421518091\n",
      "Norm of gradient at iteration 4175: 0.0003649987107384682\n",
      "Norm of gradient at iteration 4176: 0.000363299810775731\n",
      "Norm of gradient at iteration 4177: 0.0003616088387310943\n",
      "Norm of gradient at iteration 4178: 0.0003599257284386912\n",
      "Norm of gradient at iteration 4179: 0.0003582504509754388\n",
      "Norm of gradient at iteration 4180: 0.00035658298517099826\n",
      "Norm of gradient at iteration 4181: 0.0003549232547191238\n",
      "Norm of gradient at iteration 4182: 0.0003532712567950323\n",
      "Norm of gradient at iteration 4183: 0.0003516269506615441\n",
      "Norm of gradient at iteration 4184: 0.00034999030602481736\n",
      "Norm of gradient at iteration 4185: 0.0003483612519030583\n",
      "Norm of gradient at iteration 4186: 0.00034673980955089105\n",
      "Norm of gradient at iteration 4187: 0.00034512591847057786\n",
      "Norm of gradient at iteration 4188: 0.0003435195172051189\n",
      "Norm of gradient at iteration 4189: 0.0003419205836852812\n",
      "Norm of gradient at iteration 4190: 0.00034032912823682806\n",
      "Norm of gradient at iteration 4191: 0.0003387450498471817\n",
      "Norm of gradient at iteration 4192: 0.00033716836749890256\n",
      "Norm of gradient at iteration 4193: 0.0003355990134748216\n",
      "Norm of gradient at iteration 4194: 0.00033403694175595963\n",
      "Norm of gradient at iteration 4195: 0.00033248215799391953\n",
      "Norm of gradient at iteration 4196: 0.0003309346132691816\n",
      "Norm of gradient at iteration 4197: 0.0003293943009071058\n",
      "Norm of gradient at iteration 4198: 0.00032786113334623855\n",
      "Norm of gradient at iteration 4199: 0.0003263351024137737\n",
      "Norm of gradient at iteration 4200: 0.00032481616115174626\n",
      "Norm of gradient at iteration 4201: 0.00032330428652468284\n",
      "Norm of gradient at iteration 4202: 0.0003217994619417105\n",
      "Norm of gradient at iteration 4203: 0.0003203016555498766\n",
      "Norm of gradient at iteration 4204: 0.0003188108112416513\n",
      "Norm of gradient at iteration 4205: 0.00031732690314767697\n",
      "Norm of gradient at iteration 4206: 0.0003158498882046947\n",
      "Norm of gradient at iteration 4207: 0.0003143797810651574\n",
      "Norm of gradient at iteration 4208: 0.00031291646935392627\n",
      "Norm of gradient at iteration 4209: 0.0003114600098496124\n",
      "Norm of gradient at iteration 4210: 0.0003100103231398515\n",
      "Norm of gradient at iteration 4211: 0.00030856740499578077\n",
      "Norm of gradient at iteration 4212: 0.0003071311431286151\n",
      "Norm of gradient at iteration 4213: 0.00030570161330347237\n",
      "Norm of gradient at iteration 4214: 0.0003042787136412798\n",
      "Norm of gradient at iteration 4215: 0.0003028624509186881\n",
      "Norm of gradient at iteration 4216: 0.0003014527633434548\n",
      "Norm of gradient at iteration 4217: 0.00030004964119110996\n",
      "Norm of gradient at iteration 4218: 0.00029865306698491915\n",
      "Norm of gradient at iteration 4219: 0.0002972629813280983\n",
      "Norm of gradient at iteration 4220: 0.00029587936382752483\n",
      "Norm of gradient at iteration 4221: 0.0002945021890189527\n",
      "Norm of gradient at iteration 4222: 0.0002931314071439205\n",
      "Norm of gradient at iteration 4223: 0.0002917670387231946\n",
      "Norm of gradient at iteration 4224: 0.0002904089903879758\n",
      "Norm of gradient at iteration 4225: 0.000289057261861757\n",
      "Norm of gradient at iteration 4226: 0.0002877118562941803\n",
      "Norm of gradient at iteration 4227: 0.000286372698342369\n",
      "Norm of gradient at iteration 4228: 0.0002850397636252145\n",
      "Norm of gradient at iteration 4229: 0.0002837130389652956\n",
      "Norm of gradient at iteration 4230: 0.00028239248901255036\n",
      "Norm of gradient at iteration 4231: 0.0002810780864121197\n",
      "Norm of gradient at iteration 4232: 0.0002797697889080986\n",
      "Norm of gradient at iteration 4233: 0.00027846760817090216\n",
      "Norm of gradient at iteration 4234: 0.0002771714698534376\n",
      "Norm of gradient at iteration 4235: 0.0002758813735432961\n",
      "Norm of gradient at iteration 4236: 0.00027459729452174387\n",
      "Norm of gradient at iteration 4237: 0.0002733191667295871\n",
      "Norm of gradient at iteration 4238: 0.00027204702288164404\n",
      "Norm of gradient at iteration 4239: 0.00027078076519323064\n",
      "Norm of gradient at iteration 4240: 0.00026952041966575097\n",
      "Norm of gradient at iteration 4241: 0.000268265920479238\n",
      "Norm of gradient at iteration 4242: 0.0002670172937158102\n",
      "Norm of gradient at iteration 4243: 0.00026577445849104063\n",
      "Norm of gradient at iteration 4244: 0.0002645373999108686\n",
      "Norm of gradient at iteration 4245: 0.00026330610992388097\n",
      "Norm of gradient at iteration 4246: 0.0002620805489222682\n",
      "Norm of gradient at iteration 4247: 0.0002608606993942532\n",
      "Norm of gradient at iteration 4248: 0.00025964650239689426\n",
      "Norm of gradient at iteration 4249: 0.0002584379977414665\n",
      "Norm of gradient at iteration 4250: 0.00025723508376050653\n",
      "Norm of gradient at iteration 4251: 0.0002560377644952628\n",
      "Norm of gradient at iteration 4252: 0.0002548460493303317\n",
      "Norm of gradient at iteration 4253: 0.0002536598714081354\n",
      "Norm of gradient at iteration 4254: 0.00025247919252349493\n",
      "Norm of gradient at iteration 4255: 0.0002513040495062992\n",
      "Norm of gradient at iteration 4256: 0.0002501343613116094\n",
      "Norm of gradient at iteration 4257: 0.00024897012871781657\n",
      "Norm of gradient at iteration 4258: 0.00024781127046959194\n",
      "Norm of gradient at iteration 4259: 0.0002466578410964696\n",
      "Norm of gradient at iteration 4260: 0.0002455097876649761\n",
      "Norm of gradient at iteration 4261: 0.00024436703370962336\n",
      "Norm of gradient at iteration 4262: 0.00024322963257582972\n",
      "Norm of gradient at iteration 4263: 0.00024209753368766362\n",
      "Norm of gradient at iteration 4264: 0.00024097069518080595\n",
      "Norm of gradient at iteration 4265: 0.00023984908439520365\n",
      "Norm of gradient at iteration 4266: 0.00023873272113651359\n",
      "Norm of gradient at iteration 4267: 0.0002376215262464636\n",
      "Norm of gradient at iteration 4268: 0.00023651551985220867\n",
      "Norm of gradient at iteration 4269: 0.0002354146455958834\n",
      "Norm of gradient at iteration 4270: 0.00023431890556115302\n",
      "Norm of gradient at iteration 4271: 0.0002332282733510704\n",
      "Norm of gradient at iteration 4272: 0.00023214269160374355\n",
      "Norm of gradient at iteration 4273: 0.00023106218946884936\n",
      "Norm of gradient at iteration 4274: 0.0002299867173615198\n",
      "Norm of gradient at iteration 4275: 0.0002289162162397657\n",
      "Norm of gradient at iteration 4276: 0.00022785072820384546\n",
      "Norm of gradient at iteration 4277: 0.00022679019489678918\n",
      "Norm of gradient at iteration 4278: 0.00022573462439620426\n",
      "Norm of gradient at iteration 4279: 0.00022468390646140788\n",
      "Norm of gradient at iteration 4280: 0.00022363813579966434\n",
      "Norm of gradient at iteration 4281: 0.00022259720356994188\n",
      "Norm of gradient at iteration 4282: 0.00022156111925071345\n",
      "Norm of gradient at iteration 4283: 0.00022052985467263073\n",
      "Norm of gradient at iteration 4284: 0.0002195034020945873\n",
      "Norm of gradient at iteration 4285: 0.0002184817252437023\n",
      "Norm of gradient at iteration 4286: 0.0002174648082296361\n",
      "Norm of gradient at iteration 4287: 0.00021645258672550638\n",
      "Norm of gradient at iteration 4288: 0.00021544512344901976\n",
      "Norm of gradient at iteration 4289: 0.0002144423166159833\n",
      "Norm of gradient at iteration 4290: 0.00021344417642072013\n",
      "Norm of gradient at iteration 4291: 0.0002124506995863297\n",
      "Norm of gradient at iteration 4292: 0.00021146183856559655\n",
      "Norm of gradient at iteration 4293: 0.00021047759948777906\n",
      "Norm of gradient at iteration 4294: 0.00020949792677648423\n",
      "Norm of gradient at iteration 4295: 0.00020852280413729302\n",
      "Norm of gradient at iteration 4296: 0.00020755221788116917\n",
      "Norm of gradient at iteration 4297: 0.00020658618563925782\n",
      "Norm of gradient at iteration 4298: 0.00020562462956279074\n",
      "Norm of gradient at iteration 4299: 0.00020466753107329237\n",
      "Norm of gradient at iteration 4300: 0.00020371491281977733\n",
      "Norm of gradient at iteration 4301: 0.0002027667281714348\n",
      "Norm of gradient at iteration 4302: 0.00020182293724534304\n",
      "Norm of gradient at iteration 4303: 0.00020088355223732307\n",
      "Norm of gradient at iteration 4304: 0.0001999485401859232\n",
      "Norm of gradient at iteration 4305: 0.00019901787777193636\n",
      "Norm of gradient at iteration 4306: 0.00019809154888408197\n",
      "Norm of gradient at iteration 4307: 0.00019716953813028656\n",
      "Norm of gradient at iteration 4308: 0.00019625180597865864\n",
      "Norm of gradient at iteration 4309: 0.00019533836627844692\n",
      "Norm of gradient at iteration 4310: 0.0001944291541501063\n",
      "Norm of gradient at iteration 4311: 0.00019352416830103976\n",
      "Norm of gradient at iteration 4312: 0.00019262342112026589\n",
      "Norm of gradient at iteration 4313: 0.00019172685452745054\n",
      "Norm of gradient at iteration 4314: 0.0001908344634823737\n",
      "Norm of gradient at iteration 4315: 0.00018994622495564916\n",
      "Norm of gradient at iteration 4316: 0.00018906212510823393\n",
      "Norm of gradient at iteration 4317: 0.0001881821221424419\n",
      "Norm of gradient at iteration 4318: 0.0001873062287472321\n",
      "Norm of gradient at iteration 4319: 0.00018643441197421922\n",
      "Norm of gradient at iteration 4320: 0.00018556663822972628\n",
      "Norm of gradient at iteration 4321: 0.00018470294433427052\n",
      "Norm of gradient at iteration 4322: 0.0001838432311373641\n",
      "Norm of gradient at iteration 4323: 0.00018298752929050803\n",
      "Norm of gradient at iteration 4324: 0.0001821358091891725\n",
      "Norm of gradient at iteration 4325: 0.000181288032900423\n",
      "Norm of gradient at iteration 4326: 0.00018044423598653525\n",
      "Norm of gradient at iteration 4327: 0.0001796043637794173\n",
      "Norm of gradient at iteration 4328: 0.00017876838377391187\n",
      "Norm of gradient at iteration 4329: 0.00017793633456341643\n",
      "Norm of gradient at iteration 4330: 0.00017710810335409857\n",
      "Norm of gradient at iteration 4331: 0.0001762837522324296\n",
      "Norm of gradient at iteration 4332: 0.00017546323563686863\n",
      "Norm of gradient at iteration 4333: 0.00017464655003791233\n",
      "Norm of gradient at iteration 4334: 0.00017383366709909659\n",
      "Norm of gradient at iteration 4335: 0.00017302455354822728\n",
      "Norm of gradient at iteration 4336: 0.0001722191874467741\n",
      "Norm of gradient at iteration 4337: 0.00017141759128728749\n",
      "Norm of gradient at iteration 4338: 0.00017061974069936767\n",
      "Norm of gradient at iteration 4339: 0.0001698255949495944\n",
      "Norm of gradient at iteration 4340: 0.00016903512661644766\n",
      "Norm of gradient at iteration 4341: 0.00016824835393127607\n",
      "Norm of gradient at iteration 4342: 0.00016746523711857016\n",
      "Norm of gradient at iteration 4343: 0.00016668576130820796\n",
      "Norm of gradient at iteration 4344: 0.00016590992126279278\n",
      "Norm of gradient at iteration 4345: 0.0001651377054494532\n",
      "Norm of gradient at iteration 4346: 0.00016436905816286858\n",
      "Norm of gradient at iteration 4347: 0.00016360399252836547\n",
      "Norm of gradient at iteration 4348: 0.00016284251619261105\n",
      "Norm of gradient at iteration 4349: 0.0001620845555651032\n",
      "Norm of gradient at iteration 4350: 0.00016133014658678958\n",
      "Norm of gradient at iteration 4351: 0.00016057924317135712\n",
      "Norm of gradient at iteration 4352: 0.00015983181150823041\n",
      "Norm of gradient at iteration 4353: 0.00015908785898858732\n",
      "Norm of gradient at iteration 4354: 0.00015834741351172481\n",
      "Norm of gradient at iteration 4355: 0.00015761036895946447\n",
      "Norm of gradient at iteration 4356: 0.00015687676243190176\n",
      "Norm of gradient at iteration 4357: 0.00015614658283012465\n",
      "Norm of gradient at iteration 4358: 0.00015541980229420485\n",
      "Norm of gradient at iteration 4359: 0.00015469639246821703\n",
      "Norm of gradient at iteration 4360: 0.0001539763598567815\n",
      "Norm of gradient at iteration 4361: 0.0001532596415530706\n",
      "Norm of gradient at iteration 4362: 0.0001525463327503788\n",
      "Norm of gradient at iteration 4363: 0.00015183628240300186\n",
      "Norm of gradient at iteration 4364: 0.00015112955961411209\n",
      "Norm of gradient at iteration 4365: 0.00015042612443128296\n",
      "Norm of gradient at iteration 4366: 0.00014972596433426294\n",
      "Norm of gradient at iteration 4367: 0.00014902907913911438\n",
      "Norm of gradient at iteration 4368: 0.00014833542350485636\n",
      "Norm of gradient at iteration 4369: 0.00014764501406542682\n",
      "Norm of gradient at iteration 4370: 0.00014695777629766254\n",
      "Norm of gradient at iteration 4371: 0.0001462737611567522\n",
      "Norm of gradient at iteration 4372: 0.00014559292083706854\n",
      "Norm of gradient at iteration 4373: 0.0001449152655426907\n",
      "Norm of gradient at iteration 4374: 0.0001442407568375592\n",
      "Norm of gradient at iteration 4375: 0.0001435693784325755\n",
      "Norm of gradient at iteration 4376: 0.00014290113689848175\n",
      "Norm of gradient at iteration 4377: 0.0001422359854959432\n",
      "Norm of gradient at iteration 4378: 0.0001415739444152522\n",
      "Norm of gradient at iteration 4379: 0.0001409150009900225\n",
      "Norm of gradient at iteration 4380: 0.00014025911401680883\n",
      "Norm of gradient at iteration 4381: 0.00013960628045088253\n",
      "Norm of gradient at iteration 4382: 0.00013895646936216776\n",
      "Norm of gradient at iteration 4383: 0.00013830968404202998\n",
      "Norm of gradient at iteration 4384: 0.00013766591659663364\n",
      "Norm of gradient at iteration 4385: 0.00013702516021725413\n",
      "Norm of gradient at iteration 4386: 0.0001363873908148463\n",
      "Norm of gradient at iteration 4387: 0.00013575256895626136\n",
      "Norm of gradient at iteration 4388: 0.0001351207209695613\n",
      "Norm of gradient at iteration 4389: 0.00013449179477343964\n",
      "Norm of gradient at iteration 4390: 0.00013386579878487708\n",
      "Norm of gradient at iteration 4391: 0.00013324269915926192\n",
      "Norm of gradient at iteration 4392: 0.00013262254902341377\n",
      "Norm of gradient at iteration 4393: 0.00013200526059985355\n",
      "Norm of gradient at iteration 4394: 0.00013139081216420901\n",
      "Norm of gradient at iteration 4395: 0.0001307792910844748\n",
      "Norm of gradient at iteration 4396: 0.0001301705667649147\n",
      "Norm of gradient at iteration 4397: 0.000129564676370545\n",
      "Norm of gradient at iteration 4398: 0.00012896160259168778\n",
      "Norm of gradient at iteration 4399: 0.00012836133602580005\n",
      "Norm of gradient at iteration 4400: 0.0001277639148593754\n",
      "Norm of gradient at iteration 4401: 0.00012716924631979567\n",
      "Norm of gradient at iteration 4402: 0.00012657732639210546\n",
      "Norm of gradient at iteration 4403: 0.00012598816603297825\n",
      "Norm of gradient at iteration 4404: 0.00012540176496503\n",
      "Norm of gradient at iteration 4405: 0.00012481807487022055\n",
      "Norm of gradient at iteration 4406: 0.00012423714139374805\n",
      "Norm of gradient at iteration 4407: 0.00012365886824869415\n",
      "Norm of gradient at iteration 4408: 0.00012308327521554175\n",
      "Norm of gradient at iteration 4409: 0.00012251039195516723\n",
      "Norm of gradient at iteration 4410: 0.00012194017647844601\n",
      "Norm of gradient at iteration 4411: 0.00012137259762518147\n",
      "Norm of gradient at iteration 4412: 0.0001208076803254775\n",
      "Norm of gradient at iteration 4413: 0.00012024537243537095\n",
      "Norm of gradient at iteration 4414: 0.00011968569040185692\n",
      "Norm of gradient at iteration 4415: 0.00011912859188813383\n",
      "Norm of gradient at iteration 4416: 0.00011857409669822166\n",
      "Norm of gradient at iteration 4417: 0.00011802223512298745\n",
      "Norm of gradient at iteration 4418: 0.00011747287825244259\n",
      "Norm of gradient at iteration 4419: 0.00011692609977860103\n",
      "Norm of gradient at iteration 4420: 0.00011638185709685515\n",
      "Norm of gradient at iteration 4421: 0.00011584017132737686\n",
      "Norm of gradient at iteration 4422: 0.00011530099859967067\n",
      "Norm of gradient at iteration 4423: 0.00011476432156619769\n",
      "Norm of gradient at iteration 4424: 0.00011423013010664468\n",
      "Norm of gradient at iteration 4425: 0.00011369844498748267\n",
      "Norm of gradient at iteration 4426: 0.00011316923634044715\n",
      "Norm of gradient at iteration 4427: 0.00011264249205176816\n",
      "Norm of gradient at iteration 4428: 0.0001121181975889139\n",
      "Norm of gradient at iteration 4429: 0.00011159636644937797\n",
      "Norm of gradient at iteration 4430: 0.00011107690931777897\n",
      "Norm of gradient at iteration 4431: 0.00011055989952515546\n",
      "Norm of gradient at iteration 4432: 0.00011004530515208866\n",
      "Norm of gradient at iteration 4433: 0.00010953309931768626\n",
      "Norm of gradient at iteration 4434: 0.000109023262201719\n",
      "Norm of gradient at iteration 4435: 0.00010851581249705422\n",
      "Norm of gradient at iteration 4436: 0.00010801072984474016\n",
      "Norm of gradient at iteration 4437: 0.00010750800093866957\n",
      "Norm of gradient at iteration 4438: 0.0001070076046686629\n",
      "Norm of gradient at iteration 4439: 0.00010650953110813853\n",
      "Norm of gradient at iteration 4440: 0.00010601378111533711\n",
      "Norm of gradient at iteration 4441: 0.00010552035012748195\n",
      "Norm of gradient at iteration 4442: 0.00010502920487064218\n",
      "Norm of gradient at iteration 4443: 0.00010454035554380976\n",
      "Norm of gradient at iteration 4444: 0.00010405378048966979\n",
      "Norm of gradient at iteration 4445: 0.00010356943786960156\n",
      "Norm of gradient at iteration 4446: 0.00010308740554119394\n",
      "Norm of gradient at iteration 4447: 0.00010260758000417856\n",
      "Norm of gradient at iteration 4448: 0.00010212998647168464\n",
      "Norm of gradient at iteration 4449: 0.00010165462944046351\n",
      "Norm of gradient at iteration 4450: 0.00010118148469948003\n",
      "Norm of gradient at iteration 4451: 0.00010071050529489229\n",
      "Norm of gradient at iteration 4452: 0.00010024177962755097\n",
      "Norm of gradient at iteration 4453: 9.977518509725022e-05\n",
      "Norm of gradient at iteration 4454: 9.931077110836932e-05\n",
      "Norm of gradient at iteration 4455: 9.884851236403171e-05\n",
      "Norm of gradient at iteration 4456: 9.838843406331309e-05\n",
      "Norm of gradient at iteration 4457: 9.793048589880403e-05\n",
      "Norm of gradient at iteration 4458: 9.747469712843646e-05\n",
      "Norm of gradient at iteration 4459: 9.702098337951913e-05\n",
      "Norm of gradient at iteration 4460: 9.656939736285371e-05\n",
      "Norm of gradient at iteration 4461: 9.611990478137542e-05\n",
      "Norm of gradient at iteration 4462: 9.56725233433267e-05\n",
      "Norm of gradient at iteration 4463: 9.522721315868656e-05\n",
      "Norm of gradient at iteration 4464: 9.478395916617212e-05\n",
      "Norm of gradient at iteration 4465: 9.434279924840884e-05\n",
      "Norm of gradient at iteration 4466: 9.390367599258394e-05\n",
      "Norm of gradient at iteration 4467: 9.346661370030001e-05\n",
      "Norm of gradient at iteration 4468: 9.303157560947185e-05\n",
      "Norm of gradient at iteration 4469: 9.259855070140854e-05\n",
      "Norm of gradient at iteration 4470: 9.216756532891563e-05\n",
      "Norm of gradient at iteration 4471: 9.17385546077226e-05\n",
      "Norm of gradient at iteration 4472: 9.13115757707503e-05\n",
      "Norm of gradient at iteration 4473: 9.088656321804136e-05\n",
      "Norm of gradient at iteration 4474: 9.046353141549552e-05\n",
      "Norm of gradient at iteration 4475: 9.004248295119996e-05\n",
      "Norm of gradient at iteration 4476: 8.962337888123707e-05\n",
      "Norm of gradient at iteration 4477: 8.920622951423252e-05\n",
      "Norm of gradient at iteration 4478: 8.879100606803877e-05\n",
      "Norm of gradient at iteration 4479: 8.837772230380428e-05\n",
      "Norm of gradient at iteration 4480: 8.796634597828245e-05\n",
      "Norm of gradient at iteration 4481: 8.755692338150911e-05\n",
      "Norm of gradient at iteration 4482: 8.714935621059782e-05\n",
      "Norm of gradient at iteration 4483: 8.674376038448268e-05\n",
      "Norm of gradient at iteration 4484: 8.633998974530496e-05\n",
      "Norm of gradient at iteration 4485: 8.593811263444337e-05\n",
      "Norm of gradient at iteration 4486: 8.553810499590813e-05\n",
      "Norm of gradient at iteration 4487: 8.513996685886013e-05\n",
      "Norm of gradient at iteration 4488: 8.474368595035108e-05\n",
      "Norm of gradient at iteration 4489: 8.434924163078996e-05\n",
      "Norm of gradient at iteration 4490: 8.39566251873052e-05\n",
      "Norm of gradient at iteration 4491: 8.356584408954997e-05\n",
      "Norm of gradient at iteration 4492: 8.317690575375354e-05\n",
      "Norm of gradient at iteration 4493: 8.278976000448484e-05\n",
      "Norm of gradient at iteration 4494: 8.240438565687551e-05\n",
      "Norm of gradient at iteration 4495: 8.202085382811886e-05\n",
      "Norm of gradient at iteration 4496: 8.163908079632828e-05\n",
      "Norm of gradient at iteration 4497: 8.125909444002221e-05\n",
      "Norm of gradient at iteration 4498: 8.088085550760765e-05\n",
      "Norm of gradient at iteration 4499: 8.050441737176311e-05\n",
      "Norm of gradient at iteration 4500: 8.012970882027222e-05\n",
      "Norm of gradient at iteration 4501: 7.975673912327283e-05\n",
      "Norm of gradient at iteration 4502: 7.93855123876363e-05\n",
      "Norm of gradient at iteration 4503: 7.901601239744841e-05\n",
      "Norm of gradient at iteration 4504: 7.864823467203312e-05\n",
      "Norm of gradient at iteration 4505: 7.828215782210983e-05\n",
      "Norm of gradient at iteration 4506: 7.791778431523984e-05\n",
      "Norm of gradient at iteration 4507: 7.755513287802586e-05\n",
      "Norm of gradient at iteration 4508: 7.719414234438703e-05\n",
      "Norm of gradient at iteration 4509: 7.683483493024007e-05\n",
      "Norm of gradient at iteration 4510: 7.647723274316054e-05\n",
      "Norm of gradient at iteration 4511: 7.61212516524776e-05\n",
      "Norm of gradient at iteration 4512: 7.576696038219454e-05\n",
      "Norm of gradient at iteration 4513: 7.541430874562273e-05\n",
      "Norm of gradient at iteration 4514: 7.50632748965583e-05\n",
      "Norm of gradient at iteration 4515: 7.471391416536762e-05\n",
      "Norm of gradient at iteration 4516: 7.436615113778898e-05\n",
      "Norm of gradient at iteration 4517: 7.402001175821635e-05\n",
      "Norm of gradient at iteration 4518: 7.36754967102298e-05\n",
      "Norm of gradient at iteration 4519: 7.333255618345102e-05\n",
      "Norm of gradient at iteration 4520: 7.299124937181678e-05\n",
      "Norm of gradient at iteration 4521: 7.265150655905865e-05\n",
      "Norm of gradient at iteration 4522: 7.231336698589372e-05\n",
      "Norm of gradient at iteration 4523: 7.197678888412114e-05\n",
      "Norm of gradient at iteration 4524: 7.164176410547387e-05\n",
      "Norm of gradient at iteration 4525: 7.130831602992824e-05\n",
      "Norm of gradient at iteration 4526: 7.097639685908159e-05\n",
      "Norm of gradient at iteration 4527: 7.06460442057994e-05\n",
      "Norm of gradient at iteration 4528: 7.031722496235136e-05\n",
      "Norm of gradient at iteration 4529: 6.998992563791076e-05\n",
      "Norm of gradient at iteration 4530: 6.966416433052285e-05\n",
      "Norm of gradient at iteration 4531: 6.933991539612481e-05\n",
      "Norm of gradient at iteration 4532: 6.901716366178918e-05\n",
      "Norm of gradient at iteration 4533: 6.869592944523538e-05\n",
      "Norm of gradient at iteration 4534: 6.837616304024507e-05\n",
      "Norm of gradient at iteration 4535: 6.805792002335922e-05\n",
      "Norm of gradient at iteration 4536: 6.774114949589356e-05\n",
      "Norm of gradient at iteration 4537: 6.742585345574935e-05\n",
      "Norm of gradient at iteration 4538: 6.711201591076864e-05\n",
      "Norm of gradient at iteration 4539: 6.679962390002256e-05\n",
      "Norm of gradient at iteration 4540: 6.64887158464464e-05\n",
      "Norm of gradient at iteration 4541: 6.617925036621763e-05\n",
      "Norm of gradient at iteration 4542: 6.587121286356588e-05\n",
      "Norm of gradient at iteration 4543: 6.556460885872182e-05\n",
      "Norm of gradient at iteration 4544: 6.525946083341031e-05\n",
      "Norm of gradient at iteration 4545: 6.495570493164662e-05\n",
      "Norm of gradient at iteration 4546: 6.465336086039404e-05\n",
      "Norm of gradient at iteration 4547: 6.435244939406815e-05\n",
      "Norm of gradient at iteration 4548: 6.405292089596655e-05\n",
      "Norm of gradient at iteration 4549: 6.375476783553554e-05\n",
      "Norm of gradient at iteration 4550: 6.345804142550089e-05\n",
      "Norm of gradient at iteration 4551: 6.31626738167701e-05\n",
      "Norm of gradient at iteration 4552: 6.28686774680394e-05\n",
      "Norm of gradient at iteration 4553: 6.257604778866031e-05\n",
      "Norm of gradient at iteration 4554: 6.228480761384676e-05\n",
      "Norm of gradient at iteration 4555: 6.199489938519257e-05\n",
      "Norm of gradient at iteration 4556: 6.170631202532105e-05\n",
      "Norm of gradient at iteration 4557: 6.141912002854673e-05\n",
      "Norm of gradient at iteration 4558: 6.113323026404321e-05\n",
      "Norm of gradient at iteration 4559: 6.084869541825147e-05\n",
      "Norm of gradient at iteration 4560: 6.0565484448078726e-05\n",
      "Norm of gradient at iteration 4561: 6.028355720002191e-05\n",
      "Norm of gradient at iteration 4562: 6.0002972048886606e-05\n",
      "Norm of gradient at iteration 4563: 5.972370638020346e-05\n",
      "Norm of gradient at iteration 4564: 5.944572404653403e-05\n",
      "Norm of gradient at iteration 4565: 5.9169017381237165e-05\n",
      "Norm of gradient at iteration 4566: 5.889363100938997e-05\n",
      "Norm of gradient at iteration 4567: 5.861950222205858e-05\n",
      "Norm of gradient at iteration 4568: 5.834664776727355e-05\n",
      "Norm of gradient at iteration 4569: 5.807509289986737e-05\n",
      "Norm of gradient at iteration 4570: 5.780477676202353e-05\n",
      "Norm of gradient at iteration 4571: 5.753573887300456e-05\n",
      "Norm of gradient at iteration 4572: 5.7267942102374756e-05\n",
      "Norm of gradient at iteration 4573: 5.70013459189969e-05\n",
      "Norm of gradient at iteration 4574: 5.673606811565766e-05\n",
      "Norm of gradient at iteration 4575: 5.647200000288575e-05\n",
      "Norm of gradient at iteration 4576: 5.620915139238632e-05\n",
      "Norm of gradient at iteration 4577: 5.5947535139171316e-05\n",
      "Norm of gradient at iteration 4578: 5.568713303149753e-05\n",
      "Norm of gradient at iteration 4579: 5.542791881046733e-05\n",
      "Norm of gradient at iteration 4580: 5.516992735940547e-05\n",
      "Norm of gradient at iteration 4581: 5.4913152994599304e-05\n",
      "Norm of gradient at iteration 4582: 5.4657563445649345e-05\n",
      "Norm of gradient at iteration 4583: 5.4403159975644596e-05\n",
      "Norm of gradient at iteration 4584: 5.414995042559172e-05\n",
      "Norm of gradient at iteration 4585: 5.389790670945552e-05\n",
      "Norm of gradient at iteration 4586: 5.364703635489271e-05\n",
      "Norm of gradient at iteration 4587: 5.339734760368817e-05\n",
      "Norm of gradient at iteration 4588: 5.314880137909895e-05\n",
      "Norm of gradient at iteration 4589: 5.2901405396569884e-05\n",
      "Norm of gradient at iteration 4590: 5.2655168870044226e-05\n",
      "Norm of gradient at iteration 4591: 5.241009006314713e-05\n",
      "Norm of gradient at iteration 4592: 5.21661257603285e-05\n",
      "Norm of gradient at iteration 4593: 5.1923328283383093e-05\n",
      "Norm of gradient at iteration 4594: 5.1681672673904306e-05\n",
      "Norm of gradient at iteration 4595: 5.144110706467973e-05\n",
      "Norm of gradient at iteration 4596: 5.120167932696252e-05\n",
      "Norm of gradient at iteration 4597: 5.096337590059295e-05\n",
      "Norm of gradient at iteration 4598: 5.0726149638576536e-05\n",
      "Norm of gradient at iteration 4599: 5.049004534108645e-05\n",
      "Norm of gradient at iteration 4600: 5.0255048458086955e-05\n",
      "Norm of gradient at iteration 4601: 5.0021139323595224e-05\n",
      "Norm of gradient at iteration 4602: 4.9788308518188995e-05\n",
      "Norm of gradient at iteration 4603: 4.955658476963439e-05\n",
      "Norm of gradient at iteration 4604: 4.9325929752797477e-05\n",
      "Norm of gradient at iteration 4605: 4.909633096150508e-05\n",
      "Norm of gradient at iteration 4606: 4.886782107771441e-05\n",
      "Norm of gradient at iteration 4607: 4.864034604819607e-05\n",
      "Norm of gradient at iteration 4608: 4.841394729466465e-05\n",
      "Norm of gradient at iteration 4609: 4.8188594701032174e-05\n",
      "Norm of gradient at iteration 4610: 4.796432772587738e-05\n",
      "Norm of gradient at iteration 4611: 4.774105267600341e-05\n",
      "Norm of gradient at iteration 4612: 4.75188117360068e-05\n",
      "Norm of gradient at iteration 4613: 4.7297664259929916e-05\n",
      "Norm of gradient at iteration 4614: 4.7077520642349305e-05\n",
      "Norm of gradient at iteration 4615: 4.685839216282838e-05\n",
      "Norm of gradient at iteration 4616: 4.664028228357003e-05\n",
      "Norm of gradient at iteration 4617: 4.642318295891194e-05\n",
      "Norm of gradient at iteration 4618: 4.6207110024088554e-05\n",
      "Norm of gradient at iteration 4619: 4.599201240137406e-05\n",
      "Norm of gradient at iteration 4620: 4.577796315516377e-05\n",
      "Norm of gradient at iteration 4621: 4.556488114024569e-05\n",
      "Norm of gradient at iteration 4622: 4.5352807485628366e-05\n",
      "Norm of gradient at iteration 4623: 4.5141705665960196e-05\n",
      "Norm of gradient at iteration 4624: 4.493159061200414e-05\n",
      "Norm of gradient at iteration 4625: 4.4722455794294854e-05\n",
      "Norm of gradient at iteration 4626: 4.4514303020753374e-05\n",
      "Norm of gradient at iteration 4627: 4.4307112951105095e-05\n",
      "Norm of gradient at iteration 4628: 4.41008695657442e-05\n",
      "Norm of gradient at iteration 4629: 4.3895628627841695e-05\n",
      "Norm of gradient at iteration 4630: 4.3691301858092605e-05\n",
      "Norm of gradient at iteration 4631: 4.348794329677388e-05\n",
      "Norm of gradient at iteration 4632: 4.328554911537148e-05\n",
      "Norm of gradient at iteration 4633: 4.3084048365217555e-05\n",
      "Norm of gradient at iteration 4634: 4.2883516628835485e-05\n",
      "Norm of gradient at iteration 4635: 4.268390228344209e-05\n",
      "Norm of gradient at iteration 4636: 4.248523471769549e-05\n",
      "Norm of gradient at iteration 4637: 4.228750470528544e-05\n",
      "Norm of gradient at iteration 4638: 4.20906731990551e-05\n",
      "Norm of gradient at iteration 4639: 4.1894747201598184e-05\n",
      "Norm of gradient at iteration 4640: 4.169976707905641e-05\n",
      "Norm of gradient at iteration 4641: 4.1505669319781954e-05\n",
      "Norm of gradient at iteration 4642: 4.131247813847781e-05\n",
      "Norm of gradient at iteration 4643: 4.112020541193556e-05\n",
      "Norm of gradient at iteration 4644: 4.092881630990983e-05\n",
      "Norm of gradient at iteration 4645: 4.0738286171002675e-05\n",
      "Norm of gradient at iteration 4646: 4.05486808536573e-05\n",
      "Norm of gradient at iteration 4647: 4.035994731692707e-05\n",
      "Norm of gradient at iteration 4648: 4.0172099893910825e-05\n",
      "Norm of gradient at iteration 4649: 3.998509007058189e-05\n",
      "Norm of gradient at iteration 4650: 3.9798979993300317e-05\n",
      "Norm of gradient at iteration 4651: 3.961374196446393e-05\n",
      "Norm of gradient at iteration 4652: 3.9429354110275944e-05\n",
      "Norm of gradient at iteration 4653: 3.924583416526798e-05\n",
      "Norm of gradient at iteration 4654: 3.90631790330507e-05\n",
      "Norm of gradient at iteration 4655: 3.888134894361881e-05\n",
      "Norm of gradient at iteration 4656: 3.8700392828918e-05\n",
      "Norm of gradient at iteration 4657: 3.8520270877478614e-05\n",
      "Norm of gradient at iteration 4658: 3.834097481976058e-05\n",
      "Norm of gradient at iteration 4659: 3.81624950823071e-05\n",
      "Norm of gradient at iteration 4660: 3.798486850017193e-05\n",
      "Norm of gradient at iteration 4661: 3.7808060613938105e-05\n",
      "Norm of gradient at iteration 4662: 3.763208655315816e-05\n",
      "Norm of gradient at iteration 4663: 3.745694240517441e-05\n",
      "Norm of gradient at iteration 4664: 3.728258133507231e-05\n",
      "Norm of gradient at iteration 4665: 3.710903922884615e-05\n",
      "Norm of gradient at iteration 4666: 3.693632285881426e-05\n",
      "Norm of gradient at iteration 4667: 3.676440872923871e-05\n",
      "Norm of gradient at iteration 4668: 3.6593275847759646e-05\n",
      "Norm of gradient at iteration 4669: 3.642296573055307e-05\n",
      "Norm of gradient at iteration 4670: 3.625345626309399e-05\n",
      "Norm of gradient at iteration 4671: 3.608469421059375e-05\n",
      "Norm of gradient at iteration 4672: 3.5916742350716936e-05\n",
      "Norm of gradient at iteration 4673: 3.57495616167129e-05\n",
      "Norm of gradient at iteration 4674: 3.558316602069941e-05\n",
      "Norm of gradient at iteration 4675: 3.5417549718284175e-05\n",
      "Norm of gradient at iteration 4676: 3.525271461213951e-05\n",
      "Norm of gradient at iteration 4677: 3.508861090642925e-05\n",
      "Norm of gradient at iteration 4678: 3.492529072650627e-05\n",
      "Norm of gradient at iteration 4679: 3.476273658380451e-05\n",
      "Norm of gradient at iteration 4680: 3.46009419985143e-05\n",
      "Norm of gradient at iteration 4681: 3.443989988885064e-05\n",
      "Norm of gradient at iteration 4682: 3.427959390332603e-05\n",
      "Norm of gradient at iteration 4683: 3.4120026998825313e-05\n",
      "Norm of gradient at iteration 4684: 3.396121653620734e-05\n",
      "Norm of gradient at iteration 4685: 3.3803135077094585e-05\n",
      "Norm of gradient at iteration 4686: 3.364579914275009e-05\n",
      "Norm of gradient at iteration 4687: 3.348918830963028e-05\n",
      "Norm of gradient at iteration 4688: 3.33332946737245e-05\n",
      "Norm of gradient at iteration 4689: 3.31781612430419e-05\n",
      "Norm of gradient at iteration 4690: 3.302372391440592e-05\n",
      "Norm of gradient at iteration 4691: 3.2870035946895236e-05\n",
      "Norm of gradient at iteration 4692: 3.271700390709132e-05\n",
      "Norm of gradient at iteration 4693: 3.256473247920827e-05\n",
      "Norm of gradient at iteration 4694: 3.241317298003316e-05\n",
      "Norm of gradient at iteration 4695: 3.226230166128648e-05\n",
      "Norm of gradient at iteration 4696: 3.2112141679144606e-05\n",
      "Norm of gradient at iteration 4697: 3.1962659105914076e-05\n",
      "Norm of gradient at iteration 4698: 3.181389677207369e-05\n",
      "Norm of gradient at iteration 4699: 3.16658189836502e-05\n",
      "Norm of gradient at iteration 4700: 3.1518459567584284e-05\n",
      "Norm of gradient at iteration 4701: 3.137175141947229e-05\n",
      "Norm of gradient at iteration 4702: 3.122573035330487e-05\n",
      "Norm of gradient at iteration 4703: 3.108037807002549e-05\n",
      "Norm of gradient at iteration 4704: 3.093571172111662e-05\n",
      "Norm of gradient at iteration 4705: 3.079171661615074e-05\n",
      "Norm of gradient at iteration 4706: 3.064842237097444e-05\n",
      "Norm of gradient at iteration 4707: 3.050577409543296e-05\n",
      "Norm of gradient at iteration 4708: 3.0363749774404547e-05\n",
      "Norm of gradient at iteration 4709: 3.022243531154964e-05\n",
      "Norm of gradient at iteration 4710: 3.0081766434197845e-05\n",
      "Norm of gradient at iteration 4711: 2.9941760784121455e-05\n",
      "Norm of gradient at iteration 4712: 2.9802380437500703e-05\n",
      "Norm of gradient at iteration 4713: 2.966364804313665e-05\n",
      "Norm of gradient at iteration 4714: 2.9525606977866348e-05\n",
      "Norm of gradient at iteration 4715: 2.938817355865014e-05\n",
      "Norm of gradient at iteration 4716: 2.925140510316296e-05\n",
      "Norm of gradient at iteration 4717: 2.911525081214728e-05\n",
      "Norm of gradient at iteration 4718: 2.897972672086859e-05\n",
      "Norm of gradient at iteration 4719: 2.8844814195855722e-05\n",
      "Norm of gradient at iteration 4720: 2.871056889289559e-05\n",
      "Norm of gradient at iteration 4721: 2.8576944896585938e-05\n",
      "Norm of gradient at iteration 4722: 2.8443931966558995e-05\n",
      "Norm of gradient at iteration 4723: 2.8311529374887015e-05\n",
      "Norm of gradient at iteration 4724: 2.8179766066832774e-05\n",
      "Norm of gradient at iteration 4725: 2.8048603964321087e-05\n",
      "Norm of gradient at iteration 4726: 2.7918041698592864e-05\n",
      "Norm of gradient at iteration 4727: 2.7788080340439463e-05\n",
      "Norm of gradient at iteration 4728: 2.765873905085013e-05\n",
      "Norm of gradient at iteration 4729: 2.7530002651167608e-05\n",
      "Norm of gradient at iteration 4730: 2.740187628145006e-05\n",
      "Norm of gradient at iteration 4731: 2.727432128029015e-05\n",
      "Norm of gradient at iteration 4732: 2.7147365862019113e-05\n",
      "Norm of gradient at iteration 4733: 2.7020997275097253e-05\n",
      "Norm of gradient at iteration 4734: 2.6895236984822732e-05\n",
      "Norm of gradient at iteration 4735: 2.67700355884633e-05\n",
      "Norm of gradient at iteration 4736: 2.664543306163327e-05\n",
      "Norm of gradient at iteration 4737: 2.6521432722684757e-05\n",
      "Norm of gradient at iteration 4738: 2.6397999891118276e-05\n",
      "Norm of gradient at iteration 4739: 2.627510202550584e-05\n",
      "Norm of gradient at iteration 4740: 2.615280547277142e-05\n",
      "Norm of gradient at iteration 4741: 2.6031082932741067e-05\n",
      "Norm of gradient at iteration 4742: 2.5909909433655453e-05\n",
      "Norm of gradient at iteration 4743: 2.5789306366483784e-05\n",
      "Norm of gradient at iteration 4744: 2.5669276361909907e-05\n",
      "Norm of gradient at iteration 4745: 2.5549773449749958e-05\n",
      "Norm of gradient at iteration 4746: 2.5430898304364622e-05\n",
      "Norm of gradient at iteration 4747: 2.531249156758145e-05\n",
      "Norm of gradient at iteration 4748: 2.5194680839323223e-05\n",
      "Norm of gradient at iteration 4749: 2.5077431361149068e-05\n",
      "Norm of gradient at iteration 4750: 2.4960725999563823e-05\n",
      "Norm of gradient at iteration 4751: 2.4844521639179054e-05\n",
      "Norm of gradient at iteration 4752: 2.472886698181045e-05\n",
      "Norm of gradient at iteration 4753: 2.4613806971248748e-05\n",
      "Norm of gradient at iteration 4754: 2.449921147789077e-05\n",
      "Norm of gradient at iteration 4755: 2.4385207087839496e-05\n",
      "Norm of gradient at iteration 4756: 2.4271706220928158e-05\n",
      "Norm of gradient at iteration 4757: 2.4158739087347233e-05\n",
      "Norm of gradient at iteration 4758: 2.404628555365461e-05\n",
      "Norm of gradient at iteration 4759: 2.3934356709387676e-05\n",
      "Norm of gradient at iteration 4760: 2.3822949160550456e-05\n",
      "Norm of gradient at iteration 4761: 2.3712060258395915e-05\n",
      "Norm of gradient at iteration 4762: 2.3601689161630015e-05\n",
      "Norm of gradient at iteration 4763: 2.3491836627479845e-05\n",
      "Norm of gradient at iteration 4764: 2.33825127345727e-05\n",
      "Norm of gradient at iteration 4765: 2.3273680730070273e-05\n",
      "Norm of gradient at iteration 4766: 2.3165349651316756e-05\n",
      "Norm of gradient at iteration 4767: 2.305752606368859e-05\n",
      "Norm of gradient at iteration 4768: 2.2950217291213918e-05\n",
      "Norm of gradient at iteration 4769: 2.2843378350295058e-05\n",
      "Norm of gradient at iteration 4770: 2.2737073860188306e-05\n",
      "Norm of gradient at iteration 4771: 2.2631232604100217e-05\n",
      "Norm of gradient at iteration 4772: 2.2525909185976345e-05\n",
      "Norm of gradient at iteration 4773: 2.242108153661653e-05\n",
      "Norm of gradient at iteration 4774: 2.2316717831756673e-05\n",
      "Norm of gradient at iteration 4775: 2.221283276003285e-05\n",
      "Norm of gradient at iteration 4776: 2.2109449536905003e-05\n",
      "Norm of gradient at iteration 4777: 2.2006547517522804e-05\n",
      "Norm of gradient at iteration 4778: 2.1904107473994408e-05\n",
      "Norm of gradient at iteration 4779: 2.1802147824139406e-05\n",
      "Norm of gradient at iteration 4780: 2.170069015919303e-05\n",
      "Norm of gradient at iteration 4781: 2.159970760845213e-05\n",
      "Norm of gradient at iteration 4782: 2.149914605610589e-05\n",
      "Norm of gradient at iteration 4783: 2.1399107433186184e-05\n",
      "Norm of gradient at iteration 4784: 2.1299498304911206e-05\n",
      "Norm of gradient at iteration 4785: 2.1200359719967193e-05\n",
      "Norm of gradient at iteration 4786: 2.1101654949435967e-05\n",
      "Norm of gradient at iteration 4787: 2.100346893443425e-05\n",
      "Norm of gradient at iteration 4788: 2.0905693219708396e-05\n",
      "Norm of gradient at iteration 4789: 2.0808402367508125e-05\n",
      "Norm of gradient at iteration 4790: 2.0711547536396707e-05\n",
      "Norm of gradient at iteration 4791: 2.0615158309110265e-05\n",
      "Norm of gradient at iteration 4792: 2.0519218761228836e-05\n",
      "Norm of gradient at iteration 4793: 2.0423696933694743e-05\n",
      "Norm of gradient at iteration 4794: 2.0328607939266863e-05\n",
      "Norm of gradient at iteration 4795: 2.0233999552478646e-05\n",
      "Norm of gradient at iteration 4796: 2.013983508551894e-05\n",
      "Norm of gradient at iteration 4797: 2.004609651173361e-05\n",
      "Norm of gradient at iteration 4798: 1.995277867757792e-05\n",
      "Norm of gradient at iteration 4799: 1.9859902685080564e-05\n",
      "Norm of gradient at iteration 4800: 1.9767470766047017e-05\n",
      "Norm of gradient at iteration 4801: 1.9675447550509955e-05\n",
      "Norm of gradient at iteration 4802: 1.9583873631753686e-05\n",
      "Norm of gradient at iteration 4803: 1.9492711284661052e-05\n",
      "Norm of gradient at iteration 4804: 1.9402006106659047e-05\n",
      "Norm of gradient at iteration 4805: 1.93116818891298e-05\n",
      "Norm of gradient at iteration 4806: 1.922181765501177e-05\n",
      "Norm of gradient at iteration 4807: 1.913234326340378e-05\n",
      "Norm of gradient at iteration 4808: 1.9043285571944432e-05\n",
      "Norm of gradient at iteration 4809: 1.895466672470974e-05\n",
      "Norm of gradient at iteration 4810: 1.88664510380653e-05\n",
      "Norm of gradient at iteration 4811: 1.877861820942965e-05\n",
      "Norm of gradient at iteration 4812: 1.869123077033417e-05\n",
      "Norm of gradient at iteration 4813: 1.8604215095789816e-05\n",
      "Norm of gradient at iteration 4814: 1.851762026526565e-05\n",
      "Norm of gradient at iteration 4815: 1.843143042379204e-05\n",
      "Norm of gradient at iteration 4816: 1.834567212487366e-05\n",
      "Norm of gradient at iteration 4817: 1.8260281052678734e-05\n",
      "Norm of gradient at iteration 4818: 1.817527761174546e-05\n",
      "Norm of gradient at iteration 4819: 1.809069493884306e-05\n",
      "Norm of gradient at iteration 4820: 1.8006486434343448e-05\n",
      "Norm of gradient at iteration 4821: 1.7922675513016308e-05\n",
      "Norm of gradient at iteration 4822: 1.7839238696943633e-05\n",
      "Norm of gradient at iteration 4823: 1.7756217699818327e-05\n",
      "Norm of gradient at iteration 4824: 1.7673556685692574e-05\n",
      "Norm of gradient at iteration 4825: 1.759130501004181e-05\n",
      "Norm of gradient at iteration 4826: 1.7509439504226627e-05\n",
      "Norm of gradient at iteration 4827: 1.7427915637163608e-05\n",
      "Norm of gradient at iteration 4828: 1.734679823427757e-05\n",
      "Norm of gradient at iteration 4829: 1.7266041067229668e-05\n",
      "Norm of gradient at iteration 4830: 1.718568059809141e-05\n",
      "Norm of gradient at iteration 4831: 1.7105696998590442e-05\n",
      "Norm of gradient at iteration 4832: 1.7026078366408597e-05\n",
      "Norm of gradient at iteration 4833: 1.6946822192575965e-05\n",
      "Norm of gradient at iteration 4834: 1.686796830257649e-05\n",
      "Norm of gradient at iteration 4835: 1.678943527917515e-05\n",
      "Norm of gradient at iteration 4836: 1.6711288448211507e-05\n",
      "Norm of gradient at iteration 4837: 1.6633500901510684e-05\n",
      "Norm of gradient at iteration 4838: 1.6556085740667725e-05\n",
      "Norm of gradient at iteration 4839: 1.6479046353106953e-05\n",
      "Norm of gradient at iteration 4840: 1.6402328750053157e-05\n",
      "Norm of gradient at iteration 4841: 1.6325991419254974e-05\n",
      "Norm of gradient at iteration 4842: 1.6249974549800894e-05\n",
      "Norm of gradient at iteration 4843: 1.617435128687055e-05\n",
      "Norm of gradient at iteration 4844: 1.609906206690739e-05\n",
      "Norm of gradient at iteration 4845: 1.6024137066593834e-05\n",
      "Norm of gradient at iteration 4846: 1.5949558241459134e-05\n",
      "Norm of gradient at iteration 4847: 1.587534104442097e-05\n",
      "Norm of gradient at iteration 4848: 1.5801436107754445e-05\n",
      "Norm of gradient at iteration 4849: 1.572790225414273e-05\n",
      "Norm of gradient at iteration 4850: 1.5654663404481194e-05\n",
      "Norm of gradient at iteration 4851: 1.5581806399446423e-05\n",
      "Norm of gradient at iteration 4852: 1.5509289973574907e-05\n",
      "Norm of gradient at iteration 4853: 1.5437083799773098e-05\n",
      "Norm of gradient at iteration 4854: 1.536523580186164e-05\n",
      "Norm of gradient at iteration 4855: 1.5293717451055868e-05\n",
      "Norm of gradient at iteration 4856: 1.5222522283112704e-05\n",
      "Norm of gradient at iteration 4857: 1.515168671714242e-05\n",
      "Norm of gradient at iteration 4858: 1.5081180515660747e-05\n",
      "Norm of gradient at iteration 4859: 1.5010975255777566e-05\n",
      "Norm of gradient at iteration 4860: 1.4941105032717824e-05\n",
      "Norm of gradient at iteration 4861: 1.4871571946105806e-05\n",
      "Norm of gradient at iteration 4862: 1.4802359214570442e-05\n",
      "Norm of gradient at iteration 4863: 1.4733456540005237e-05\n",
      "Norm of gradient at iteration 4864: 1.4664871303080272e-05\n",
      "Norm of gradient at iteration 4865: 1.459663146547125e-05\n",
      "Norm of gradient at iteration 4866: 1.4528681501856342e-05\n",
      "Norm of gradient at iteration 4867: 1.446106834581326e-05\n",
      "Norm of gradient at iteration 4868: 1.4393760051229201e-05\n",
      "Norm of gradient at iteration 4869: 1.4326767887762238e-05\n",
      "Norm of gradient at iteration 4870: 1.4260073540779957e-05\n",
      "Norm of gradient at iteration 4871: 1.4193711576525565e-05\n",
      "Norm of gradient at iteration 4872: 1.4127632008287356e-05\n",
      "Norm of gradient at iteration 4873: 1.406188711835306e-05\n",
      "Norm of gradient at iteration 4874: 1.3996414791325778e-05\n",
      "Norm of gradient at iteration 4875: 1.3931260871567418e-05\n",
      "Norm of gradient at iteration 4876: 1.3866445247821398e-05\n",
      "Norm of gradient at iteration 4877: 1.3801880049999014e-05\n",
      "Norm of gradient at iteration 4878: 1.3737637999518764e-05\n",
      "Norm of gradient at iteration 4879: 1.3673726285594216e-05\n",
      "Norm of gradient at iteration 4880: 1.3610055518070218e-05\n",
      "Norm of gradient at iteration 4881: 1.3546728538830967e-05\n",
      "Norm of gradient at iteration 4882: 1.3483666770606086e-05\n",
      "Norm of gradient at iteration 4883: 1.3420895996836182e-05\n",
      "Norm of gradient at iteration 4884: 1.3358432518997417e-05\n",
      "Norm of gradient at iteration 4885: 1.3296264111221059e-05\n",
      "Norm of gradient at iteration 4886: 1.3234371089537277e-05\n",
      "Norm of gradient at iteration 4887: 1.3172746025560084e-05\n",
      "Norm of gradient at iteration 4888: 1.311144702657098e-05\n",
      "Norm of gradient at iteration 4889: 1.3050422893800868e-05\n",
      "Norm of gradient at iteration 4890: 1.2989675235781396e-05\n",
      "Norm of gradient at iteration 4891: 1.292923128230525e-05\n",
      "Norm of gradient at iteration 4892: 1.286906331857549e-05\n",
      "Norm of gradient at iteration 4893: 1.280913918788643e-05\n",
      "Norm of gradient at iteration 4894: 1.2749520343324419e-05\n",
      "Norm of gradient at iteration 4895: 1.2690179752793588e-05\n",
      "Norm of gradient at iteration 4896: 1.2631093288114741e-05\n",
      "Norm of gradient at iteration 4897: 1.2572308616223908e-05\n",
      "Norm of gradient at iteration 4898: 1.2513803739527016e-05\n",
      "Norm of gradient at iteration 4899: 1.2455573224444382e-05\n",
      "Norm of gradient at iteration 4900: 1.2397583504551723e-05\n",
      "Norm of gradient at iteration 4901: 1.2339885047915249e-05\n",
      "Norm of gradient at iteration 4902: 1.2282462473700881e-05\n",
      "Norm of gradient at iteration 4903: 1.222528296375575e-05\n",
      "Norm of gradient at iteration 4904: 1.2168362092154552e-05\n",
      "Norm of gradient at iteration 4905: 1.2111745360396193e-05\n",
      "Norm of gradient at iteration 4906: 1.2055363656979918e-05\n",
      "Norm of gradient at iteration 4907: 1.1999251924970644e-05\n",
      "Norm of gradient at iteration 4908: 1.1943399651142635e-05\n",
      "Norm of gradient at iteration 4909: 1.188783381323288e-05\n",
      "Norm of gradient at iteration 4910: 1.183250049938848e-05\n",
      "Norm of gradient at iteration 4911: 1.1777421257548846e-05\n",
      "Norm of gradient at iteration 4912: 1.1722598772399907e-05\n",
      "Norm of gradient at iteration 4913: 1.1668023189908423e-05\n",
      "Norm of gradient at iteration 4914: 1.1613698328818114e-05\n",
      "Norm of gradient at iteration 4915: 1.1559652046359093e-05\n",
      "Norm of gradient at iteration 4916: 1.1505829241916105e-05\n",
      "Norm of gradient at iteration 4917: 1.145227619513516e-05\n",
      "Norm of gradient at iteration 4918: 1.1398986918543491e-05\n",
      "Norm of gradient at iteration 4919: 1.1345922322007118e-05\n",
      "Norm of gradient at iteration 4920: 1.1293095122214311e-05\n",
      "Norm of gradient at iteration 4921: 1.1240538415200288e-05\n",
      "Norm of gradient at iteration 4922: 1.1188219210792412e-05\n",
      "Norm of gradient at iteration 4923: 1.113613865685335e-05\n",
      "Norm of gradient at iteration 4924: 1.1084304090916282e-05\n",
      "Norm of gradient at iteration 4925: 1.103272078253419e-05\n",
      "Norm of gradient at iteration 4926: 1.0981360193848059e-05\n",
      "Norm of gradient at iteration 4927: 1.0930257615737745e-05\n",
      "Norm of gradient at iteration 4928: 1.0879385932683049e-05\n",
      "Norm of gradient at iteration 4929: 1.0828750106653386e-05\n",
      "Norm of gradient at iteration 4930: 1.0778351727110904e-05\n",
      "Norm of gradient at iteration 4931: 1.0728192072667932e-05\n",
      "Norm of gradient at iteration 4932: 1.0678252609621316e-05\n",
      "Norm of gradient at iteration 4933: 1.0628549951507848e-05\n",
      "Norm of gradient at iteration 4934: 1.0579074480333093e-05\n",
      "Norm of gradient at iteration 4935: 1.0529845203396726e-05\n",
      "Norm of gradient at iteration 4936: 1.0480836461255003e-05\n",
      "Norm of gradient at iteration 4937: 1.0432053116902733e-05\n",
      "Norm of gradient at iteration 4938: 1.03835067576234e-05\n",
      "Norm of gradient at iteration 4939: 1.0335181066850341e-05\n",
      "Norm of gradient at iteration 4940: 1.0287049578413642e-05\n",
      "Norm of gradient at iteration 4941: 1.0239194312594689e-05\n",
      "Norm of gradient at iteration 4942: 1.0191518088381466e-05\n",
      "Norm of gradient at iteration 4943: 1.0144109523221508e-05\n",
      "Norm of gradient at iteration 4944: 1.00969038017078e-05\n",
      "Norm of gradient at iteration 4945: 1.0049890785241876e-05\n",
      "Norm of gradient at iteration 4946: 1.0003129126789748e-05\n",
      "Norm of gradient at iteration 4947: 9.956545465565491e-06\n"
     ]
    }
   ],
   "source": [
    "gradient_betas = gradient_descent(X_train_scaled,y_train,np.zeros((X_train_scaled.shape[1],1)),0.01,tau = 10e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[538146.88650935],\n",
       "       [-55655.7172881 ],\n",
       "       [  2842.59688566],\n",
       "       [290948.51915265],\n",
       "       [-16587.41536677]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = X_test_scaled @ gradient_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 277901.8758834 ],\n",
       "       [ 205501.37763017],\n",
       "       [1035367.15026277],\n",
       "       ...,\n",
       "       [ 381686.66598857],\n",
       "       [ 648327.11088438],\n",
       "       [ 965025.3719985 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5049944614045041"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test.flatten(),predictions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient(X,y,tau,betas,decay_rate,learning_rate,maxiter = 10e6, batch_size = 1):\n",
    "    xy = np.c_[X.reshape(X.shape[0],-1),y.reshape(y.shape[0],1)]\n",
    "    rng = np.random.default_rng(0)\n",
    "    \n",
    "    diff = 0\n",
    "    i = 0\n",
    "    for _ in range(maxiter):\n",
    "        rng.shuffle(xy)\n",
    "        x = 0\n",
    "        grad = 0\n",
    "        learning_rate = (1/(i+1))\n",
    "        for start in range(0,X.shape[0],batch_size):\n",
    "            stop = start + batch_size\n",
    "            X_batch, y_batch = xy[start:stop,:-1], xy[start:stop,-1:]\n",
    "            x+=1\n",
    "            \n",
    "            grad += (2/(X_batch.shape[0]))*X_batch.T @ (X_batch @ betas - y_batch)\n",
    "            # grad += gradient(X_batch,y_batch,betas)\n",
    "            \n",
    "        grad = grad/x\n",
    "        grad_norm = np.linalg.norm(grad)\n",
    "        if grad_norm < tau:\n",
    "            break\n",
    "        print(\"Norm of gradient at iteration {}: {}\".format(i, grad_norm))\n",
    "        betas += -learning_rate*grad\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "    return betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[538000],\n",
       "       [604000],\n",
       "       [510000],\n",
       "       ...,\n",
       "       [402101],\n",
       "       [400000],\n",
       "       [325000]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of gradient at iteration 0: 1276080.6084072064\n",
      "Norm of gradient at iteration 1: 2572714.5807547425\n",
      "Norm of gradient at iteration 2: 2935767.2170651085\n",
      "Norm of gradient at iteration 3: 1481105.4704729647\n",
      "Norm of gradient at iteration 4: 192634.013977105\n",
      "Norm of gradient at iteration 5: 34548.51966571339\n",
      "Norm of gradient at iteration 6: 27310.903788501546\n",
      "Norm of gradient at iteration 7: 25193.149101071205\n",
      "Norm of gradient at iteration 8: 23674.552159072682\n",
      "Norm of gradient at iteration 9: 22445.096627400864\n",
      "Norm of gradient at iteration 10: 21407.049368425327\n",
      "Norm of gradient at iteration 11: 20490.928581392516\n",
      "Norm of gradient at iteration 12: 19690.094669314174\n",
      "Norm of gradient at iteration 13: 18978.338483827658\n",
      "Norm of gradient at iteration 14: 18359.664244082735\n",
      "Norm of gradient at iteration 15: 17796.87794388479\n",
      "Norm of gradient at iteration 16: 17274.0642944129\n",
      "Norm of gradient at iteration 17: 16800.865788207546\n",
      "Norm of gradient at iteration 18: 16363.847457190888\n",
      "Norm of gradient at iteration 19: 15965.740427988247\n",
      "Norm of gradient at iteration 20: 15593.366620854535\n",
      "Norm of gradient at iteration 21: 15300.020963478251\n",
      "Norm of gradient at iteration 22: 14923.60411137321\n",
      "Norm of gradient at iteration 23: 14606.41787815783\n",
      "Norm of gradient at iteration 24: 14338.695379381574\n",
      "Norm of gradient at iteration 25: 14075.339408197262\n",
      "Norm of gradient at iteration 26: 13816.133858000421\n",
      "Norm of gradient at iteration 27: 13584.040928431832\n",
      "Norm of gradient at iteration 28: 13358.315995578756\n",
      "Norm of gradient at iteration 29: 13139.290339643543\n",
      "Norm of gradient at iteration 30: 12936.169799912208\n",
      "Norm of gradient at iteration 31: 12742.953682084202\n",
      "Norm of gradient at iteration 32: 12563.554405919676\n",
      "Norm of gradient at iteration 33: 12380.976368451253\n",
      "Norm of gradient at iteration 34: 12202.233681049009\n",
      "Norm of gradient at iteration 35: 12048.016308975022\n",
      "Norm of gradient at iteration 36: 11887.413254376897\n",
      "Norm of gradient at iteration 37: 11743.457949663636\n",
      "Norm of gradient at iteration 38: 11602.75175074976\n",
      "Norm of gradient at iteration 39: 11464.105161570746\n",
      "Norm of gradient at iteration 40: 11330.208443067202\n",
      "Norm of gradient at iteration 41: 11195.663137785168\n",
      "Norm of gradient at iteration 42: 11071.873539744685\n",
      "Norm of gradient at iteration 43: 10932.775118810472\n",
      "Norm of gradient at iteration 44: 10837.627690540112\n",
      "Norm of gradient at iteration 45: 10732.194483935235\n",
      "Norm of gradient at iteration 46: 10618.253115177684\n",
      "Norm of gradient at iteration 47: 10507.857962303335\n",
      "Norm of gradient at iteration 48: 10416.106104892342\n",
      "Norm of gradient at iteration 49: 10312.482739385758\n",
      "Norm of gradient at iteration 50: 10211.205043417925\n",
      "Norm of gradient at iteration 51: 10115.485931021623\n",
      "Norm of gradient at iteration 52: 10024.770439528776\n",
      "Norm of gradient at iteration 53: 9940.902502713237\n",
      "Norm of gradient at iteration 54: 9851.324710540639\n",
      "Norm of gradient at iteration 55: 9774.251415560502\n",
      "Norm of gradient at iteration 56: 9691.750633147207\n",
      "Norm of gradient at iteration 57: 9614.536332152045\n",
      "Norm of gradient at iteration 58: 9543.497912461573\n",
      "Norm of gradient at iteration 59: 9461.545356007491\n",
      "Norm of gradient at iteration 60: 9386.19007913267\n",
      "Norm of gradient at iteration 61: 9319.027190349892\n",
      "Norm of gradient at iteration 62: 9224.005623319143\n",
      "Norm of gradient at iteration 63: 9183.493848116723\n",
      "Norm of gradient at iteration 64: 9107.269674694842\n",
      "Norm of gradient at iteration 65: 9038.845650819494\n",
      "Norm of gradient at iteration 66: 8982.311471035426\n",
      "Norm of gradient at iteration 67: 8924.471208444074\n",
      "Norm of gradient at iteration 68: 8863.976015733917\n",
      "Norm of gradient at iteration 69: 8798.655755222855\n",
      "Norm of gradient at iteration 70: 8772.15477437511\n",
      "Norm of gradient at iteration 71: 8688.74697786137\n",
      "Norm of gradient at iteration 72: 8622.735125196628\n",
      "Norm of gradient at iteration 73: 8568.548135911544\n",
      "Norm of gradient at iteration 74: 8509.735883301333\n",
      "Norm of gradient at iteration 75: 8487.0579643319\n",
      "Norm of gradient at iteration 76: 8414.150622079384\n",
      "Norm of gradient at iteration 77: 8365.205152914175\n",
      "Norm of gradient at iteration 78: 8315.44601256484\n",
      "Norm of gradient at iteration 79: 8259.768598512792\n",
      "Norm of gradient at iteration 80: 8214.862658829144\n",
      "Norm of gradient at iteration 81: 8172.710566630071\n",
      "Norm of gradient at iteration 82: 8122.443338232458\n",
      "Norm of gradient at iteration 83: 8079.747098596876\n",
      "Norm of gradient at iteration 84: 8028.547126555409\n",
      "Norm of gradient at iteration 85: 8000.180703145298\n",
      "Norm of gradient at iteration 86: 7955.791635682794\n",
      "Norm of gradient at iteration 87: 7895.241997012671\n",
      "Norm of gradient at iteration 88: 7857.826790615982\n",
      "Norm of gradient at iteration 89: 7804.815700611958\n",
      "Norm of gradient at iteration 90: 7782.0485646381485\n",
      "Norm of gradient at iteration 91: 7736.973797417165\n",
      "Norm of gradient at iteration 92: 7705.5208047894\n",
      "Norm of gradient at iteration 93: 7663.259400185372\n",
      "Norm of gradient at iteration 94: 7619.732829133591\n",
      "Norm of gradient at iteration 95: 7585.391674779172\n",
      "Norm of gradient at iteration 96: 7549.083557145704\n",
      "Norm of gradient at iteration 97: 7511.994583846777\n",
      "Norm of gradient at iteration 98: 7481.774455247176\n",
      "Norm of gradient at iteration 99: 7448.212095644428\n",
      "Norm of gradient at iteration 100: 7405.746337620197\n",
      "Norm of gradient at iteration 101: 7370.892784678401\n",
      "Norm of gradient at iteration 102: 7335.617591240355\n",
      "Norm of gradient at iteration 103: 7311.547639717223\n",
      "Norm of gradient at iteration 104: 7271.6858139876695\n",
      "Norm of gradient at iteration 105: 7207.322187189655\n",
      "Norm of gradient at iteration 106: 7217.8827516286765\n",
      "Norm of gradient at iteration 107: 7183.026280472006\n",
      "Norm of gradient at iteration 108: 7147.790896005798\n",
      "Norm of gradient at iteration 109: 7116.2167392128285\n",
      "Norm of gradient at iteration 110: 7076.100917357383\n",
      "Norm of gradient at iteration 111: 7061.251328068996\n",
      "Norm of gradient at iteration 112: 7052.558471542744\n",
      "Norm of gradient at iteration 113: 7020.42369780773\n",
      "Norm of gradient at iteration 114: 6971.108386471279\n",
      "Norm of gradient at iteration 115: 6947.100263863771\n",
      "Norm of gradient at iteration 116: 6928.700626336149\n",
      "Norm of gradient at iteration 117: 6888.446741786105\n",
      "Norm of gradient at iteration 118: 6862.378211916504\n",
      "Norm of gradient at iteration 119: 6834.83798415483\n",
      "Norm of gradient at iteration 120: 6811.4082366173325\n",
      "Norm of gradient at iteration 121: 6783.0647801099\n",
      "Norm of gradient at iteration 122: 6759.579396157983\n",
      "Norm of gradient at iteration 123: 6731.789487570057\n",
      "Norm of gradient at iteration 124: 6706.685722720072\n",
      "Norm of gradient at iteration 125: 6677.170869324954\n",
      "Norm of gradient at iteration 126: 6660.139118833362\n",
      "Norm of gradient at iteration 127: 6622.992254472409\n",
      "Norm of gradient at iteration 128: 6603.214440835429\n",
      "Norm of gradient at iteration 129: 6581.828099271254\n",
      "Norm of gradient at iteration 130: 6559.264817701762\n",
      "Norm of gradient at iteration 131: 6535.886237914944\n",
      "Norm of gradient at iteration 132: 6511.9154974095645\n",
      "Norm of gradient at iteration 133: 6492.350975107697\n",
      "Norm of gradient at iteration 134: 6468.281714382437\n",
      "Norm of gradient at iteration 135: 6444.170029697262\n",
      "Norm of gradient at iteration 136: 6419.172870308511\n",
      "Norm of gradient at iteration 137: 6402.17483677962\n",
      "Norm of gradient at iteration 138: 6376.027633783317\n",
      "Norm of gradient at iteration 139: 6365.701292086986\n",
      "Norm of gradient at iteration 140: 6341.186897990462\n",
      "Norm of gradient at iteration 141: 6316.75542200113\n",
      "Norm of gradient at iteration 142: 6292.555014440224\n",
      "Norm of gradient at iteration 143: 6273.952955183887\n",
      "Norm of gradient at iteration 144: 6251.778536962731\n",
      "Norm of gradient at iteration 145: 6229.773523218284\n",
      "Norm of gradient at iteration 146: 6212.73060362039\n",
      "Norm of gradient at iteration 147: 6195.5237652326405\n",
      "Norm of gradient at iteration 148: 6175.018279511293\n",
      "Norm of gradient at iteration 149: 6156.246992824495\n",
      "Norm of gradient at iteration 150: 6144.78855635541\n",
      "Norm of gradient at iteration 151: 6124.485285993615\n",
      "Norm of gradient at iteration 152: 6098.1637870901495\n",
      "Norm of gradient at iteration 153: 6086.97117442222\n",
      "Norm of gradient at iteration 154: 6062.181885040864\n",
      "Norm of gradient at iteration 155: 6054.468792884937\n",
      "Norm of gradient at iteration 156: 6030.701314967726\n",
      "Norm of gradient at iteration 157: 6009.715342692544\n",
      "Norm of gradient at iteration 158: 5976.707782763295\n",
      "Norm of gradient at iteration 159: 5974.731185965816\n",
      "Norm of gradient at iteration 160: 5964.890576586354\n",
      "Norm of gradient at iteration 161: 5935.2266801464675\n",
      "Norm of gradient at iteration 162: 5924.579211350677\n",
      "Norm of gradient at iteration 163: 5911.370887330294\n",
      "Norm of gradient at iteration 164: 5888.677795843685\n",
      "Norm of gradient at iteration 165: 5863.786944587818\n",
      "Norm of gradient at iteration 166: 5854.118649656502\n",
      "Norm of gradient at iteration 167: 5841.242075791342\n",
      "Norm of gradient at iteration 168: 5821.879805720164\n",
      "Norm of gradient at iteration 169: 5804.87558744986\n",
      "Norm of gradient at iteration 170: 5761.560946417748\n",
      "Norm of gradient at iteration 171: 5762.379981280758\n",
      "Norm of gradient at iteration 172: 5753.203788237977\n",
      "Norm of gradient at iteration 173: 5744.170038568744\n",
      "Norm of gradient at iteration 174: 5729.783762994171\n",
      "Norm of gradient at iteration 175: 5716.4102477363385\n",
      "Norm of gradient at iteration 176: 5694.027732352318\n",
      "Norm of gradient at iteration 177: 5681.538889738173\n",
      "Norm of gradient at iteration 178: 5678.492474707713\n",
      "Norm of gradient at iteration 179: 5694.445832107499\n",
      "Norm of gradient at iteration 180: 5642.173566905835\n",
      "Norm of gradient at iteration 181: 5626.058519641268\n",
      "Norm of gradient at iteration 182: 5607.068789986511\n",
      "Norm of gradient at iteration 183: 5594.7613203747005\n",
      "Norm of gradient at iteration 184: 5584.3359081739745\n",
      "Norm of gradient at iteration 185: 5566.712865481475\n",
      "Norm of gradient at iteration 186: 5552.716703094211\n",
      "Norm of gradient at iteration 187: 5530.670873521562\n",
      "Norm of gradient at iteration 188: 5535.260895854508\n",
      "Norm of gradient at iteration 189: 5514.166226550521\n",
      "Norm of gradient at iteration 190: 5494.469325434069\n",
      "Norm of gradient at iteration 191: 5485.7301133657475\n",
      "Norm of gradient at iteration 192: 5464.07543710675\n",
      "Norm of gradient at iteration 193: 5452.811529969945\n",
      "Norm of gradient at iteration 194: 5445.792187124797\n",
      "Norm of gradient at iteration 195: 5430.9670156491065\n",
      "Norm of gradient at iteration 196: 5421.6369197915465\n",
      "Norm of gradient at iteration 197: 5405.470966597823\n",
      "Norm of gradient at iteration 198: 5394.067715407704\n",
      "Norm of gradient at iteration 199: 5380.957555472716\n",
      "Norm of gradient at iteration 200: 5383.068952964308\n",
      "Norm of gradient at iteration 201: 5353.07628108647\n",
      "Norm of gradient at iteration 202: 5344.743839492032\n",
      "Norm of gradient at iteration 203: 5330.99980884249\n",
      "Norm of gradient at iteration 204: 5308.902378398006\n",
      "Norm of gradient at iteration 205: 5311.6137303506775\n",
      "Norm of gradient at iteration 206: 5294.395547131106\n",
      "Norm of gradient at iteration 207: 5285.759846406803\n",
      "Norm of gradient at iteration 208: 5274.071436240496\n",
      "Norm of gradient at iteration 209: 5256.418464742443\n",
      "Norm of gradient at iteration 210: 5250.555319904024\n",
      "Norm of gradient at iteration 211: 5228.569180141918\n",
      "Norm of gradient at iteration 212: 5223.9067363906015\n",
      "Norm of gradient at iteration 213: 5216.761811777358\n",
      "Norm of gradient at iteration 214: 5196.145643726945\n",
      "Norm of gradient at iteration 215: 5194.954303154196\n",
      "Norm of gradient at iteration 216: 5182.680510106248\n",
      "Norm of gradient at iteration 217: 5168.124217154751\n",
      "Norm of gradient at iteration 218: 5162.39135040749\n",
      "Norm of gradient at iteration 219: 5146.025004078333\n",
      "Norm of gradient at iteration 220: 5134.7013725299075\n",
      "Norm of gradient at iteration 221: 5126.796302141005\n",
      "Norm of gradient at iteration 222: 5111.618800221075\n",
      "Norm of gradient at iteration 223: 5105.4861723421\n",
      "Norm of gradient at iteration 224: 5093.218404175657\n",
      "Norm of gradient at iteration 225: 5085.703111834115\n",
      "Norm of gradient at iteration 226: 5096.53703913659\n",
      "Norm of gradient at iteration 227: 5062.936931904449\n",
      "Norm of gradient at iteration 228: 5056.471525755639\n",
      "Norm of gradient at iteration 229: 5034.333021682108\n",
      "Norm of gradient at iteration 230: 5036.27068788223\n",
      "Norm of gradient at iteration 231: 5017.412004856335\n",
      "Norm of gradient at iteration 232: 5012.1450604558095\n",
      "Norm of gradient at iteration 233: 5003.102517562696\n",
      "Norm of gradient at iteration 234: 4987.077554628596\n",
      "Norm of gradient at iteration 235: 4981.0008467233065\n",
      "Norm of gradient at iteration 236: 4968.924727728832\n",
      "Norm of gradient at iteration 237: 4961.370373798282\n",
      "Norm of gradient at iteration 238: 4952.528864132516\n",
      "Norm of gradient at iteration 239: 4939.010580851871\n",
      "Norm of gradient at iteration 240: 4934.67237375649\n",
      "Norm of gradient at iteration 241: 4922.865508858742\n",
      "Norm of gradient at iteration 242: 4933.417005027974\n",
      "Norm of gradient at iteration 243: 4910.046620584382\n",
      "Norm of gradient at iteration 244: 4895.614335869766\n",
      "Norm of gradient at iteration 245: 4872.0968253214005\n",
      "Norm of gradient at iteration 246: 4877.242891628436\n",
      "Norm of gradient at iteration 247: 4867.398170170924\n",
      "Norm of gradient at iteration 248: 4853.201920917275\n",
      "Norm of gradient at iteration 249: 4846.445105783479\n",
      "Norm of gradient at iteration 250: 4831.443956343638\n",
      "Norm of gradient at iteration 251: 4827.418856606265\n",
      "Norm of gradient at iteration 252: 4818.312546287742\n",
      "Norm of gradient at iteration 253: 4810.418582694502\n",
      "Norm of gradient at iteration 254: 4801.534088166187\n",
      "Norm of gradient at iteration 255: 4803.517992374213\n",
      "Norm of gradient at iteration 256: 4785.06127670017\n",
      "Norm of gradient at iteration 257: 4779.211459166176\n",
      "Norm of gradient at iteration 258: 4761.29683935256\n",
      "Norm of gradient at iteration 259: 4760.194534253822\n",
      "Norm of gradient at iteration 260: 4748.085691202631\n",
      "Norm of gradient at iteration 261: 4743.1241710419135\n",
      "Norm of gradient at iteration 262: 4735.980240984893\n",
      "Norm of gradient at iteration 263: 4726.06248088711\n",
      "Norm of gradient at iteration 264: 4743.082211590587\n",
      "Norm of gradient at iteration 265: 4727.604764084348\n",
      "Norm of gradient at iteration 266: 4699.227056616268\n",
      "Norm of gradient at iteration 267: 4702.738370738515\n",
      "Norm of gradient at iteration 268: 4681.78252282667\n",
      "Norm of gradient at iteration 269: 4675.2583754068855\n",
      "Norm of gradient at iteration 270: 4664.785368939869\n",
      "Norm of gradient at iteration 271: 4660.878259052583\n",
      "Norm of gradient at iteration 272: 4647.954135110098\n",
      "Norm of gradient at iteration 273: 4647.439100732537\n",
      "Norm of gradient at iteration 274: 4636.23482397242\n",
      "Norm of gradient at iteration 275: 4629.269139436003\n",
      "Norm of gradient at iteration 276: 4619.9211283192935\n",
      "Norm of gradient at iteration 277: 4614.21067560286\n",
      "Norm of gradient at iteration 278: 4604.976212472009\n",
      "Norm of gradient at iteration 279: 4599.138521243357\n",
      "Norm of gradient at iteration 280: 4587.015792286385\n",
      "Norm of gradient at iteration 281: 4581.021154099989\n",
      "Norm of gradient at iteration 282: 4573.925484115697\n",
      "Norm of gradient at iteration 283: 4566.760548532515\n",
      "Norm of gradient at iteration 284: 4564.113601817446\n",
      "Norm of gradient at iteration 285: 4552.822701992677\n",
      "Norm of gradient at iteration 286: 4540.86507049387\n",
      "Norm of gradient at iteration 287: 4540.793317201439\n",
      "Norm of gradient at iteration 288: 4531.155167982476\n",
      "Norm of gradient at iteration 289: 4516.7889982963525\n",
      "Norm of gradient at iteration 290: 4521.631025493678\n",
      "Norm of gradient at iteration 291: 4532.423143516535\n",
      "Norm of gradient at iteration 292: 4503.866575096902\n",
      "Norm of gradient at iteration 293: 4492.314490828716\n",
      "Norm of gradient at iteration 294: 4485.242432632509\n",
      "Norm of gradient at iteration 295: 4483.782857318508\n",
      "Norm of gradient at iteration 296: 4477.207122210808\n",
      "Norm of gradient at iteration 297: 4461.754300390617\n",
      "Norm of gradient at iteration 298: 4456.3152939079455\n",
      "Norm of gradient at iteration 299: 4448.867944813876\n",
      "Norm of gradient at iteration 300: 4446.4464287633855\n",
      "Norm of gradient at iteration 301: 4437.642150418965\n",
      "Norm of gradient at iteration 302: 4433.189590208715\n",
      "Norm of gradient at iteration 303: 4425.948763778977\n",
      "Norm of gradient at iteration 304: 4417.5302067815155\n",
      "Norm of gradient at iteration 305: 4411.2035392094085\n",
      "Norm of gradient at iteration 306: 4384.346426787432\n",
      "Norm of gradient at iteration 307: 4400.5644697366515\n",
      "Norm of gradient at iteration 308: 4397.321254510444\n",
      "Norm of gradient at iteration 309: 4383.08182160413\n",
      "Norm of gradient at iteration 310: 4376.086511238145\n",
      "Norm of gradient at iteration 311: 4375.010445116077\n",
      "Norm of gradient at iteration 312: 4369.702797221453\n",
      "Norm of gradient at iteration 313: 4380.898771519439\n",
      "Norm of gradient at iteration 314: 4353.400994422181\n",
      "Norm of gradient at iteration 315: 4336.042856585201\n",
      "Norm of gradient at iteration 316: 4336.095160125816\n",
      "Norm of gradient at iteration 317: 4339.335823708244\n",
      "Norm of gradient at iteration 318: 4328.8857515999525\n",
      "Norm of gradient at iteration 319: 4325.390310765165\n",
      "Norm of gradient at iteration 320: 4316.298181050761\n",
      "Norm of gradient at iteration 321: 4305.68142849063\n",
      "Norm of gradient at iteration 322: 4300.668326827065\n",
      "Norm of gradient at iteration 323: 4295.638914824359\n",
      "Norm of gradient at iteration 324: 4284.219401963333\n",
      "Norm of gradient at iteration 325: 4287.339032119073\n",
      "Norm of gradient at iteration 326: 4277.510029989025\n",
      "Norm of gradient at iteration 327: 4267.505795358097\n",
      "Norm of gradient at iteration 328: 4265.357194935715\n",
      "Norm of gradient at iteration 329: 4268.179758866873\n",
      "Norm of gradient at iteration 330: 4249.61953352622\n",
      "Norm of gradient at iteration 331: 4257.9894188749995\n",
      "Norm of gradient at iteration 332: 4243.744380982502\n",
      "Norm of gradient at iteration 333: 4228.585021907931\n",
      "Norm of gradient at iteration 334: 4231.775460719243\n",
      "Norm of gradient at iteration 335: 4224.186826328818\n",
      "Norm of gradient at iteration 336: 4214.545712780872\n",
      "Norm of gradient at iteration 337: 4211.920070536104\n",
      "Norm of gradient at iteration 338: 4201.542221227184\n",
      "Norm of gradient at iteration 339: 4202.006944539672\n",
      "Norm of gradient at iteration 340: 4193.130630730479\n",
      "Norm of gradient at iteration 341: 4194.977216888936\n",
      "Norm of gradient at iteration 342: 4184.87485037062\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26224/1427379883.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstochastic_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10e-6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26224/914491126.py\u001b[0m in \u001b[0;36mstochastic_gradient\u001b[1;34m(X, y, tau, betas, decay_rate, learning_rate, maxiter, batch_size)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mgrad\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mbetas\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[1;31m# grad += gradient(X_batch,y_batch,betas)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "betas = stochastic_gradient(X_train_scaled,y_train,10e-6,np.zeros((X_train_scaled.shape[1],1)),0.01,0.01,maxiter = 10000, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[538146.9130253 ],\n",
       "       [-55407.81004142],\n",
       "       [  4037.40320119],\n",
       "       [289545.14933787],\n",
       "       [-16406.6190379 ]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = X_test_scaled @ betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5050576359316632"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test.flatten(),predictions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5bea1dba265153f73dd176568fe5adcb617454bd08dac3159439b35e09c34b6f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
